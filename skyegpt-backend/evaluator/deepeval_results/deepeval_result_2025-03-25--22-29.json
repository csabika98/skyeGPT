{
  "testFile": "evaluator/test_skyegpt.py",
  "testCases": [
    {
      "name": "test_customer_chatbot[test_case0]",
      "input": "I have three time based schedulers:\n1.\tCan run in parallel\n2.\tCan run in parallel\n3.\tCannot run in parallel\nWhile scheduler a) is already running, c) gets queued, after that b) gets queued. Will b) run in parallel with a)? If while a) is running, b) gets queued first and c) gets queued second, will b) run parallel with a)?",
      "actualOutput": "In the scenario you described, the execution behavior of the schedulers will depend on their ability to run in parallel and the order in which they are queued.\n\n1. **First Scenario**: \n   - Scheduler a) (can run in parallel) is already running.\n   - Scheduler c) (cannot run in parallel) gets queued and will wait until a) finishes.\n   - Scheduler b) (can run in parallel) gets queued after c).\n\n   In this case, scheduler b) will **not** run in parallel with a) because it is queued after c), which is waiting for a) to finish. Therefore, b) will also wait until a) completes before it can start.\n\n2. **Second Scenario**: \n   - Scheduler a) (can run in parallel) is already running.\n   - Scheduler b) (can run in parallel) gets queued first.\n   - Scheduler c) (cannot run in parallel) gets queued second.\n\n   In this case, scheduler b) will **not** run in parallel with a) because it is queued after c), which is waiting for a) to finish. Therefore, b) will also wait until a) completes before it can start.\n\nIn summary, in both scenarios, scheduler b) will not run in parallel with scheduler a) due to the queuing order and the constraints of scheduler c). \n\nFor more details on how task execution and queuing work, you can refer to the documentation on [Parallel execution](https://confluence.innoveo.com/dosearchsite.action?queryString=parallelization).",
      "expectedOutput": "If c) gets queued before b), b) will not run in parallel with a), because skye is always checking the very next scheduler in the queue, and that is c), which is non-parallel. So a) will finish, and both will wait for it. Then c) will run and finish and b) will wait for it. Then b) will run and finish.\nIf b) gets queued before c), it will get triggered and start running while a) is still running. c) will wait for both to finish and then start.",
      "context": [
        "# Parallel execution\n\nIn a queue of tasks which are ready for execution, where there is a combination of tasks that can run in parallel with others and tasks that cannot run in parallel with others, the order of execution will be the following:\n\n- If the next task in the queue is a task that cannot run in parallel, this task will be running alone.\n- If the next task in the queue is a task that can run in parallel, all the tasks that are ready and that can run in parallel will be grouped and triggered. The queue will wait until they are done to trigger the next item from the queue."
      ],
      "retrievalContext": [
        "---\ntitle: \"Running tasks in parallel\"\nweight: 30\n---  \nIt is possible to configure whether tasks triggered by a scheduler are allowed to run in parallel with tasks from other schedulers. The following page explains how the parallel execution is carried out.",
        "# Parallel execution  \nIn a queue of tasks which are ready for execution, where there is a combination of tasks that can run in parallel with others and tasks that cannot run in parallel with others, the order of execution will be the following:  \n- If the next task in the queue is a task that cannot run in parallel, this task will be running alone.\n- If the next task in the queue is a task that can run in parallel, all the tasks that are ready and that can run in parallel will be grouped and triggered. The queue will wait until they are done to trigger the next item from the queue.  \n![screenshot](https://confluence.innoveo.com/is915/files/158613071/158613072/1/1718368191000/Tasks+Parallel+9.14.2.JPG)",
        "## Condition based scheduler configuration  \nTwo types of conditions are supported in this type of schedulers:  \n- after another task\n- when a file is added (file listener)  \nIt is also possible to use both of the conditions in the same scheduler. In that case, the scheduler will wait for all the defined conditions to be fulfilled before triggering the tasks.",
        "## Running tasks in parallel  \nTo learn more details about parallel task execution, see [this page](./parallelization.md).",
        "## Running tasks in parallel  \nTo learn more details about parallel task execution, see [this page](./parallelization.md).",
        "---\ntitle: \"Time based task scheduler\"\nweight: 10\n---  \nTime based task scheduler is used to define a list of tasks which should be scheduled at a given date and time. Time based schedulers support one-off and recurring scheduling.",
        "# Parallel execution  \nBy default the service calls are executed in parallel, in case a service call should not be executed in parallel with other service calls the property 'restEndpoint.blocking' can be configured. The value of the property is a comma-separated list of rest endpoint attributes text id paths that do not allow parallel execution.  \nAn example of when not to use parallel execution would be when creating or updating implementations that require a unique value verification (UniqueRootAttributeImplValueServiceDelegate).",
        "## Time based scheduler configuration  \n![screenshot](https://confluence.innoveo.com/is914/files/158606820/158606821/1/1711441128000/image2024-3-13_8-51-7.png)  \n| <div style=\"width:200px\">Property</div> | <div style=\"width:500px\">Description</div> | Mandatory |\n| --- | --- | --- |\n| Recurring | If selected, the tasks triggered by this scheduler will be recurring (i.e they will run multiple times with the periodicity defined on \"Recurring trigger time\"). Otherwise, the tasks will run only once.  | No |\n| Schedule tasks when activating | If selected, the scheduler execution will be created automatically when activating the definition. If not selected, the scheduler execution will not be created, it will only delete the old schedulers and related tasks that were scheduled previously. | No |\n| Trigger time | Defines when the tasks triggered by this scheduler should be added to the task queue after the definition has been activated. In order to run the event immediately after activation, use the value %{TODAY+TIME\\[NOW\\]}. Date resolvers or date in format 'yyyy.MM.dd HH:mm:ss' can be used. | Yes |\n| Recurring trigger time | Only visible if 'Recurring' is selected. It defines when the tasks triggered by this scheduler should be repeated after the previous execution. The tasks will be repeatedly added to the queue until the scheduler is stopped. Only date resolvers should be used. | Yes, if \"Recurring\" is selected |\n| Tasks triggered by this scheduler | A list of tasks that will be triggered by this scheduler. At least one entry is mandatory in the list.<br> <br> The tasks will be executed in the order given in the list. | Yes |\n| Allow tasks to run in parallel | If selected, then the tasks triggered by this scheduler can run in parallel with other tasks from other scheduler.<br> <br> It is important that tasks that run in parallel do not have dependencies or relations between each other. | No |",
        "---\ntitle: \"Condition based task scheduler\"\nweight: 20\n---  \nCondition based task scheduler is used to define a list of tasks which should be triggered once the conditions defined in the scheduler have been fulfilled. Condition based schedulers support one-off and recurring scheduling.",
        "### After another task condition  \nThis condition type allows the user to select one or more preceding tasks that need to be completed in one of the selected statuses in order for the tasks that are listed in the scheduler to be triggered.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606822/158606824/1/1711441128000/image2024-3-13_9-1-2.png)  \n| <div style=\"width:200px\">Property</div> | <div style=\"width:500px\">Description</div> | Mandatory |\n| --- | --- | --- |\n| Recurring | If selected, the tasks triggered by this scheduler will be recurring (i.e they will run every time the conditions defined in the scheduler are fulfilled). <br> Otherwise, the tasks will run only once after the conditions have been fulfilled.  | No |\n| Preceding task | A list of preceding tasks that need to be completed for the scheduler to trigger the related tasks. At least one entry is mandatory in the list | Yes |\n| Preceding task scheduler | Scheduler related to the selected preceding task. | Yes |\n| Preceding task status | One or more statuses with which the preceding task needs to end for the scheduler to trigger the related tasks. The list of possible task statuses can be found [here](../task/_index.md#task-status). | Yes |\n| Tasks triggered by this scheduler | A list of tasks that will be triggered by this scheduler. At least one entry is mandatory in the list. The tasks will be executed in the order given in the list. | Yes |\n| Allow tasks to run in parallel | If selected, then the tasks triggered by this scheduler can run in parallel with other tasks from other scheduler. It is important that tasks that run in parallel do not have dependencies or relations between each other.  | No |",
        "---\ntitle: \"Tasks and schedulers configuration examples\"\nweight: 70\n---  \nTasks and schedulers allow for a great degree of flexibility when it comes to scheduling tasks and configuring actions that happen after processing a task that cover many business needs.  \nA few examples are given below.",
        "## The challenge with Event Scheduler  \nSkye is a transactional system and within a user action it works in a sequential way. This means that if there are multiple actions to be executed in order, then firstly the first action is executed, then every consequence of that action is executed then it moves to the second action, then the consequences of the second action etc.  \nImagine that you are a user in the system and you clicked on an action button that triggered a web-service call. You are stuck on that screen until every consequence of that action button set value are done (every excel, dependency, web-service, etc). This part of Skye works sequentially. Imagine that you open the same application in a new browser window, then you could work parallelly while your first browser tab\u2019s actions are executed (only if you are editing different implementations).  \nThis gives us the benefit of being deterministic, but with the events, it brings a challenge: if there is a slow event, then Skye waits until the last consequence of that event is finished before it moves to the next event. Imagine that if a 40 min import is triggered at 00:01:00 and an email sending is triggered at 00:02:00, then the event would not be executed until the import is finished and would be only sent out at 00:41:00 which is undesired. This also means that events can queue up: if you have multiple slow imports they will be executed sequentially and not in parallel. When all the actions are executed and before Skye moves on to the next event, Skye checks if the event is recurring or not and if yes, then it marks the current event processed and creates the new event trigger time in the scheduler (this also means that if there was a problem during executions this is not done and the recurring part stops).",
        "## How to define when to plan a scheduler  \nThe scheduler is created via a trigger event dependency. A scheduler is created when the scheduler attribute is set to trigger event via dependency.  \n**Note:** To activate a scheduler attribute, make sure the implementation where the attribute is set up is saved in the database.  \nExample:  \nIf the attribute 'Travel.Condition2' switches to a value of '1', the scheduler attribute will activate, initiating the planning of the specified scheduler (provided there isn't one already scheduled with the same text ID).  \n![screenshot](https://confluence.innoveo.com/is914/files/158604245/158604246/1/1711440408000/image2024-3-11_15-23-2.png)",
        "---\ntitle: \"Scheduler attribute\"\nweight: 440\n---  \nThe scheduler attribute facilitates the scheduling of a task scheduler linked to an established implementation.  \n1. Selection of the scheduler (identified by its text ID).\n1. Selection of the scheduler based on different criteria (specified in the criterion table).\n1. Determination of when the scheduler should be generated (specified within the \"Trigger event\" dependency action of the event attribute).\n1. Specification of the locale to be utilized during the execution of the task(designated in the trigger locale).  \nOn this page only the scheduler attribute is described but not the tasks that can be created and triggered with it.",
        "---\ntitle: \"Parallel service invoker service attribute\"\nweight: 330\n---  \nThis service allows invoking multiple services in parallel.",
        "---\ntitle: \"Viewing schedulers and tasks\"\nweight: 70\n---  \nWith the Admin console it is possible to view schedulers and tasks, which are saved in the database.  \nThe following information is available:  \n- Scheduler definition ID and text-id\n- Type of trigger (time or condition based)\n- Source of the scheduler (whether it was created in Business Canvas or in the Admin console)\n- Triggered time of the scheduler\n- Scheduled for time of the scheduler\n- Status of the scheduler\n- Task definition ID and text-id\n- Task type (delete, email, import, export, set values, other)\n- Status of the task\n- Start and end date and time of task  \n![screenshot](https://confluence.innoveo.com/is915/files/158609794/158609796/1/1718367280000/image2024-6-12_14-36-30.png)",
        "---\ntitle: \"Email scheduler attribute\"\nweight: 160\n---  \nThe email scheduler attribute facilitates the scheduling of task scheduler creation linked to an established implementation.  \n1. Selection of the email scheduler (identified by its text ID).\n1. Selection of the email scheduler based on different criteria (specified in the criterion table).\n1. Determination of when the scheduler should be generated (specified within the \"Trigger event\" dependency action of the event attribute).\n1. Specification of the locale to be utilized during the execution of the event (designated in the trigger locale).\n1. Selection of the email that would be sent (defined in the email attribute property)  \nOn this page only the scheduler attribute is described but not the email tasks that are created and triggered with it.",
        "### Using \"Predefined expression\" scheduling option  \nPredefined expressions allow the user to quickly schedule a recurring task with some of the most common options for daily, weekly and monthly recurrence.  \n| Step | Description |\n| --- | --- |\n| 1 | Repeat steps 1-3 described in the \"Date time\" scheduling option above. |\n| 2 | Select the \"Predefined expression\" as the scheduling option and then select one of the available repetition option from the dropdown. ![screenshot](https://confluence.innoveo.com/is915/files/158609896/158609899/1/1718367304000/image2024-6-12_15-45-16.png) |\n| 3a | In case \"**Daily**\" repetition is selected, the desired date and time for task scheduling has to be selected.![screenshot](https://confluence.innoveo.com/is915/files/158609896/158609904/1/1718367304000/image2024-6-12_15-9-44.png) In the example given on the picture above, the selected task will be scheduled every day at 15:08. |\n| 3b | In case \"**Weekly**\" repetition is selected, the following needs to be defined: <ul><li>days of the week when the task should be scheduled</li><li>time at which the task should be scheduled.</li></ul> ![screenshot](https://confluence.innoveo.com/is915/files/158609896/158609903/1/1718367304000/image2024-6-12_15-12-25.png) In the example given on the picture above, the selected task will be scheduled every Monday and Friday at 22:00. |\n| 3c | In case \"**Monthly**\" repetition is selected, the following needs to be defined: <ul><li>whether the task will be scheduled on the first or last day of the month</li><li>time at which the task should be scheduled.</li></ul> ![screenshot](https://confluence.innoveo.com/is915/files/158609896/158609902/1/1718367304000/image2024-6-12_15-16-1.png) In the example given on the picture above, the selected task will be scheduled every last day of the month at 12:00. |\n| 4 | Click on the \"Save\" button.<br> A new scheduler record is automatically created in the table with the selected task scheduled at the selected date and time. <br> After the first occurrence of the task is triggered, a new scheduler with the next occurrence of the task will be visible in the table. ![screenshot](https://confluence.innoveo.com/is915/files/158609896/158609901/1/1718367304000/image2024-6-12_15-18-33.png) |",
        "## How to define when to plan an email scheduler  \nThe scheduler is created via a trigger event dependency. A scheduler is created when the scheduler attribute is set to trigger event via dependency.  \n**Note**: To activate a scheduler attribute, make sure the implementation where the attribute is set up is saved in the database.  \nExample:  \nIf the attribute 'EmailConfiguration.Condition1' switches to a value of '1', the scheduler attribute will activate, initiating the planning of the specified scheduler (provided there isn't one already scheduled with the same text ID).  \n![screenshot](https://confluence.innoveo.com/is914/files/158604215/158604217/1/1711440406000/image2024-3-12_12-14-53.png)",
        "## Scheduler attribute properties  \n![screenshot](https://confluence.innoveo.com/is915/files/158610446/158610451/1/1718367420000/image2024-3-11_14-42-31.png) ![screenshot](https://confluence.innoveo.com/is915/files/158610446/158610450/1/1718367420000/image2024-3-11_14-45-44.png)  \n| <div style=\"width:200px\">Property</div> | <div style=\"width:500px\">Description</div> |\n| --- | --- |\n| Task scheduler selection | The task scheduler selection determines whether the scheduler attribute will execute a single scheduler (value Simple) or if multiple schedulers will be triggered based on specified criteria (value Advanced). |\n| Task scheduler definition | Text-id of the scheduler that should be scheduled. |\n| Criterion | Text-id of the scheduler that should be scheduled under the defined criteria. <br> <br> Example:<br>![screenshot](https://confluence.innoveo.com/is914/files/158604245/158604248/1/1711440408000/image2024-3-11_14-59-39.png) <br> <br> If the attribute Condition1 holds the value \"nationality,\" the scheduler CreateNationalityIndexScheduler will be scheduled upon execution of the 'Trigger event' dependency.Alternatively, if the attribute Condition1 contains the value \"car,\" the scheduler CreateCarIndexScheduler will be scheduled upon execution of the 'Trigger event' dependency. |\n| Trigger locale | Locale that will be used during the scheduler execution. <br> <br> In case of variable resolver expression, it will be resolved at the moment the scheduler attribute \"Trigger event\" dependency action is triggered. <br> <br> The value will overwrite the property 'Locale' on the task that would be executed by the scheduler. |"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Fantastic job! The perfect score of 1.00 reflects that there are no contradictions between the actual output and the retrieval context. Keep up the excellent work!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.018705,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Tasks that cannot run in parallel will be executed alone, one at a time.\",\n    \"Tasks that can run in parallel will be grouped together and executed simultaneously.\",\n    \"Schedulers can be configured to trigger tasks based on conditions such as 'after another task' or 'when a file is added.'\",\n    \"Time-based schedulers can schedule tasks at specific dates and times, supporting both one-off and recurring scheduling.\",\n    \"The 'restEndpoint.blocking' property can block certain endpoints from executing in parallel with others.\",\n    \"Schedulers created via trigger events require certain conditions to be met in order to activate.\",\n    \"Event scheduling within the Skye transactional system operates sequentially, leading to potential delays if slow events occur.\",\n    \"Schedulers and tasks can be viewed with the Admin console, showing details like status, scheduler type, and trigger time.\",\n    \"Email scheduler attributes can be used to schedule tasks related to emails, with specified criteria for execution.\",\n    \"Predefined expressions allow quick scheduling of recurring tasks with set daily, weekly, or monthly intervals.\",\n    \"Scheduler attributes can initiate the planning of a scheduler based on trigger event dependencies.\",\n    \"Schedulers have attributes like task scheduler selection, definition text-id, and criterion, which determine how and when tasks are scheduled.\"\n] \n \nClaims:\n[\n    \"Scheduler a) can run in parallel and is already running in both scenarios.\",\n    \"Scheduler c) cannot run in parallel and gets queued, waiting for a) to finish.\",\n    \"Scheduler b) can run in parallel but will not run in parallel with a) in both scenarios.\",\n    \"The queuing order and constraints of c) prevent scheduler b) from running in parallel with a).\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.9090909090909091,
          "reason": "The score is 0.91 because the responses thoroughly address the parallelization conditions of the schedulers in the input. The main relevant points are covered clearly with a strong understanding of the problem setup afforded by the input details. However, a slightly better score is possible by replacing or removing the general reference to documentation without directly offering specific guidance pertinent to the input situation.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.008382500000000001,
          "verboseLogs": "Statements:\n[\n    \"The execution behavior of the schedulers depends on their ability to run in parallel and the order in which they are queued.\",\n    \"Scheduler a) can run in parallel and is already running.\",\n    \"Scheduler c) cannot run in parallel and will wait until a) finishes.\",\n    \"Scheduler b) can run in parallel and is queued after c).\",\n    \"Scheduler b) will not run in parallel with a) because it is queued after c).\",\n    \"Scheduler b) will also wait until a) completes before it can start.\",\n    \"Scheduler b) is queued after a) and will wait until a) completes before starting.\",\n    \"Scheduler c) causes scheduler b) to wait until a) finishes.\",\n    \"Both scenarios result in scheduler b) not running in parallel with scheduler a).\",\n    \"The queuing order and constraints of scheduler c) affect execution.\",\n    \"More details on task execution and queuing can be found in the documentation on Parallel execution.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"This statement references documentation without providing specific, direct information about the scenarios described in the input.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.9366374989878119,
          "reason": "The context fully exists within the retrieval context, a link is included, and retrieval context does not contradict context. It maintains consistency and offers additional context about parallel execution by mentioning the configuration of tasks, enhancing understanding.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.012355,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Compare if CONTEXT fully exists within RETRIEVAL_CONTEXT.\",\n    \"Check if RETRIEVAL_CONTEXT includes a link.\",\n    \"Ensure that the additional information in RETRIEVAL_CONTEXT does not contradict CONTEXT.\",\n    \"Verify that RETRIEVAL_CONTEXT enhances or maintains the consistency with CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.3,
          "reason": "Actual Output aligns with Expected Output about b) not running in parallel when c) is first but contradicts when b) is first, stating b) will not run when a) is running. It wrongly describes that b) waits in both scenarios and includes a link to documentation.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0036875000000000002,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the Actual Output and Expected Output for similarities to determine closeness.\",\n    \"Check if the Actual Output includes a link to documentation.\",\n    \"Verify the Actual Output for the presence of additional information and ensure it does not contradict the Expected Output.\",\n    \"Evaluate if the additional information in the Actual Output supports or enhances the Expected Output without causing discrepancies.\"\n]"
        }
      ],
      "runDuration": 7.069666917002905,
      "evaluationCost": 0.04313,
      "order": 0
    },
    {
      "name": "test_customer_chatbot[test_case1]",
      "input": "Do I need to migrate attributes that do not have a default value?",
      "actualOutput": "You do not need to migrate attributes that do not have a default value when the implementation is being opened for the first time. If an attribute is expected to have no value for existing implementations, such as a newly added attribute that customers will fill in later, it does not require migration. \n\nFor more details, you can refer to the documentation here: [Why is this so important?](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/404848836).",
      "expectedOutput": "- Compact database doesn\u2019t store empty attributes, so there is no need to migrate\n- Difference between versions before and after 8.7",
      "context": [
        "# The Why\n## Necessity of migration\n\nInnoveo Skye is built on using models that are representing products, processes, organizations, etc. The models (definitions) are prepared by the Business Canvas tool.\nInnoveo Skye software on the servers uses the models to create objects (implementations) in which the unique data is stored.\nBy time, the models change, and this can cause inconsistency with the objects already existing in the database.To overcome this challenge, migration is needed.\n\n# The What\n## Compact database\n\nSince Skye 7, there is an option called compact database. If the compact database is enabled, then the attributes without values will not be saved to the database. \nThis is implemented on a rather deep (database-connection) layer of the application and works in a way, that if an attribute can not be found in the database, Skye will assume that it is empty.\nThis is a really big gamechanger for the migration.\n\n### Why is this so important?There are two parts to it.\n    \nYou don\u2019t have to migrate attributes that do not need to have a value when the implementation is being opened for the first time. If you add an attribute called \u201ccustomerFirstName\u201d and you expect the customers to fill that information in your next phase, you don\u2019t have to migrate this attribute, as it is expected to have no value for all the existing implementations.\n- A lot of attributes not only do not have but can not have values in the database. You don\u2019t have to migrate Excel attributes, service attributes, container attributes, basically nothing which does not have the default value option in Skye.\n    \nIt reduces the number of rows required to save an implementation. This is different on every project, but the thumb-rule is that usually, an implementation has 60% fewer rows with this feature enabled. This will reduce your database size by almost 60% which then again will shorten your migration run time exponentially."
      ],
      "retrievalContext": [
        "# Best practices (Configuration)  \n## Add a value to a newly added attribute  \nThe Default value parameter is only applied in attributes when a new implementation is created.  \nFor existing implementations the Migration value parameter can be used to set a value on a newly added attribute.",
        "### Why is this so important?  \nThere are two parts to it.  \n1. You don\u2019t have to migrate attributes that do not need to have a value when the implementation is being opened for the first time. If you add an attribute called \u201ccustomerFirstName\u201d and you expect the customers to fill that information in your next phase, **you don\u2019t have to migrate this attribute, as it is expected to have no value for all the existing implementations.**  \n1. **A lot of attributes not only do not have but can not have values in the database**. You don\u2019t have to migrate Excel attributes, service attributes, container attributes, basically nothing which does not have the default value option in Skye.\n2. It reduces the number of rows required to save an implementation. This is different on every project, but the thumb-rule is that usually, an implementation has 60% fewer rows with this feature enabled. This will reduce your database size by almost 60% which then again will shorten your migration run time exponentially.",
        "## Compact database  \nBefore we get into this, there is an important factor that we need to clarify. Since Skye 7, there is an option called compact database. If the compact database is enabled, then the **attributes without values will not be saved to the database.** This is implemented on a rather deep (database-connection) layer of the application and works in a way, that if an attribute can not be found in the database, Skye will assume that it is empty. This is a really big gamechanger for the migration.",
        "# Purpose  \nAs part of migration, sometimes you have to delete specific attributes.",
        "### Migration Operations  \nMigration operations are the transformations performed automatically on the implementations. The following are supported:  \n* Attributes\n* Add\n* When an attribute is added, it\u2019s also possible to set its value (variable resolver expressions are supported here). If no value is defined here the new attributes' value will be empty. The attribute default value (from the definition) is not taken.\n* Remove\n* Rename\n* Move  \n* Bricks (Single)\n* Add\n* Remove\n* Rename  \n* Multibricks\n* Add\n* Remove\n* Rename\n* Conversion of a single brick into a multibrick\n* Conversion of a multibrick into a single brick\n* Changing min/maxUsage of a multibrick",
        "# Always consider for any migration scripts  \n## Order of running scripts  \nThere may be dependencies that you need to consider in order to execute your migration scripts in the appropriate order.  \nAs a simple example, let\u2019s say we have configured a new brick and a new attribute.  \nRunning the insert\\_attribute migration script before the insert\\_brick migration script, the attribute will have no container brick, it will have \u201cnowhere to go\u201d.  \nThere is a dependency to first insert the new brick to existing implementations, and only then the attribute(s).",
        "## Supported migrations  \nMigration commands may be generated for following changes in definitions:  \n- Add brick on root\n- Add brick on brick\n- Add attribute on root\n- Add attribute on brick\n- Delete attribute\n- Delete brick\n- Modify brick text id\n- Modifyattribute text id\n- Modifyattribute default value\n- Warn: if default value contains a variable resolver expression it would be inserted as the default value in the DB and therefore resolved every time, not just once on creation!",
        "### Effect on migration  \nThe key part is the *\u201cif an attribute can not be found in the database, Skye will assume that it is empty\u201d.* Without this setting, if an attribute is not found for an implementation, Skye would run on an error as it would find inconsistent implementations. If this setting is enabled, then when it is not found an attribute it will not run into an error, it will assume it is empty.",
        "## What are the actions that would cause a need to migrate  \n#### Brick  \n* creating a brick\n* deleting a brick\n* renaming a brick\n* move the brick under another brick\n* Create a brick on a hotfix branch which you have to recreate on the master branch  \n#### Attribute  \n* Creating Generic, Flexdata, MultiFlexdata, Counter, Reference attributes  \n+ ONLY when creating an attribute where you want them to have a specific value in the historical implementations  \n- in case the rule above applies AND when Create an attribute on a hotfix branch which you have to recreate on the master branch\n* deleting an attribute\n* renaming an attribute\n* move the attribute to a different brick\n* the default value of the attribute (in case you want to use the new default value in the historical implementations you have to update the value in the database)\n* attribute type change (like single resource attribute to multi-resource attribute)",
        "## Order of running scripts  \nThere may be dependencies that you need to consider in order to execute your migration scripts in the appropriate order.  \nAs a simple example, let\u2019s say we have configured a new brick and within that brick a new attribute.  \nIf you would run the insert\\_attribute migration script before the insert\\_brick migration script, the attribute would have no container brick, it would have \u201cnowhere to go\u201d.  \nIn this case there is a dependency between these migration scripts, and you have to pay attention to run them in the right order; first the insert\\_brick, then the insert\\_attribute.",
        "Migration manually",
        "Identifying need for migration",
        "Preparing for migrations",
        "### Moving attributes  \nIn addition to creating attributes directly within a module definition, attributes from other definitions can be moved to a module as well.  \n* Link has to exist, Module has to exist\n* Cross definition references to attributes will not be migrated!",
        "Migration",
        "# What needs to be migrated?  \nThe simple answer to this question is; data that is stored in the database on the implementation level. When you change something on the definitions, you have to migrate the data which was affected by that change.  \nFirst we will discuss what could be affected, then what could affect them. You will only be able to understand when migration is needed if you understand both of these concepts.",
        "### Pre-validation  \nAs a result of faulty past manual migrations, there might be data inconsistencies in existing Skye databases. Examples of these are missing attributes or bricks. The migration process has to make sure that it\u2019s not adding to the problem by creating inconsistencies that didn\u2019t exist before (e.g. duplicated attributes or bricks in case the implementation was manually migrated but the 'definition version' was not updated).  \nTo prevent this, each implementation is validated for consistency relative to its current definition, prior to the migration being applied. If a given implementation doesn\u2019t satisfy the preconditions for migration, it won\u2019t be migrated until it\u2019s fixed.  \nIf the pre-validation fails during batch migration, the problematic implementation will be skipped and the errors encountered will be stored in the DB. The migration of that particular implementation will not be reattempted until it\u2019s manually fixed. The process to handle these cases is described [here](#dealing-with-inconsistent-implementations). The migration job still proceeds with the remaining implementations.  \nIf, on the other hand, the pre-validation fails during an \u201con-load\u201d migration, then an exception will be thrown and inconsistencies found will be logged (in this case the errors are not stored in the DB).",
        "Data Migration",
        "# What migration is exactly?  \nWhen we say migration, we mean the activity to add and/or modify some data in the database, so there won\u2019t be an inconsistency after the release.  \nWe use migration (sql) scripts to add and/or modify data. These scripts are prepared beforehand based on the changes you introduce in the release and they are executed during deployment. We discuss each step in detail later.",
        "Migration after Go-live"
      ],
      "success": true,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions, reflecting a perfect alignment between the actual output and the retrieval context. Well done on maintaining consistency and accuracy!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0121525,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The default value parameter is used in attributes when a new implementation is created.\",\n    \"For existing implementations, the migration value parameter can set a value on a newly added attribute.\",\n    \"Attributes do not need to be migrated if they are not required to have a value initially.\",\n    \"Some database attributes do not and cannot have values and therefore do not require migration.\",\n    \"Enabling a compact database option in Skye prevents attributes without values from being saved to the database.\",\n    \"Migration operations can involve adding, removing, or renaming attributes or bricks, among other actions.\",\n    \"Dependencies between migration scripts require running them in the appropriate order.\",\n    \"Attributes can be migrated from one module definition to another, given certain conditions.\",\n    \"Data migration involves adding or modifying data in the database to prevent inconsistencies post-release.\",\n    \"A pre-validation check ensures that migrations do not create inconsistencies in the existing database.\"\n] \n \nClaims:\n[\n    \"Attributes without a default value do not need to be migrated when the implementation is opened for the first time.\",\n    \"Newly added attributes that customers will fill in later do not require migration if they do not have a value in existing implementations.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not provide sufficient information to determine this. Attributes without default values are mentioned to not require migration unless needed, but specifics about the first-time opening of implementations are not available.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.6,
          "reason": "The score is 0.60 because the output acknowledges the documentation's value but misses the mark by not directly addressing the migration of attributes without default values. While the mention of documentation is useful, it doesn't provide a precise answer to the query.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.005487500000000001,
          "verboseLogs": "Statements:\n[\n    \"You do not need to migrate attributes without a default value when opening the implementation for the first time.\",\n    \"Attributes with no expected values for existing implementations do not require migration.\",\n    \"A newly added attribute that will be filled in later by customers does not require migration.\",\n    \"For more details, refer to the documentation.\",\n    \"'Why is this so important?' is linked in the documentation.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Referring to the documentation does not directly address the requirement to migrate attributes.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The statement about a link in the documentation doesn't address the necessity of migrating attributes.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.9,
          "reason": "The retrieval context includes all key elements from the context, such as the necessity of migration and the compact database feature in Skye 7. It provides additional value with details on default and migration value parameters. However, it lacks a direct link, which affects its completeness.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.00814,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if RETRIEVAL_CONTEXT contains all key elements present in CONTEXT.\",\n    \"Ensure RETRIEVAL_CONTEXT includes a link as expected.\",\n    \"Verify that the retrieval context logically aligns with and enhances the reference context without omitting any critical information from CONTEXT.\",\n    \"Analyze extra content in RETRIEVAL_CONTEXT to ensure it provides additional value without causing confusion.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.7,
          "reason": "The actual output aligns with the expected output regarding not migrating attributes without default values. The link provided is relevant, but the actual output lacks specific version comparison mentioned in expected output and compact database detail.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.00276,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the actual output and expected output for similarity in content and context.\",\n    \"Check if the actual output includes a link to documentation; verify the relevance of the link.\",\n    \"Ensure the actual output does not contain any contradicting information compared to the expected output.\",\n    \"Assess if the actual output contains additional information that supplements the expected output without contradiction.\"\n]"
        }
      ],
      "runDuration": 7.226452791997872,
      "evaluationCost": 0.028540000000000003,
      "order": 1
    },
    {
      "name": "test_customer_chatbot[test_case2]",
      "input": "Where can I find the audit trail logs?",
      "actualOutput": "You can find the audit trail logs in the Skye runtime filesystem, where they are written to an audit-trail log file. Additionally, if configured, audit log data may also be sent to Graylog. \n\nFor more detailed information on how to view and configure the audit trail logs, you can refer to the following documentation links:\n\n1. [Technical Audit Trail](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1950122344)\n2. [Audit trail possibilities](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1949892763)\n3. [Logs](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2455732341)\n\nMake sure to check the log configuration in the Admin console to ensure that the audit trail logging is properly set up.",
      "expectedOutput": "- Log4j prints it to a separate audit trail log file, in the skye runtime file system\n- It can be configured via log4j to also add it to putty and graylog logs by setting the \u201cadditivity\u201d to true (this is not an option via admin console)",
      "context": [
        "# View audit log\n\nAudit trail information is printed by Log4j logger \"skye.audittrail\" using log level INFO.\n- It produces log lines in the following format:\nAttribute <attribute full text-id path> on implementation <implementation UUID> changed value from <old value> to <new value> at <modification timestamp> by <user role> user <username>.\n\n- Example:\nAttribute 'Home.Product.Package' on implementation '8d46aeb7-5af5-421d-a906-c475ccd9314f' changed value from 'super' to 'standard' at 2021-03-04T14:16:52.486Z by 'callcenter' user 'usercc'.\n\nBy Skye deployment default, audit log data is written to an audit-trail log file on Skye runtime filesystem.\nUpon request, audit log data may also be sent to Graylog. Audit logs may contain sensitive user data, therefore setup in Graylog requires fine-grained user access permission configuration in Graylog.\n\n# Log4j overview\n\nlog4j is a reliable, fast and flexible logging framework. It is highly configurable through external configuration files at runtime. \nIt views the logging process in terms of levels of priorities and offers mechanisms to direct logging information to a great variety of destinations, such as a database, file, console, UNIX Syslog, etc.\n\nlog4j has three main components:\n   - loggers: Responsible for capturing logging information.\n   - appenders: Responsible for publishing logging information to various preferred destinations.\n   - layouts: Responsible for formatting logging information in different styles.\nThe log4j2.xml file in folder <tomcat>/conf/skye/config configures the logging behavior of Skye\n\n# Skye log4j configuration\n\nThe log4j2.xml configuration file is located in /opt/tomcat_<appname>/conf/skye/config and is notified with -Dlog4j.configurationFile parameter to Tomcat.All web applications within the Tomcat instance share the same log4j configuration file, i.e. for Skye User Management the webapps skyeum, skye-admin, idp, and sts all share the same file.\n\nThe following chapters describe log4j configuration when debugging some Skye functions, along with example log output. The log4j2.xml configuration file may be adapted manually on a DEV stage for testing and debugging purposes, changes are considered without a Tomcat restart, though still require up to 30 seconds waiting time.\n\nLog examples are displayed to show the output when described loggers are activated. Example log messages contain the log level, the full logger name, and the message"
      ],
      "retrievalContext": [
        "Technical Audit Trail",
        "Audit trail possibilities",
        "# Purpose  \nDefault ways to implement the Technical Audit Trail, which can be read in the log after the implementation and turned on by the admin console and modified the log4j file.",
        "# View audit log  \nAudit trail information is printed by Log4j logger \"skye.audittrail\" using log level INFO.  \nIt produces log lines in the following format:  \n**Audit trail log format**  \n```Attribute <attribute full text-id path> on implementation <implementation UUID> changed value from <old value> to <new value> at <modification timestamp> by <user role> user <username>.```  \nExample:  \n**Audit trail log example**  \n```Attribute 'Home.Product.Package' on implementation '8d46aeb7-5af5-421d-a906-c475ccd9314f' changed value from 'super' to 'standard' at 2021-03-04T14:16:52.486Z by 'callcenter' user 'usercc'.```  \nBy Skye deployment default, **audit log data is written to an audit-trail log file** on Skye runtime filesystem.  \nUpon request, audit log data may also be sent to Graylog. Audit logs may contain sensitive user data, therefore setup in Graylog requires fine-grained user access permission configuration in Graylog.  \nYou can find more details about the log4j configuration of the logs [here](../../operations-guide/log4j.md).",
        "---\ntitle: \"Audit trail\"\n---  \nInnoveo Skye\u00ae provides a functionality to create an audit log that contains the attribute value changes in the application. The audit log data is available in the application logs. The content of the audit log can be configured using the Audit trail model type.",
        "Logs",
        "# Configure audit trail  \nAn audit trail definition must be created for each model text-id where there are any attributes that are part of the audit log.  \nThe attribute value changes will be logged as long as the audit trail definition is activated on the environment.",
        "How to read logs",
        "# Preparation  \n1. Enter in to the Admin console, go to the Log configuration and add the skye.audittrail option to the Log.\n2. Enter the catalina log  \n1. Enter the skyeapp-log4j command\n2. Add the additivity=\"true\" parameter to the skye.audittrail logger line\n3. **In order for these logs to be visible in Graylog, a ticket must be submitted to the Infra team.**\n3. We need to have a Product or Generic definition which is prepared for to work. In Our case we have a CustomerGentric Definition with some basic details.\n4. Create a Audit trail definition and select the definition Model text-id whose changes you want to log.",
        "# What is Graylog  \nGraylog is a log management solution and you are able to search, view and export historical logs for your stages.  \nA full, official documentation of Graylog is available here (latest version): <https://docs.graylog.org/en/3.3/>",
        "# History panel  \nThe history panel audit trails all changes made for a selected definition.",
        "Log of Transactions",
        "## Audit trailed attributes  \nDefine which attributes from the selected model-text id should be part of the audit log.  \nThere are 3 options:  \n**All attributes**  \nAll attributes from the selected definition will be included in the audit trail.  \n**Include selected attributes**  \nThe list of audit trailed attributes can be explicitly specified by adding them to the list.  \n![screenshot](https://confluence.innoveo.com/is914/files/158605619/158605620/1/1711440772000/image2023-1-30_9-57-32.png)  \n**Exclude selected attributes**  \nAll attributes from the selected definition will be in the audit trail except the ones specified in the list.",
        "# Background:  \nThis guide describes the way you can check the log (called Import Summary) of an import event.",
        "# Purpose  \nThis section contains all we can share about logs in Skye. How to find them, how to read them, and how to gather metrics from them.",
        "# Skye implementation  \n## All attributes  \nThis option is not recommended for definitions with many attributes, as it may result in a stack overflow.  \n1. Select the All attributes option in the Audit trail definition\n2. Create an implementation or modify any attribute value on a all ready exist implementation.\nIn one exemple I sart to create a new implementation and filled in two parameters on the screen.\n3. In the log you can se the following log messages:\n2023-11-09 11:43:30,661 [http-nio-8443-exec-1] Test INFO audittrail - ***Attribute 'CustomerGeneric.MainDetails.Type' on implementation '32f262b9-8979-4539-b0dd-aaf122dfa442' changed value from '' to 'Persone' at 2023-11-09T11:43:30.661Z by 'callcenter' user 'Test'.***\n2023-11-09 11:44:19,655 [http-nio-8443-exec-4] Test INFO audittrail - ***Attribute '***[***CustomerGeneric.MainDetails.Name***](http://CustomerGeneric.MainDetails.Name)***' on implementation '32f262b9-8979-4539-b0dd-aaf122dfa442' changed value from '' to 'Bart Carroll' at 2023-11-09T11:44:19.655Z by 'callcenter' user 'Test'.***  \nAudit trail log format:\n`Attribute <attribute full text-id path> on implementation <implementation UUID> changed value from <old value> to <new value> at <modification timestamp> by <user role> user <username>.`",
        "## Model text-id  \nDefine the model text-id from which the attributes of the implementations should be audit trailed when creating the audit trail definition. In case attributes from multiple models should be audit trailed, multiple audit trail definitions must be created.  \n![screenshot](https://confluence.innoveo.com/is914/files/158605619/158605621/1/1711440772000/image2023-1-30_9-53-42.png)",
        "## Listing logs for different time-frames  \nYou can list logs for a specific time-frame by clicking the clock icon.",
        "# What to check  \n* Skye application logs\n* Business Canvas logs\n* Does it happen with all definitions? One definition?\n* Does it happen with all users? Or only some?",
        "### Capture event  \nAfter logs are enabled analysis can start. If a case is observed it should be possible to the get `uuid` of the implementation that is causing the CUE.  \n1. Identify all `traces` that changed the CUE implementation  \nThe first step is to identify all requests within a given time frame that changed this implementation. The time frame depends on the scenario. Some pointers how to select the correct time window.  \n* typically, it's not more than what the longest request would take, i.e. <30 sec before the request\n* there are also cases (browser window left open and activity resumed at a much later stage) where the time window has to be increased  \nThe log that can used for this task is `skye.core.database`. There is a dedicated field `implementation_uuid` that can be used as filter. From here you will get all `trace_id`s that changed the implementation  \n1. Output all logs for the given traces  \nThis can be done by simply filtering for the `trace_id`s identified in step 1. Here it's important to reduce the log to the essentials. Most of the time that includes only `ERROR` logs and logs from `skye.core.database` and `skye.performance.http`."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because no contradictions were present, indicating that the actual output is perfectly aligned with the retrieval context. This demonstrates a commendable level of accuracy and consistency in the provided information.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0137525,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Log4j logger \"skye.audittrail\" is utilized to print audit trail information.\",\n    \"Audit trail log format documents attribute changes by displaying the old and new values, the modification timestamp, and the user role and username responsible for changes.\",\n    \"The audit trail logs can be written both to an audit-trail log file on Skye's runtime filesystem and to Graylog.\",\n    \"Graylog is described as a log management solution for searching, viewing, and exporting historical logs.\",\n    \"The activation of an audit trail definition will lead to the logging of attribute value changes relevant to the audit log for a specific model text-id.\",\n    \"Audits trail all changes made for a selected definition within the history panel.\",\n    \"There are three options for defining which attributes are included in the audit log: all attributes, include selected attributes, and exclude selected attributes.\",\n    \"The audit trail logs might contain sensitive user information.\",\n    \"The log example provided displays a change from 'super' to 'standard' by a call center user \"usercc\".\",\n    \"Setting up Graylog requires a specific configuration of user access permissions.\",\n    \"A log entry example from \"2023-11-09\" reflects a change by a call center user named \"Test\".\",\n    \"Defining the model text-id is essential to determining which attributes should be part of an audit log.\"\n] \n \nClaims:\n[\n    \"You can find the audit trail logs in the Skye runtime filesystem, where they are written to an audit-trail log file.\",\n    \"If configured, audit log data may also be sent to Graylog.\",\n    \"For more detailed information on how to view and configure the audit trail logs, you can refer to specific documentation links.\",\n    \"You should check the log configuration in the Admin console to ensure that the audit trail logging is properly set up.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": false,
          "score": 0.3333333333333333,
          "reason": "The score is 0.33 because while the output attempts to guide on how to find the audit trail logs, it fails to provide a direct answer to their specific location. The output includes statements that diverge into providing additional insights or suggesting where to look, which ultimately don't sufficiently address the core question.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.007357500000000001,
          "verboseLogs": "Statements:\n[\n    \"Audit trail logs are located in the Skye runtime filesystem.\",\n    \"Logs are written to an audit-trail log file.\",\n    \"Audit log data may also be sent to Graylog if configured.\",\n    \"Detailed information on audit trail logs can be found in provided documentation links.\",\n    \"Check the following documentation links for more details:\",\n    \"Technical Audit Trail documentation provides more insights.\",\n    \"Audit trail possibilities are further detailed in the available documentation.\",\n    \"The Logs documentation link offers additional information.\",\n    \"Ensure log configuration in the Admin console for proper setup.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The statement points to where additional information can be found, but does not directly specify the location of the logs.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"It suggests where to look for more information, without directly pointing out the location of the logs.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Offers insights, but does not directly indicate where the audit logs are found.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Indicates that detailed information is available, but not the specific location of the logs.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Refers to where to find detailed information, rather than the logs themselves.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Mentions configuration needed for proper setup, but does not directly address the log location.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.9,
          "reason": "RETRIEVAL_CONTEXT includes all essential elements from CONTEXT, including the audit log format and example, Skye deployment defaults, and mention of Graylog setup. It contains valid link references and additional relevant information that aligns with CONTEXT. The only minor issue is the redundant emphasis on the steps to enable logs, which slightly duplicated information already covered.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0085825,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if the essential elements from CONTEXT are present in RETRIEVAL_CONTEXT.\",\n    \"Verify that RETRIEVAL_CONTEXT includes a valid link.\",\n    \"Evaluate if RETRIEVAL_CONTEXT has additional relevant information that does not contradict CONTEXT.\",\n    \"Ensure the information in RETRIEVAL_CONTEXT aligns logically with the reference CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.8,
          "reason": "The core content aligns as both mention audit trail logs in the Skye runtime and Graylog configuration. Links to documentation are provided, which is expected. The extra information about the Admin console contradicts slightly as it states 'not an option' in the Expected Output, but this does not alter the intended result.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0033450000000000003,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the core content of the ACTUAL OUTPUT and EXPECTED OUTPUT to assess alignment and completeness.\",\n    \"Verify that the ACTUAL OUTPUT contains a link to documentation as expected.\",\n    \"Ensure that any extra information in the ACTUAL OUTPUT is relevant and does not contradict the EXPECTED OUTPUT.\",\n    \"Identify any discrepancies and confirm they do not alter the intended result of the EXPECTED OUTPUT.\"\n]"
        }
      ],
      "runDuration": 7.604330999998638,
      "evaluationCost": 0.033037500000000004,
      "order": 2
    },
    {
      "name": "test_customer_chatbot[test_case3]",
      "input": "How can I check the indices\u00a0 and extract them to another file format?",
      "actualOutput": "To check the indices and extract them to another file format, you can follow these steps:\n\n1. **Check Available Indices**:\n   - Use SSH to connect to the appropriate stage (e.g., Hamilton stage, DEV environment) using a command like:\n     ```bash\n     ssh app01.dev.int.hamilton.innoveo-skye.net\n     ```\n   - Once connected, run the following command to list all available indices:\n     ```bash\n     curl -X GET \"localhost:9200/_cat/indices\"\n     ```\n\n2. **Extract Indices**:\n   - To extract the indices, you can use the Index Management API or the File builder API to export the index as CSV. Note that exporting might perform poorly under heavy load.\n   - For exporting, you can refer to the documentation on how to use the File builder API for exporting indices.\n\n3. **Convert to Desired Format**:\n   - If you need to convert the extracted index to another format (like JSON), you can use a conversion tool. For example, you can upload the downloaded index file to the [Index Converter](https://indexconverterlinux.azurewebsites.net/) to convert it to CSV or JSON.\n\nFor detailed instructions, you can refer to the following documentation links:\n- [Check Indices](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2153021456)\n- [Index Management API](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2279931907)\n- [Exporting Indices](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2014838938) \n\nThese resources will provide you with the necessary steps and tools to check and extract indices effectively.",
      "expectedOutput": "- mention multiple ways to check indices: admin console, API call, putty\n- give a high level explanation of how commands exist for checking index contents, copying them into folders on your computer, etc.\n- mention the index converter\n- be ready to elaborate on parts the user is interested in, based on the link in the next cell",
      "context": [
        "# Step 0: Indentify the indexes\n\nWhen referring to indexes, we're discussing a dataset uploaded in CSV format via the Admin console. As there's no out-of-the-box method to download it, I'll show you the steps.\nOpen Putty, connect to the bastion host (jump host), and SSH to the stage you'd like to use. In this example i\u2019m going to use Hamilton stage, DEV environment.\n$ ssh app01.dev.int.hamilton.innoveo-skye.net\n\nYou need to identify which index or indexes you'd like to save. To check all available indexes, run the following command:\n$ curl -X GET \"localhost:9200/_cat/indices\"\n\nIf you are facing a problem or getting a \u201cConnection refused\u201d or \u201cCouldn't connect to server\u201d error, please switch user.\n$ sudo su - stagenamedev1a\n$ curl -X GET \"localhost:9200/_cat/indices\"\nstagename - Your Skye stage name, for example: everestredev1a or hamiltondev1a\ndev1a - Refers to the environment. If you connected to dev, it's dev1a. If you connected to UAT or SIT, it's uat1a or sit1a, respectively.\n\nfor example:\nI\u2019m connected to Hamilton stage, DEV environment.\n$ sudo su - hamiltondev1a\n$ curl -X GET \"localhost:9200/_cat/indices\"\nPlease note that, depending on the stage, the full index name will follow the following pattern: 'stagenamedev1a_indexname'. Hence, you will need to refer to them in this way.\n\n# Step 3: Download the index(es) and save it to your local computer\n\nSimply execute the following command:\n$ curl -X GET \"localhost:9200/full_index_name/_search?pretty&size=10000\" >> input.txt\nfor example:\n$ curl -X GET \"localhost:9200/hamiltondev1a_prodcops/_search?pretty&size=10000\" >> input.txt\nBy using this command, we create a file named 'input.txt' in the stage's storage. It will be located in your default home directory, which corresponds to your Putty username. \n\nFor instance, in my case, it's 'inncssa' at /home/inncssa.\nYou can \u201cvim\u201d or \u201ccat\u201d to check if the file that we created actually is what we are looking for.\n$ vim /home/yourputtyusername/input.txt or cat /home/yourputtyusername/input.txt\nfor example:\n$ vim /home/inncssa/input.txt or cat /home/inncssa/input.txt\nIn order to download this to your local computer you need to set a tunnel and connect to WinSCP ->(more info how to do that: How to connect to a stage with WinSCP and copy log files or How to connect with WinSCP to a stage)\n\n# Step 4: Convert the downloaded index to CSV and JSON\n\nVisit the following site: https://sallai.tech/indexconverter ( I created a Flask web app to handle the raw JSON format, convert it back to CSV, or provide the formatted clean JSON version)\n- Upload the \u201cinput.txt\u201d you have downloaded \u2192 \n- Click \u201cProcess\u201d \u2192 wait a couple of minutes\n- Download either the CSV or the JSON or both"
      ],
      "retrievalContext": [
        "Extract index as JSON",
        "## Creating an index from a CSV file  \nThe following steps describehow to create an index by uploading a CSV file using the Admin console.  \n| Step | Description |\n| --- | --- |\n| 1 | In the Admin console select the 'Indexes' menu item. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609726/1/1718367266000/image2024-6-11_12-28-48.png) |\n| 2 | Click the \"New index\" button at the upper right corner of the table. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609725/1/1718367266000/image2024-6-11_12-34-2.png) |\n| 3 | Click the upload button, or drag and drop a CSV file in the marked area within the panel. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609724/1/1718367266000/image2024-6-11_12-36-29.png) |\n| 3 | (Optional) The index name is automatically set. Edit the index name, if you would like to change it before creating the index.![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609721/1/1718367266000/image2024-6-11_12-41-16.png) <br> {{< callout type=\"info\" >}}**Note**: If there is already a index with the specified index name and index version, it will be **replaced** by the content of the uploaded CSV file.{{< /callout >}} |\n| 4 | (Optional) If you wish to upload a version of an already existing index, choose the 'New versioned index' option and specify the version name. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609722/1/1718367266000/image2024-6-11_12-40-1.png) |\n| 5 | Click on \"Create index\" to upload the selected CSV file. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609720/1/1718367266000/image2024-6-11_12-42-7.png) |\n| 6 | After clicking the 'Create index' button, the index will be created. The duration of the index creation varies and depends on the number of records in the CSV file. Once complete, the index is displayed in the \"List of uploaded indexes\" table including the index name, the CSV file used, the user uploading and the last modified date. ![screenshot](https://confluence.innoveo.com/is915/files/158609716/158609719/1/1718367266000/image2024-6-11_12-43-24.png) |",
        "# Create and remove an index  \nThe Admin console is the primary method for creating indexes from CSV files.  \nFind more information at [Data source attribute](../user-guide/attributes/specialized/data-source.md) about the following topics:  \n- What is an index and how to use it\n- Correct index preparation\n- Language-specific search columns\n- Other ways to create indexes",
        "# Purpose  \nThis page aims to provide a detailed guide on how to download indexes from the APP/UM & how to format & convert it to CSV/JSON.",
        "# Step 4: Convert the downloaded index to CSV and JSON  \n* Visit the following site: [Index Converter - Upload File (indexconverterlinux.azurewebsites.net)](https://indexconverterlinux.azurewebsites.net/) ( I created a Flask web app to handle the raw JSON format, convert it back to CSV, or provide the formatted clean JSON version )\n* Upload the \u201cinput.txt\u201d you have downloaded \u2192  \n* Click \u201cProcess\u201d \u2192 wait a couple of minutes\n* Download either the CSV or the JSON or both  \nYou can create a back up or you can re-upload the converted index to your Skye stage.",
        "### Create indexviaCSV upload  \nTo create an index via CSV upload you need to proceed with the following three steps:  \n1. [Prepare CSV](#prepare-csv)\n1. [Upload CSV](#upload-csv)\n1. Create and configure[flexdata-single attribute](./flexdata-single.md) or [flexdata-multi attribute](./flexdata-multi.md) accordingly  \n##### **Prepare CSV**  \nEvery entry displayed in the flexdata attribute corresponds to one row in a CSV that you have to prepare for the flexdata attribute. The file must contain at least one column, that has unique values. This column should be used as the ID of the index entries (Id field of the Datasource attribute). As additional columns you need the one that will be displayed in the screen and if needed you can add other columns that can be mapped to other attributes when selecting one entry.  \nExample:  \n![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604183/1/1711440396000/image2014-1-8+8%3A48%3A27.png)  \n| Column | Description |\n| --- | --- |\n| id | Corresponds to the postal code of every city and can be mapped to the attribute \"postalCode\" when selecting the corresponding entry |\n| city | Can be mapped automatically when selecting the corresponding entry |\n| postalCodeCity | Concatenation of postal code and city which is used to be displayed in the screen |\n| country | Can be mapped automatically when selecting the corresponding entry |  \nPlease check[here](#current-behavior) for not supported functionality.  \n##### **For datasource with constraints**  \nIf constraints are set on the data source and they should be compared using a data type other than string, it is mandatorythat the data type is specified in the CSV to increase the searcher performance  \n- The data type is specified in the field header after a ':' e.g  \n![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604194/1/1711440396000/image2017-7-31+9%3A35%3A43.png)  \n- The data types which can be defined in the field header are:\n- Integer\n- Decimal\n- String\n- Date\n- Timestamp\n- The data types are case insensitive\n- If there is no :`<DataType>` then string will be used as default\n- If after the ':' one of these data types there is an invalid text (not integer, decimal, string, date, timestamp) then on upload of CSV there is a server exception\n- The formats allowed for data type \"Date\" are:\n- yyyyMMdd\n- yyyy.MM.dd\n- yyyy/MM/dd\n- yyyy-MM-dd\n- The formats allowed for data type \"Timestamp\" are:\n- yyyyMMdd HH:mm:ss\n- yyyy.MM.dd HH:mm:ss\n- yyyy/MM/dd HH:mm:ss\n- yyyy-MM-dd HH:mm:ss  \nPlease check [here](#current-behavior) for not supported functionality.  \n##### **Encoding**  \nThe CSV file that is uploaded to create a new index needs to be UTF-8 encoded. Otherwise special characters are not properly displayed.  \nUnlike with previous versions, since Innoveo Skye 6.3.0 both UTF-8 with and without BOM are supported.  \n##### **Language specific search columns**  \nIt is possible to have language specific suggestion, sorting and single search fields. To use this feature please proceed with the following steps:  \n1. For every language specific column, enter one column per language. The column headers must all follow the format:\n- {columnName}_{language}_{country}\nwhere\n- {columnName} is the one that is used in the fields of the flexdata attributes to specify thesuggestion / sorting / search field and is therefore the same for all those columns.  \n- {language}_{country} is the locale for which this column should be taken into account\nExample: en_us, de_ch  \n**Example**:  \n![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604184/1/1711440396000/image2014-12-29+13%3A10%3A59.png)  \n1. On the flexdata-single attribute in the property \"Label field\", \"Sorting fields\" and in the value of the backend info \"LuceneIndexFreeTextSearchSingleField\" enter only the {columnName}.  \n**Example**:  \n![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604195/1/1711440396000/image2018-2-17_13-39-8.png)  \n##### **Upload CSV**  \nThe CSV file can be uploaded using the [Admin console](../../../admin-console/_index.md). You can find the detailed step in[Creating indexes](../../../admin-console/creating-indexes.md).",
        "# PoC - how to use  \nAttached IndexVisualizationWithExport.zip contains the definition set.  \nThis section explains the different definitions of the PoC definition set. This definition set cannot be used on its own and must be added to your project.  \nExport is using File builder API (CSV)\ud83d\udcce to export index as CSV which might perform badly under heavy load (refer linked IPH page on recommendations)",
        "### Errors file  \n**Filename:** 'Location of files'/'File name (Error file)''Timestamp suffix'.csv  \nIf some errors occur during the task, an error file is produced. The file has the same structure as the details file and displays all the roots for which deletion failed.",
        "# Step 0: Indentify the indexes  \nWhen referring to indexes, we're discussing a dataset uploaded in CSV format via the Admin console. As there's no out-of-the-box method to download it, I'll show you the steps.  \nOpen Putty, connect to the bastion host (jump host), and SSH to the stage you'd like to use.\nIn this example i\u2019m going to use Hamilton stage, DEV environment.  \nbashssh app01.dev.int.hamilton.innoveo-skye.net  \nYou need to identify which index or indexes you'd like to save. To check all available indexes, run the following command:  \nbashcurl -X GET \"localhost:9200/\\_cat/indices\"  \n**If you are facing a problem or getting a \u201cConnection refused\u201d or \u201cCouldn't connect to server\u201d error, please switch user.**  \nbashsudo su - stagenamedev1a\ncurl -X GET \"localhost:9200/\\_cat/indices\"  \n**stagename** - Your Skye stage name, for example: **everestredev1a** or **hamiltondev1a**  \n**dev1a** - Refers to the environment. If you connected to dev, it's **dev1a**. If you connected to UAT or SIT, it's **uat1a or sit1a**, respectively.  \nfor example:\nI\u2019m connected to Hamilton stage, DEV environment.  \nbashsudo su - hamiltondev1a\ncurl -X GET \"localhost:9200/\\_cat/indices\"  \nPlease note that, depending on the stage, the full index name will follow the following pattern: '**stagenamedev1a\\_indexname**'. Hence, you will need to refer to them in this way.",
        "### Details file  \n**Filename:**'Location of files'/'File name (Details file)''Timestamp suffix'.csv  \nIt includes the following information:  \n- **General structure:** level, text-id, model type and UUID\n- **Additional columns:** All the attributes configured in the list 'attributes to details file' will be exported to the details file. The column ordering is defined through the order of the list.",
        "# Use plug-and-play component  \nThe downloadable component is available for **Skye 9.11 or newer** versions.  \nImport the definitions from Attachment section to start using the Index Management API.",
        "## Data source attribute properties  \n![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604161/1/1711440395000/image2023-6-9_8-20-23.png)  \n| Property | Description |\n| --- | --- |\n| Data source | Defines how the [index](#how-to-create-an-index) is created: <br><br> **[CSV upload](#create-index-via-csv-upload)** <br> The index is created by uploading a CSV file with different columns in the admin console. <br> <br> **[Event](#create-index-via-create-index-event)** <br> The index is created via web service which is invoked via a \"Create index by web service event\". <br> <br> **Web service** <br> The index is created via web service (not transient). <br> <br> **[On the fly by web service](#create-index-on-the-fly-via-web-service)** <br> The index is created transiently via web service whenever the service attribute's value is set to true. <br> <br> **[Data Table](#data-table)** <br> The data table enables the user to create their own value ranges or data table |\n| Index name | Name of the index to be displayed. If the index is created via CSV upload, the index name is defined when uploading. If the index is created via \"create index event\", the index name is defined on the event definition in the attribute@SearchIndexName. <br> This field is not needed in case of creating the index on the fly by web service. |\n| Reduce index fields | If this option is selected, a list of fields must be specified that are part of the reduced index. This means that only those fields will be available in the Data source and that the duplicate records in the reduced index will be filtered out automatically. Find more information about reduce index [here](#reduced-index). |\n| Service attribute | Defines the web service invoker service attribute, which should be used to invoke the web service in order to create the transient index. |\n| Id field | Defines the name of the index field to be used as record id. The value contained in this field will be stored as value for this attribute when an entry is selected.<br> <br> The Id field must always be unique. <br> <br> It is highly recommended to define an index id field in order to avoid language specific values. Especially if the suggestion fields are language specific, another field should be used as value. |\n| Get data from an index version | When an index has multiple versions it is possible to user the data from a specific index version. <br> <br> When this option is not selected, the unversioned index entries will be used. |\n| Version name | Specifies the index version to be used. |\n| Constraints | Constraints can be defined to filter the values of a field of the index file or the data table. Multiple constraints are possible and these are treated with an AND condition. <br> <br> Creating a constraint, it is required to specify a field, an operator and a value. <br> <br> The operators which are available are as follows: <ul><li>Equals</li><li>Not equals</li><li>Greater</li><li>Greater or equals</li><li>Smaller</li><li>Smaller or equals</li><li>Contains</li><li>Not contains</li><li>Is value of (###)</li><li>Is not value of (###)</li><li>Is value of (`;`)</li><li>Is not value of (`;`)</li></ul> <br> All operators consider the values as strings. <br><br> **Example:** <br><br> ![screenshot](https://confluence.innoveo.com/is914/files/158604160/158604164/1/1711440395000/image2018-2-17_13-54-38.png) <br> <br> This would return only index entries containing values greater than 1997 from the field REG_YEAR of the index file or data table |",
        "Index Management API\ud83d\udcce",
        "Visualize index content\ud83d\udcce",
        "## Configure the CSV file and the transformation definition  \nFind [here](./transformation-and-csv.md) the details on how the CSV file and the transformation definition must be configured.",
        "## Configure the CSV file and the transformation definition  \nFind [here](./transformation-and-csv.md) the details on how the CSV file and the transformation definition must be configured.",
        "## Configure the CSV file and the transformation definition  \nFind [here](./transformation-and-csv.md) the details on how the CSV file and the transformation definition must be configured.",
        "### Response mapping into the index  \nIn order to identify the list object that will be converted into an index (each element of the list will be an entry in the index) we need to add the following configuration to the transformation specific for \"Index creation transformations\"  \n| Control attribute | Description | Mandatory | Example value |\n| --- | --- | --- | --- |\n| @IndexSourceListPath | Defines the XPath of the list element in the response object to be used to create the index. | Yes | /banks  |  \nEvery element in the list defined by the attribute above will be transformed into an entry of the index to be created, each field of the objects in the list, will be a field in the index entry with the same name.",
        "# Future implementation  \nTo make it easier, in the future, you can just provide your index name, and just connect to the stage with a tunnel, and you can download any indexes from ES\u2026",
        "## What is an Index  \nAn index can be seen as a table, where each entry of the table (each row) is called document, and each document has a set of fields (they would actually be the columns of the table).One of the fields of the document can be identified as key or id field.  \nIt is possible to use an index for searching purposes, or as an intermediary data structure to be converted into a value range when required. An index can be persistent (stored in the file system), or transient (only in memory), in which case will only be available temporary in the scope of the session of the user for which was created."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 0.8571428571428571,
          "reason": "The score is 0.86 because while the retrieval context does not mention the use of the Index Management API or File Builder API for exporting indices to CSV, the overall alignment between the actual output and the context is quite strong, indicating a generally faithful representation.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.023585000000000002,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The process for creating an index involves uploading a CSV file using the Admin console.\",\n    \"To create a new index, select the 'Indexes' menu item in the Admin console.\",\n    \"An index can be created by clicking the 'New index' button in the Admin console.\",\n    \"An option exists to upload a CSV file by dragging and dropping it into a marked area in the panel.\",\n    \"If an uploaded CSV file has a name and version that already exist, it will replace the existing index content.\",\n    \"The uploaded index creation time depends on the number of records in the CSV file.\",\n    \"Once an index is created, it is listed in the 'List of uploaded indexes' table with details such as the index name, uploaded CSV file, user, and last modified date.\",\n    \"The index process includes uploading a CSV file to the server, where it must be UTF-8 encoded.\",\n    \"The admin console is primarily used for creating indexes directly from CSV files.\",\n    \"Indexes are not downloaded directly but can be processed using a Flask web app to convert between JSON and CSV formats.\",\n    \"The flexdata attribute in a CSV file requires at least one unique value column, used as the ID of the index entries.\",\n    \"The system supports multiple data types in CSV headers, such as Integer, Decimal, String, Date, and Timestamp.\",\n    \"CSV files uploaded for creating indexes must be UTF-8 encoded for proper display of special characters.\",\n    \"The index name can be automatically set or edited manually before the index creation.\",\n    \"Language-specific search columns can be specified in the CSV headers.\",\n    \"Indexes have properties such as data source type, index name, id field, and version name.\",\n    \"Indexes can be transient or persistent, with persistent ones being stored on the file system.\",\n    \"The Admin console can upload and manage indexes, with support for both event-driven and web service-created indexes.\",\n    \"Indexes act as data tables for storing and searching documents, which are individual entries in the index.\"\n] \n \nClaims:\n[\n    \"To check available indices, connect to the appropriate stage using SSH.\",\n    \"Use the command 'curl -X GET \"localhost:9200/_cat/indices\"' to list all available indices.\",\n    \"Use the Index Management API or the File builder API to export indices as CSV.\",\n    \"Exporting indices might perform poorly under heavy load.\",\n    \"You can convert extracted index to another format using a conversion tool such as the Index Converter.\",\n    \"To convert indices, upload the downloaded index file to the Index Converter website for conversion to CSV or JSON.\",\n    \"Documentation links provide detailed instructions for checking and extracting indices.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim suggests a method to check available indices but does not contradict any information in the given context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim provides a specific technical command and does not contradict the context.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The context does not mention that the Index Management API or File builder API are used for exporting indices as CSV.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim about exporting indices performing poorly under load is not covered in the context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The provided claim gives a general advice about using a conversion tool but this is neither confirmed nor denied by the context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim about using the Index Converter website for conversion does not find a direct contradiction in the context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim suggests the existence of documentation links for detailed instructions, which is outside the provided context.\"\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.6363636363636364,
          "reason": "The score is 0.64 because the answer partially addresses the task of checking and extracting indices. However, it includes irrelevant information about SSH connections and general server management, which is not directly related to the question asked.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.008180000000000002,
          "verboseLogs": "Statements:\n[\n    \"To check the indices, use SSH to connect to the appropriate stage.\",\n    \"Use the command: ssh app01.dev.int.hamilton.innoveo-skye.net to connect via SSH.\",\n    \"Run the command: curl -X GET 'localhost:9200/_cat/indices' to list all available indices.\",\n    \"You can extract indices using the Index Management API or the File builder API.\",\n    \"Exporting might perform poorly under heavy load.\",\n    \"You can use a conversion tool to convert the extracted index to another format like JSON.\",\n    \"Upload the downloaded index file to the Index Converter to convert it to CSV or JSON.\",\n    \"Refer to provided documentation links for detailed instructions.\",\n    \"The Check Indices link provides necessary steps for checking indices.\",\n    \"The Index Management API link is for managing indices.\",\n    \"The Exporting Indices link offers guidance on exporting indices.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"SSH connection is a setup step, not directly related to index checking or extraction.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Provides information on how to connect to a server via SSH, not relevant to checking or extracting indices.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"General information, not specific to checking or extracting indices.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"A general reference to managing indices, not directly about checking or extracting them.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.4,
          "reason": "RETRIEVAL_CONTEXT is missing a direct link, incomplete representation of key information about using Putty and SSH from CONTEXT, and lacks detailed steps for downloading indexes. However, there is a mention of converting index to CSV and JSON related to CONTEXT.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.015027500000000001,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Verify if RETRIEVAL_CONTEXT includes a link; if not, flag as incomplete.\",\n    \"Check that all key information from CONTEXT is accurately represented in RETRIEVAL_CONTEXT.\",\n    \"Identify any discrepancies between CONTEXT and RETRIEVAL_CONTEXT, noting any missing elements that should have been included.\",\n    \"Assess whether RETRIEVAL_CONTEXT adds relevant and appropriate additional information beyond what is found in CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.7636828033347336,
          "reason": "The Actual Output provides methods to check and extract indices and mentions the index converter as required. It includes links to documentation, which adheres to step 2 of the evaluation. However, it only mentions SSH and API call for checking indices but not the admin console or putty, and lacks high-level explanations for certain tasks outlined in the Expected Output.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.003675,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare Actual Output to Expected Output to assess similarity and completeness.\",\n    \"Check if Actual Output includes a link to documentation.\",\n    \"Ensure additional information in Actual Output does not contradict Expected Output.\",\n    \"Verify that Actual Output either matches or exceeds Expected Output in terms of information richness, without contradictions.\"\n]"
        }
      ],
      "runDuration": 16.99044170900015,
      "evaluationCost": 0.0504675,
      "order": 3
    },
    {
      "name": "test_customer_chatbot[test_case4]",
      "input": "Why am I not able to see in the logs the requests and responses of my APIs?",
      "actualOutput": "If you are unable to see the requests and responses of your APIs in the logs, there are a few potential reasons and solutions to consider:\n\n1. **Logger Configuration**: Ensure that the appropriate loggers are enabled for capturing HTTP requests and responses. For example, you should have the logger for HTTP integration set to DEBUG level:\n   ```xml\n   <logger name=\"skye.integration.http\" level=\"DEBUG\">\n       <AppenderRef ref=\"GELF\"/>\n   </logger>\n   ```\n   This configuration allows you to capture detailed logs for HTTP transactions.\n\n2. **Trace and Session IDs**: Make sure that you have enabled `trace_id` and `session_id` in your logging configuration. This helps in tracking logs related to specific requests and user sessions. For example:\n   ```xml\n   %X{trace_id}\n   %X{session_id}\n   ```\n\n3. **Log Level**: Check if the log level for the relevant categories is set correctly. For example, you might want to set `skye.performance.http` to DEBUG to capture all request logs:\n   ```xml\n   <logger name=\"skye.performance.http\" level=\"DEBUG\"/>\n   ```\n\n4. **Graylog Streams**: If you are using Graylog, ensure that the streams are configured correctly to route messages into the appropriate categories. If you do not see any streams, you may need to contact customer support for assistance.\n\n5. **Log Storage**: Verify that the logs are being stored correctly. Sometimes, logs may be written to a specific file or location that you are not monitoring. For webservice logs, check the `catalina.out` file or the log folder at `/opt/rakbankdev1a-data/logs/`.\n\n6. **API Call Issues**: If the API calls are failing (e.g., returning 403 Unauthorized errors), they may not be logged as expected. Check the network tab in your developer tools to see if the requests are being sent and what responses are being returned.\n\nFor more detailed guidance on logging and troubleshooting, you can refer to the relevant documentation:\n- [How to read logs](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1798766629)\n- [Sharepoint troubleshooting](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2039939258)\n- [Logs](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2455732341)",
      "expectedOutput": "If you are unable to see the requests and responses of your APIs in the logs, there could be several reasons for this issue:\n\nLogging Configuration: The logging level for your API requests and responses may not be set to capture the necessary details. You may need to adjust the logging configuration to ensure that the relevant logs are being recorded. For example, you can enable debug logging for specific packages related to your API.\n\nLog Filters: If there are filters applied to your logging system, they might be excluding the logs you are interested in. Ensure that your log queries are correctly set up to include the desired log messages.\n\nLog Storage Location: The logs might be stored in a different location than expected. Make sure you are checking the correct log files or log management system (like Graylog) where the logs are being sent.\n\nAPI Errors: If your APIs are encountering errors before they can log requests and responses, those logs may not be generated. Check for any errors in the application that might prevent logging.\n\nAccess Permissions: Ensure that you have the necessary permissions to view the logs. Sometimes, access restrictions can prevent you from seeing certain log entries.\n\nLog Rotation or Cleanup: If log rotation or cleanup policies are in place, older logs may have been deleted or archived, making it difficult to find the logs you need.\n\nTo troubleshoot this issue further, you can refer to the documentation on how to read logs and configure logging settings: How to read logs and Logs.",
      "context": [
        "# Skye exposed REST services\n\nLogger: skye.integration.http\nFor the REST services exposed by Skye, configured in the Endpoint attribute within the API definition, the log category used is skye.integration.http (like for the httpInvoker attribute).\nUse level INFO for production and DEBUG (detailed) or TRACE (very detailed) for development/test environments.\n<logger name=\"skye.integration.http\" level=\"INFO\" />\n\n# Outgoing web services\n## Request and response logging\n\nOutgoing web service calls are traced with logger \"org.apache.cxf.services...DummyImpl\".  By default, request and response messages of outgoing web service requests are logged into the web service log file. \nWith the following log4j setting, outgoing web service requests/responses would not be logged anymore:\n<logger name=\"org.apache.cxf.services...DummyImpl\" level=\"ERROR\" additivity=\"false\">\n    <AppenderRef ref=\"WEBSERVICE_FILE\"/>\n</logger>\n\n## Logging response body only in case of an exception\n\nThe logger \"skye.integration.webservice.exception.logger\" with log level DEBUG will only print the response body in the logs in case an exception occurred during the web service invocation.\nThe following log4j configuration will print these exception logs in the web service log file.\n<logger name=\"skye.integration.webservice.exception.logger\" level=\"DEBUG\" additivity=\"false\">\n    <AppenderRef ref=\"WEBSERVICE_FILE\"/>\n</logger\n\n## Web service client logging\n\nCalling remote web services are additionally logged by following logger. By default, it is logged into the catalina.out and the profile log file.  \n<logger name=\"skye.integration.webservice.client\" level=\"PROFILE\" additivity=\"true\">\n    <AppenderRef ref=\"PROFILE_FILE\"/>\n</logger>\n\n# Internal API service\n\nLogger: skye.api.internal\nSkye provides internal invoker and internal endpoint services for direct API service calls within Skye application.\nUse level INFO for production and DEBUG (detailed) or TRACE (very detailed) for development/test environments.\nThe following is the default logger setting, which writes to the webservice log file and sends to Graylog:\n<logger name=\"skye.api.internal\" level=\"INFO\" additivity=\"false\">\n            <AppenderRef ref=\"WEBSERVICE_FILE\"/>\n            <AppenderRef ref=\"GELF\"/>\n</logger>\nSet level DEBUG to log request and response body.  "
      ],
      "retrievalContext": [
        "How to read logs",
        "Sharepoint troubleshooting  \nEnable this to get the requests.  \n<logger name=\"com.microsoft.graph\" level=\"DEBUG\">\n<AppenderRef ref=\"GELF\">\n</logger>",
        "### Prepare logs  \n1. Enable `trace_id` for logs  \n*Graylog*  \nIn Graylog all requests should automatically be tagged with a `trace_id`. A `trace_id` allows you to track all logs of a particular request. It's also passed to other services (e.g. when using internal web service calls) which will use the same `trace_id`.  \n*CLI*  \nThe trace_id has to be output as part of the appender configuration with `%X{trace_id}`  \n1. Enable `session_id` for logs  \nThis is important to understand which users are making the requests to better understand the user behaviour from a high level point of view.  \n*Graylog*  \nGraylog automatically tags all logs with the `session_id`  \n*CLI*  \nSimilar to the `trace_id` the `session_id` logging can be enabled by specifying `%X{session_id}` in the appender configuration.  \n1. Enable trace logs for all requests. This is done in this category:  \n`skye.performance.http` set to `DEBUG` or `INFO`. The latter only prints when a request is finished. Sometimes, this makes it challenging to analyze the logs.  \n> *Note* On CLI the default is to write all logs in this category to a dedicated file. It helps to write the outputs for this category to the standard appender. To achieve the desired result different settings for `additivity` can be used.  \n1. Enable trace logs for database operations  \n`skye.core.database` set to `DEBUG`",
        "Logs",
        "## 2. Search for a specific logger.  \n> **Loggers are responsible for capturing logging information.** They **keep track of important events or messages that occur within the system's code**. Skye has **several loggers to capture and track important events or messages, usually separated by specific functionality**.\n>\n> For example, `skye.integration.http` **is used to capture HTTP-related logs**, while `skye.event` is **used to filter event scheduling/task scheduling- based logs**.\n> We can filter logs in Graylog based on any valid and available Skye logger.  \nFor example, if we would like to fetch all the APIs/HTTP transactions  \nMore information about loggers:\n[Configuration file :: Apache Log4j](https://logging.apache.org/log4j/2.x/manual/configuration.html#configuring-loggers)\n[Log4j logging and configuration - Innoveo Skye 9.15](https://confluence.innoveo.com/is915/log4j-logging-and-configuration-158613796.html?searchId=SPPGNF1QT#Log4jloggingandconfiguration-Log4joverview)  \nyamlloggerName:skye.integration.http  \nloggerName*:* `[logger]` means we are explicitly telling Graylog to use this specific logger only. In this case, we would only be able to see the HTTP related logs.  \nTo view all available loggers in Skye, please check `log4j`, or `admin console(log configuration).`  \nYou can use multiple loggers in one query, for example, fetching all the Events alongside the APIs we can use this  \nyamlloggerName:skye.integration.http OR loggerName:skye.event  \n---",
        "### Examples  \n* Listing all messages that are POST requests and include \u201ctook ms\u201d:  \n* Listing messages where tookms field is 115  \n* Listing messages for only 1 node (in case of multi-node architecture), by using \u201csource\u201d field  \n* Listing messages for a given user, \u201cAPIAdmin\u201d (Note: you need to add user to the list of fields first as described above)",
        "# Purpose  \nIf an API is blocked and you cannot call it from outside (you will get 403 Unauthorized error, usually this is done by Infra), you can use the above mentioned solution to bypass the restriction and call that API.",
        "## API management  \nThere is a few things, which is good to know about the API. These information can be useful later.  \n* Who owns the API? Customer or third party\n* Is the API specifically developed for this project or it is a general purpose API?  \n+ If the API is developed for you project, you have a higher change to request changes, but the API might be less stable / reliable.\n* Is it an ongoing / recent development or an existing API?  \n+ If it is an ongoing / recent development you can expect some changes / issues with the system.\n* Is anyone else using the API right now?  \n+ If the server\u2019s capacity is low, another party using the API can impact your work (slow / unavailable API)  \n---  \nIf you have questions, that you usually ask when you analyze an API and not included in the list, feel free to add it, or if you have an example of poor API design / implementation (please *remove all the personal information or any data which would indicate whose API it is*) which can cause challenges for the Skye integration.",
        "# Streams  \nThe Graylog streams are a mechanism to route messages into categories in real time while they are processed.  \nStreams are defined rules that instruct Graylog which messages to route into which streams.  \n* Stream configuration is usually done by the Innoveo Infra team\n* Streams are usually categorized by stage  \nIf you do not see any streams after logging in, ask [Customer Support to help you](https://innoveo.atlassian.net/servicedesk/customer/portal/13/group/62).  \n* Streams are available from the \u201cStreams\u201d tab  \nYou can then enter a stream and see the server logs for a given stage. There are usually 3 categories per stage:  \n* Proxy Access\n* Skye Access\n* Skye Application: You can find the application related logs (e.g. Excel input/output, exposed API request/response) here",
        "Documenting APIs using Swagger",
        "### What are the available logs and streams?  \nThere are 3 logs available in Graylog:  \n* proxy access logs\n* tomcat access logs\n* skye logs  \nThe proxy and tomcat access serve a similar purpose and are mainly the same. In fact the proxy logs are only used if there is an issue with tomcat, otherwise tomcat access logs provide more information.  \nAccess logs log every request, status code, request duration, source IPs and other low level paramters. They can be predominantly used to get a high level overview of:  \n* health of the system by taking a look at the status code distribution (e.g. all request with status code 500 for server errors)\n* performance of the system by taking a look at the request duration distribution (e.g. all requests that take longer than 10s to execute, longer than 60s to execute and will result in timeout on load balancer with standard settings)",
        "Periodical API calls\ud83d\udcce",
        "# Prerequisites  \nBefore you start the analysis, you need the following:  \n* API documentation\n* Sample requests / responses to every API method\n* Test endpoint and credentials  \nThese are quite general and basic needs, if the API provider did not provide them at first, feel free to ask for them. If they are unable or unwilling to provide this in some way, it is an alarming sign. Either the API is not really ready to be used or the provider is not really committed to have this integration.  \nTesting the API during the analysis can help you to quick get answer to your assumption, or it can turn out, that you got credentials but actually they are not working (if you realize this when you would start the configuration this can cause delays)  \nMost common API documentation types:  \n* A Doc or Pdf file / Online document\n* [SwaggerUI](https://swagger.io/tools/swagger-ui/)  \n+ Example: [Petstore API](https://petstore.swagger.io/)\n* Postman API documentation  \n+ Example: [NASA API](https://documenter.getpostman.com/view/35240/SVmtxerV#e9854a64-659a-4fdc-b57e-88ae5c8c8b93)\n* [RESTful API Modeling Language (RAML)](https://raml.org/)  \n+ Example: [Organization API](https://github.com/raml-org/raml-examples/blob/master/defining-examples/organisation-api.raml)\n* [Web Services Description Language (WSDL)](https://www.w3.org/TR/wsdl.html)  \n+ Example: [Calculator API](https://svn.apache.org/repos/asf/airavata/sandbox/xbaya-web/test/Calculator.wsdl)  \nYou may get two of the above mentioned documentation types, because one might be a technical documentation (and hard to read) or has limited options to provide contextual / supporting details.So for a SOAP API, usually you get a WSDL and a PDF file, the WSLD contains the API methods and the structure for the request, but the sequence and other details are described in the supporting PDF.",
        "API integrations",
        "# Webservice logs  \nWebservice logs are stored in the catalina.out from time to time. It is varying on the stage if this is enabled or not. If it is not added to the catalina.out, then you can reach this log in the log folder: */opt/rakbankdev1a-data/logs/*",
        "### Http invokers  \nThese are dummy invokers which must be updated to point to actual services. The workflow is in place, only the URL and request mapping is missing.",
        "# Introduction - What is Swagger  \nSwagger allows us to describe the structure of our APIs so that machines or humans can read them in an industry-standard format. The documentation that can be produced either manually or by importing YAML/JSON file that you already have for your API. The specification asks you to include information like:  \n* What are all the operations that your API supports?\n* What are your API\u2019s parameters and what does it return?\n* Does your API need some authorization?\n* And even fun things like terms, contact information and license to use the API.  \nYou can read more what Swagger is all about [on this page](https://swagger.io/docs/specification/2-0/what-is-swagger/).  \nWith Skye we are able to create exposed REST APIs, Swagger then allows us to document these endpoints in a structured and widely understood manner.",
        "## 3. Filtering for HTTP Request or HTTP Response only  \nFor HTTP Response only:  \nyamlloggerName:skye.integration.http AND \"Http response:\"  \nFor HTTP Request only  \nyamlloggerName:skye.integration.http AND \"Executing HTTP request\"  \n---",
        "## Retrieve operation  \nThe request and response mapping configuration will depend on the action configured for the service, this section explains the request and response mapping for the retrieve operation.  \n![screenshot](https://confluence.innoveo.com/is914/files/158605003/158605012/1/1711440521000/image2022-10-6_16-40-38.png)",
        "# What if my error is not in the list of common errors?  \nIf you are sure that you are using the right link, both the UM and the APP is affected, not even the login pages load, I would recommend to open the network tab in the developer tools and check the request with the same name as the link you are trying to access. First check if the response tab is empty. If it is you might have a server issue, because the server wasn\u2019t able to respond. If you have a response, check the header and the status code there. If it is lesser than 500 you have some problem with the link, the browser, the cookies, the cache, etc. If it is greater or equal that 500 you have a problem with your app."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions found, indicating the actual output perfectly aligns with the retrieval context. Excellent work maintaining consistency!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0189825,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The text explains how to read logs and offers steps for troubleshooting Sharepoint.\",\n    \"Enabling `trace_id` in logs allows tracking of a particular request.\",\n    \"Graylog automatically tags requests with a `trace_id`.\",\n    \"`session_id` logging is important for understanding user behavior.\",\n    \"`skye.performance.http` set to `DEBUG` or `INFO` enables trace logs for all requests.\",\n    \"`skye.core.database` set to `DEBUG` enables trace logs for database operations.\",\n    \"Loggers are entities responsible for capturing and tracking important events or messages within a system.\",\n    \"`skye.integration.http` is used to capture HTTP-related logs in Skye.\",\n    \"`skye.event` is used to filter event scheduling/task scheduling-based logs.\",\n    \"Graylog streams route messages into categories in real-time.\",\n    \"Innoveo Infra team usually configures Stream in Graylog.\",\n    \"Swagger is used to describe API structures for better comprehension by machines or humans.\",\n    \"Swagger documentation includes information like operations supported by the API, required parameters, and return data.\",\n    \"Several log types are mentioned such as proxy access logs, tomcat access logs, and skye logs.\",\n    \"Access logs provide information on request status codes, durations, and source IPs.\",\n    \"API documentation and sample requests/responses are prerequisites for API analysis.\",\n    \"Webservice logs can be located in catalina.out or in a specified log folder.\",\n    \"Http invokers need updating to map to actual services.\",\n    \"HTTP Request logs can be filtered using `yamlloggerName:skye.integration.http AND \"Executing HTTP request\"`.\"\n] \n \nClaims:\n[\n    \"If you are unable to see the requests and responses of your APIs in the logs, there are a few potential reasons and solutions to consider.\",\n    \"Ensure that the appropriate loggers are enabled for capturing HTTP requests and responses.\",\n    \"Have the logger for HTTP integration set to DEBUG level.\",\n    \"Enable trace_id and session_id in your logging configuration for tracking logs related to specific requests and user sessions.\",\n    \"Set skye.performance.http to DEBUG to capture all request logs.\",\n    \"If using Graylog, ensure streams are correctly configured to route messages into the appropriate categories.\",\n    \"Verify that the logs are being stored correctly and are not written to a location that is not being monitored.\",\n    \"Check the network tab in your developer tools to see if requests are being sent and what responses are being returned.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The claim about potential reasons and solutions for not seeing API requests and responses in logs is not directly supported or contradicted by the given context.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not specifically mention verifying the storage location of logs.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not provide information about checking the network tab in developer tools.\"\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.9285714285714286,
          "reason": "The score is 0.93 because the output effectively addresses the general concern of missing API logs by identifying a log visibility issue, which is highly relevant to your question. However, the suggestion to contact customer support, although helpful in some contexts, is not directly linked to explaining the absence of logs, slightly lowering the score.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0087925,
          "verboseLogs": "Statements:\n[\n    \"Incorrect logger configuration may prevent viewing API requests and responses in logs.\",\n    \"Enable the appropriate loggers for HTTP requests and responses.\",\n    \"HTTP integration logger should be set to DEBUG level.\",\n    \"Trace and session IDs help track logs related to specific requests and sessions.\",\n    \"Include trace_id and session_id in the logging configuration.\",\n    \"Ensure log level is set correctly for relevant categories.\",\n    \"Set skye.performance.http to DEBUG to capture all request logs.\",\n    \"Graylog streams must be configured correctly for proper message categorization.\",\n    \"Contact customer support if Graylog streams are not visible.\",\n    \"Verify logs are stored in the correct locations.\",\n    \"Logs might be stored in catalina.out or /opt/rakbankdev1a-data/logs/.\",\n    \"API call failures, like 403 errors, may lead to missing logs.\",\n    \"Check network tools to see if requests are being sent and responses returned.\",\n    \"Refer to documentation for detailed logging and troubleshooting guidance.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Contacting customer support is useful for issues with visibility in Graylog but does not directly explain missing API logs.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.2,
          "reason": "The Retrieval Context lacks specific details on logger configurations like 'skye.api.internal' and does not provide explicit logger settings present in Context. It also does not include a required link relevant to the Context information. Only skye.integration.http is briefly mentioned without detail.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.010735000000000001,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Compare the key information in CONTEXT to see if it exists in RETRIEVAL_CONTEXT.\",\n    \"Check if RETRIEVAL_CONTEXT includes a link, as it is required.\",\n    \"Evaluate if RETRIEVAL_CONTEXT contains all critical details present in CONTEXT, regardless of additional information.\",\n    \"Ensure any discrepancies where RETRIEVAL_CONTEXT lacks information from CONTEXT are identified.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.897632281382745,
          "reason": "The actual output includes the mandatory documentation links and covers all key points like logging configuration, storage location, and API errors. It adds valid additional information about Graylog streams and trace/session IDs without contradiction. Minor deviation in phrasing, but nothing critical.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0049375,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Step 1: Verify if the ACTUAL OUTPUT includes a link to documentation, as this is mandatory.\",\n    \"Step 2: Compare the ACTUAL OUTPUT to the EXPECTED OUTPUT for completeness, ensuring that all key points are covered.\",\n    \"Step 3: Evaluate if the ACTUAL OUTPUT contains additional information that does not contradict the EXPECTED OUTPUT, deeming it as acceptable.\",\n    \"Step 4: Identify any contradictions between the ACTUAL and EXPECTED OUTPUT, marking them as not acceptable.\"\n]"
        }
      ],
      "runDuration": 26.897947292000026,
      "evaluationCost": 0.0434475,
      "order": 4
    },
    {
      "name": "test_customer_chatbot[test_case5]",
      "input": "Is there a way where we can utilize the same process for two different generics? / Can I use the same process for two products?",
      "actualOutput": "Yes, you can utilize the same process for two different generics or products in Innoveo Skye. The process definitions can be shared across different product definitions, allowing you to maintain a single process while applying it to multiple products or generics. \n\nFor more detailed information on how to configure and manage processes in this context, you can refer to the following documentation link: [Process Configuration](https://confluence.innoveo.com/dosearchsite.action?queryString=process).",
      "expectedOutput": "No, you cannot use the same process for two products in Innoveo Skye. Each process is typically tied to a specific product definition, and while you can create similar processes for different products, they must be defined separately.",
      "context": [
        "# Structural embedding\n\nAs the name indicates, process definitions are part of the process oriented streams.\nA process implementation always references a \"Current process object\" which is either of model type product or generic (in user management: user, user group or generic). \n\n# How to configure a process\nA process definition consists of a root with two mandatory attributes and one brick per process step. Buttons are defined as action attributes on every process step brick. Please find the detailed configuration manual below.\n\n# Configuring a new process\n\nOn the root on the control attribute \"@CurrentProcessObject\" on tab 'Reference' set model type of referenced model to \"Product\".\nRefer to \"Delete task\" for Delete behavior.\nAdd reference to a model (select product definition you want to use this process for). Note: It is only possible to reference one process object from a process."
      ],
      "retrievalContext": [
        "## 2. Pricing API with multiple Pricing Generics  \nHave separate Pricing Generics holding one Pricing Excel version each and the Pricing API endpoints must be called dynamically per version.  \n*This approach resolves the possible performance issues, however, creates a large amount of Pricing Generics which can make maintenance of the application (work in Business Canvas) a bit problematic.*  \n*Product - Pricing Generic relation*",
        "### Structural embedding  \nGeneric definitions can be used in all three streams. In the generic stream they are used as current process objects but basically there is no restriction in using them elsewhere.",
        "### Example  \n**Sharing a session variable named 'sessionId' in two different products**  \n1. Create a session variable attribute with the variable name 'sessionId' in both products  \n![screenshot](https://confluence.innoveo.com/is914/files/158605078/158605081/1/1711440539000/image2023-1-11_14-23-26.png)  \n![screenshot](https://confluence.innoveo.com/is914/files/158605078/158605080/1/1711440539000/image2023-1-11_14-23-47.png)  \n1. Set the value of the session variable in one of the products using any of the Skye features  \n![screenshot](https://confluence.innoveo.com/is914/files/158605078/158605079/1/1711440539000/image2023-1-11_14-26-43.png)  \n1. Read the value of the session variable in the other product using any of the available Skye functionality  \n```\n%{Product2.SessionIdProduct2->rawValue}\n```  \nThe expression above should return ID66666",
        "### Custom e-mail configuration with generic definitions  \nThis e-mail configuration starts with the introduction of a generic definition which will act as a container for both the e-mail attribute, as well as the event attribute.  \nThe idea behind the solution is simply that for each e-mail that we have to send, a new implementation of this generic definition is created, therefore the e-mail and event attributes always reside in different implementations, eliminating the need to worry about event timelines and how a trigger mechanism is going to affect said event.  \nThe Inputs brick stores all the input values that arrive from our source definition which is a User definition in this case. Please also note that the e-mail content, subject, address will dynamically change therefore we can use one generic definition to send e-mails out for multiple products at once, instead of having to create a generic definition per each product.  \nBelow is a screenshot of the configuration in the BrokerUser definition as an example for this solution.  \nThe main aspects of the configuration are the implementation creation service, the reference attribute and the Excel that will map all the values to the generic definition\u2019s \u201cInputs\u201d brick.  \nImplementation creation service: This is the service attribute that will create the implementation of generic definition \"UserActivationEmailGeneric\", once the user enters \"Created\" status.  \nReference attribute: This is the reference attribute to establish a connection between the newly created \"UserActivationEmailGeneric\" implementation, handled by the \"UserActivationEmailGenericCreateService\" service attribute (reference to target).  \nExcel trigger: This is the attribute that triggers the \"UserActivationEmailMapperExcel\", to start mapping the values to the newly created generic def. implementation, \"UserActivationEmailGeneric\".  \nThe trigger dependency uses the value of \"UserActivationEmailGenericRef\", to make sure that the Excel does not start running before the implementation and the reference connection between the two definitions, \"BrokerUser\" and \"UserActivationEmailGeneric\", has been successfully established.  \nExcel attribute: This is the Excel that starts mapping all the values from this definition, to the newly created generic definition, \"UserActivationEmailGeneric\".",
        "---\ntitle: \"Context handling\"\n---  \nIn Innoveo Skye\u00ae configuration the same product definition including all product related attributes, product business logic, ev. price calculation etc. can be used in different distribution channels for different user roles. Even though the basis for every selling process of the same product is the same, the way how it is presented to users in different distribution channels might differ a lot. That's why Innoveo Skye\u00ae offers the possibility to define parts of your selling processes (like e.g. the visibility and structuring of attributes) depending on distribution channel and user role via contextual configuration.",
        "## 1. Pricing API with one Pricing Generic  \nHave a Pricing Generic holding all the Pricing Excel versions (extended over time).  \n*This approach holds a possible performance issue once the number of excels grows too large [must be confirmed with platform team]. If the excels used are relatively small in size it should not be an issue for quite a long time.*  \n*Product - Pricing Generic relation*",
        "---\ntitle: \"Generic\"\n---  \nGeneric definitions are used when no special model type is needed. As for product definitions, most of the tools described in this user guide are applicable for generic definitions (depending on the usage stream) so there is no additional documentation added here.",
        "## Parallel work management  \nInnoveo Skye does not support branch merging - if you have two versions of the same definitions there is no way for automatically to merge it, it has to be done manually. To avoid this, on one definition only a person works at the same time. If someone else needs to work on the same definition, he has to stop the work and let the other person work on it. This is communicated in the chat, that a definition was taken or released. To make it easier to understand, conversations goes usually like this:  \n* A: Took Motor *- starts to work on Motor definition*  \nB: Took Compare *- starts to work on Compare definition*\n* C: A, do you need Motor for a long time? I would need it for a small change\n* A: I can release it for 30 mins - is that ok?\n* C: Yes, Thanks!\n* A: Released Motor *- commits Motor definition to git*  \nC: Took Motor *- Pulls the git repository to have the latest Motor version and starts to work on it*  \nB: Released Compare*- commits Compare definition to git*  \nA: Took Compare*- Pulls the git repository to have the latest Compare version and starts to work on it*  \nC: Released Motor -*commits Motor definition to git*",
        "# Not supported  \n### Use both components together  \nIt is not possible to use for one multibrick the two configuration options in different channels. You have to decide for one or the other.",
        "## Parallel development  \nWith discipline, it is possible to have parallel teams developing for a single Skye application. As you can not merge definitions today, the only way to merge is by ensuring there are no conflicts, and the only way to achieve this is if the teams are working on separate definitions. **Therefore the key is that the distribution of the teams must be done via definitions!**",
        "### Example  \nIf the selling process of a product can be split into a quotation process and a process to convert a quote into a policy you will normally define two different processes in Skye. If the user should have the possibility to enter the \"Convert to policy\" process directly at the end of the quotation process you can configure a button which will redirect you to the second process when clicking on it.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606425/1/1711441002000/image2018-11-30_15-32-18.png)",
        "## Definition Types to migrate  \nSkye creates implementations of various objects. However, it is not actively using all the saved implementations. As a thumb rule, you only have to migrate implementations which were created by implementations of the following definition types:  \n* Product\n* Generic\n* User\n* User Organization\n* ShoppingCart  \nThe rest of the definitions - even if they create implementations in the background - does not need to be migrated.",
        "## Importing definitions from a different project  \nIn case you would like to add a definition from a different project, you can import it to the Jumplead definition set in the following way:  \n**Make sure to import the needed products and processes as well and remove any reference or resolver from the definition which refer to not imported definitions**. You may also need to adjust the authorization model, processes, contexts or other definitions.",
        "### How to configure  \n1. Add the control attribute @isVisible to the process step you want to show or hide dynamically\n1. Set default visibility of @isVisible to \"read\"\n1. Now you can control the value of this attribute for example by dependency. Navigating through the reference attribute @CurrentProcessObject you can set the value of the attribute \u201c@isVisible\u201d to true depending on the value of any attribute in your product definition.  \n{{< callout type=\"warning\" >}}\nPlease note that even if you never display two process steps together you have to give them different sort orders. If two process steps in the definition have the same sort order the \"show/hide process step\" functionality doesn't work properly.\n{{< /callout >}}  \n{{< callout type=\"warning\" >}}\nDependencies on@isVisible attributes are only triggered when clicking on an action button.\n{{< /callout >}}  \n{{< callout type=\"warning\" >}}\nA button that points to a page that is dynamically shown or hidden should only be visible if the page is also visible. Otherwise you will jump to a page that is not visible (panel of this page is hidden but attributes are still displayed). So if you add a dependency on an @isVisible attribute you should add the same dependency to the button that points to this page.\n{{< /callout >}}",
        "### Key points  \n* There are parallel teams developing. Team distribution is dictated by the distribution of definitions. **Every definition must belong to exactly one team.**  \n+ Product 1 team managing Product 1 related definitions\n+ Product 2 team managing Product 1 related definitions\n+ Product n team managing Product n related definitions\n+ Base team managing all the shared definitions\n* Each team has its own DEV & SIT environments, but Hotfix & PROD are shared.\n* Each team has its own branch. Merging happens before the production release. There is a main branch (in diagram: prod branch) that serves as the merged set of definitions that are going to be deployed to prod.\n* UAT is executed on the PROD branch and UAT environment.\n* It is possible to have a dedicated branch to execute smaller changes on PROD (imagine a monthly release with minor changes for which you don\u2019t want to wait until the next major deployment). This would work the same as the hotfix branch, with the only exception that they have dedicated DEV & SIT.",
        "### Structural embedding  \nAs the name indicates, process definitions are part of the process oriented streams. A process implementation always references a \"Current process object\" which is either of model type product or generic (in [user management](../user_management/_index.md): user, user group or generic).",
        "### Making it user-specific  \nYou can make this user-specific (depending on any custom user claim). In our example, we will create an attribute called \u201cAvailableProducts\u201d in the user management, which is a checkbox with multi-selection with the different products. It sends the value \u201cMotor\u201d if Motor is ticked, sends \u201cMotor;Home\u201d if both Motor and Home are selected.  \nAs the visibility can be dynamic with using dependencies and the product categorization is depending on the visibility of the contexts, you can make dynamic access.  \nIn the example on the right side, we are making the Motor product avaialble depending on the selection in the user management.",
        "# Reference guide  \n## Different process layouts  \nThe layout of a process depends on one part of the URL. It is rendered differently if the URL contains \"enter\" or \"component\". The process configuration is the same for both. This means that you can use the same process definition for different layouts and it will automatically be displayed differently.",
        "## Parallel work management  \nParalell work can be made a lot faster if you are creating smaller objects. Please make sure you finish our modularization training if you have any challenge: Possible Skye Trainings  \nInnoveo Skye does not support branch merging - if you have two versions of the same definitions there is no way for automatically to merge it, it has to be done manually. To avoid this, on one definition only a person works at the same time. If someone else needs to work on the same definition, he has to stop the work and let the other person work on it. This is communicated in the chat, that a definition was taken or released. To make it easier to understand, converstiaion goes usually like this:  \n* A: Took Motor *- starts to work on Motor definition*\n* B: Took Compare *- starts to work on Compare definition*\n* C: A, do you need Motor for a long time? I would need it for a small change\n* A: I can release it for 30 mins - is that ok?\n* C: Yes, Thanks!\n* A: Released Motor *- commits Motor definition to git*\n* C: Took Motor *- Pulls the git repository to have the latest Motor version and starts to work on it*\n* B: Released Compare*- commits Compare definition to git*\n* A: Took Compare*- Pulls the git repository to have the latest Compare version and starts to work on it*\n* C: Released Motor -*commits Motor definition to git*",
        "## Import from root with a re trigger in case of failure  \nThis section provides a step-by-step guide on scheduling an import from the root and how to re trigger it if it fails during execution. The only prerequisite is that there exists an initial configuration with two products and processes already in operation, as these products will be utilized both to initiate the import and to serve as the items to be imported.  \n**Create the import from root task**  \n1. Create the CSV file  \nThe import will create or update implementations of type \"ProductImported\" and the CSV file will have three columns KEY, ATTRIBUTE1, ATTRIBUTE2 (The import will update if required 3 attributes)  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606347/1/1711440991000/image2024-3-18_11-5-29.png)  \n1. Add the following configuration in the product that is responsible of triggering the import from root (In this example they will be added to the product \"ProductTriggeringImport\")  \n- Configure the resource attribute where the user will upload the import file\n- Configure the scheduler attribute that will be in charge of scheduling the import task\n- Configure the dependency that will be triggering the scheduler\n- The scheduler used in the scheduler attribute will be explained below  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606351/1/1711440991000/image2024-3-18_10-18-19.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606350/1/1711440991000/image2024-3-18_10-18-45.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606349/1/1711440991000/image2024-3-18_10-24-26.png)  \n1. Create a new \"Import from root\" task and configure it:  \n- General tab: set the language as en_us\n- Import file tab:\n- specify the model text-id that will be in charge of triggering the scheduler\n- define the resource attribute where the file to be imported will be uploaded\n- specify the transformation definition to be used for importing records (See detailed configuration below)  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606353/1/1711440991000/image2024-3-18_10-6-49.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606352/1/1711440991000/image2024-3-18_10-7-20.png)  \n1. Add a new time based scheduler  \n- Specify the \"Trigger time\" property\n- Add the task where the import from root was configured  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606348/1/1711440991000/image2024-3-18_10-27-30.png)  \n1. Create a new transformation definition and  \n- configure the mandatory control attributes\n- configure the attributes that are going to be updated if required in the import  \n**Mandatory control attributes**  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606346/1/1711440991000/image2024-3-18_11-7-26.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606345/1/1711440991000/image2024-3-18_11-7-50.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606344/1/1711440991000/image2024-3-18_11-8-9.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606343/1/1711440991000/image2024-3-18_11-8-28.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606342/1/1711440991000/image2024-3-18_11-8-48.png)  \n**Attributes updated during the import**  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606341/1/1711440991000/image2024-3-18_11-15-25.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606340/1/1711440991000/image2024-3-18_11-15-43.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606338/1/1711440991000/image2024-3-18_11-16-6.png)"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions present, indicating full alignment between the actual output and the retrieval context. Great job on maintaining accuracy!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0186475,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The Pricing API can have multiple Pricing Generics, each holding one Pricing Excel version.\",\n    \"The performance issue with using multiple Pricing Generics can be resolved, but it creates maintenance problems.\",\n    \"Sharing a session variable named 'sessionId' between two products involves setting and reading the value in each product using Skye functionality.\",\n    \"Custom email configurations use generic definitions as containers for email and event attributes.\",\n    \"A service attribute creates the implementation of the generic definition 'UserActivationEmailGeneric' upon user status change.\",\n    \"Dependencies on @isVisible attributes are triggered by action button clicks.\",\n    \"Parallel work in Innoveo Skye requires manual merging of definitions if there are multiple versions.\",\n    \"A 'ProductImported' CSV import requires a specific task configuration in Innoveo Skye.\",\n    \"Parallel teams working on a Skye application must work on separate definitions to avoid merge conflicts.\",\n    \"Innoveo Skye configuration allows definition of product selling processes varying by distribution channel and user role.\",\n    \"Modularization of objects can speed up parallel work management in Skye.\",\n    \"Importing definitions from one project to another requires updating authorization models and removing unnecessary references.\"\n] \n \nClaims:\n[\n    \"You can utilize the same process for two different generics or products in Innoveo Skye.\",\n    \"The process definitions can be shared across different product definitions in Innoveo Skye.\",\n    \"A single process can be maintained while applying it to multiple products or generics in Innoveo Skye.\",\n    \"For detailed information on configuring and managing processes, you can refer to a documentation link provided.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.6,
          "reason": "The score is 0.60 because although the output addresses the general possibility of using the same process for different generics, it delves into irrelevant details, like seeking more information elsewhere, which detracts from a direct answer.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.005855000000000001,
          "verboseLogs": "Statements:\n[\n    \"You can utilize the same process for two different generics or products in Innoveo Skye.\",\n    \"Process definitions can be shared across different product definitions.\",\n    \"This allows you to maintain a single process while applying it to multiple products or generics.\",\n    \"More detailed information is available in the documentation link provided.\",\n    \"Documentation link: https://confluence.innoveo.com/dosearchsite.action?queryString=process.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The statement about more detailed information doesn't directly answer if the same process can be used for two generics or products.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The documentation link alone provides no direct answer to the question of using the same process for two generics or products.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.1,
          "reason": "The Retrieval Context does not contain the specific structural embedding information or configuration guidance present in Context. Additionally, no link is present for validation, and content mostly differs without contradicting the core information.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.013405,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if RETRIEVAL_CONTEXT contains all the essential information from CONTEXT.\",\n    \"Verify that RETRIEVAL_CONTEXT includes a link as expected for validation.\",\n    \"Assess if the additional information in RETRIEVAL_CONTEXT does not contradict the core information in CONTEXT.\",\n    \"Ensure that the structure of the essential information in RETRIEVAL_CONTEXT matches that of CONTEXT for consistency.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.18007516243038427,
          "reason": "The Actual Output contradicts the Expected Output regarding process sharing across products. However, it includes a documentation link which is correctly referenced.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0031025,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Step 1: Compare the Actual Output to the Expected Output to determine relevancy and completeness of information, ensuring the base content matches.\",\n    \"Step 2: Verify the presence of a documentation link in the Actual Output and check that it provides appropriate reference materials.\",\n    \"Step 3: Ensure that any additional information provided in the Actual Output does not conflict with the Expected Output; contradictions are not acceptable.\",\n    \"Step 4: Confirm that any extra details enhance the Expected Output without altering its intended meaning or direction.\"\n]"
        }
      ],
      "runDuration": 27.221312583002145,
      "evaluationCost": 0.041010000000000005,
      "order": 5
    },
    {
      "name": "test_customer_chatbot[test_case6]",
      "input": "Deleting excels will create migration issue?",
      "actualOutput": "Yes, deleting excels can create migration issues. It may lead to missing values, which can cause application misbehavior, or result in objects in the implementation referencing something from a definition that is no longer present, leading to inconsistent values in the database.\n\nFor more detailed information on the potential issues and how to handle them, you can refer to the documentation on testing migration: [Testing the migration](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1759543505).",
      "expectedOutput": "No, deleting excels will not create migration issues.",
      "context": [
        "# Compact database\n\nBefore we get into this, there is an important factor that we need to clarify. Since Skye 7, there is an option called compact database.\nIf the compact database is enabled, then the attributes without values will not be saved to the database.\nThis is implemented on a rather deep (database-connection) layer of the application and works in a way, that if an attribute can not be found in the database, Skye will assume that it is empty.\nThis is a really big gamechanger for the migration. \n\n#Effect on migration\n\nThe key part is the \u201cif an attribute can not be found in the database, Skye will assume that it is empty\u201d. \nWithout this setting, if an attribute is not found for an implementation, Skye would run on an error as it would find inconsistent implementations.\nIf this setting is enabled, then when it is not found an attribute it will not run into an error, it will assume it is empty.\n\n# Why is this so important?\nThere are two parts to it. \n\nYou don\u2019t have to migrate attributes that do not need to have a value when the implementation is being opened for the first time.\nIf you add an attribute called \u201ccustomerFirstName\u201d and you expect the customers to fill that information in your next phase, you don\u2019t have to migrate this attribute, as it is expected to have no value for all the existing implementations.\n   - A lot of attributes not only do not have but can not have values in the database. You don\u2019t have to migrate Excel attributes, service attributes, container attributes, basically nothing which does not have the default value option in Skye.\nIt reduces the number of rows required to save an implementation. This is different on every project, but the thumb-rule is that usually, an implementation has 60% fewer rows with this feature enabled.\nThis will reduce your database size by almost 60% which then again will shorten your migration run time exponentially."
      ],
      "retrievalContext": [
        "Identifying need for migration",
        "# Purpose  \nAs part of migration, sometimes you have to delete specific attributes.",
        "Migration",
        "Data Migration",
        "## Recommendations  \nFor performance reasons it is recommended to use the XLS Excel format. For smaller Excel files, XLSX may still have acceptable performance and therefore be used.  \nAs a rule of thumb, files larger than 1 MB shall only be used with XLS format.  \nExtensive use of the Excel function`SUMIFS`, which is only supported in XLSX, has a negative performance impact, in that case even smaller XLSX files (about 0.4 MB) may cause performance issues. In that case it is recommended to use the `VLOOKUP` function in XLS format.  \nAn overview of the format pros and cons are listed in the table below  \n| Criteria | XLS | XLSX |\n| --- | --- | --- |\n| Performance | High performance for all Excel sizes | Performance decreases with size of Excel |\n| Column count | Limited to 264 | Limited to 16384 |\n| Excel evaluate | Not compatible | Compatible |",
        "## Size of Excels  \n* Generally the file size of Excels affect performance exponentially.\n* Avoid creating Excels bigger than 1-2 MB.\n* Typical mistake is Excels with large lookups (e.g., VLOOKUP, INDEX + MATCH, etc.). This can be outsourced to Elastic Search indexes.  \n+ Indexes perform better than Excel lookups, and\n+ Scale better than Excel (easily supports millions of rows).",
        "### Recommended use case  \nIt is typically used when the use case is relatively small and simple but there is a need for version control.  \nIn other words,  \n* there is a need for version control\n* the size of the excel is small (<1MB)\n* Frequency of pricing change is rare (1-4x/year)",
        "# Usage  \nThe database can be handy in a number of cases: maybe you are just not understanding a behaviour, maybe you need to export some data, maybe you just want to check what data your excel is triggered with.",
        "Migration manually",
        "### Recommendations  \nFor performance reasons it is recommended to follow some guidelines. For more information please refer to the page [Excel / Apache POI](../../excel-apache-poi/).",
        "Migration list file not found",
        "Migration - The Execution",
        "Preparing for migrations",
        "# Purpose  \nThe purpose of this page is to describe how to prepare for migrations.",
        "# Testing  \nThe most common symptoms of a failed migration are  \n* there is a missing value which causes application misbehavior\n* there is an object in the implementation which references something from a definition which is not there causing inconsistent values in the database",
        "Migration - The How",
        "# Purpose  \nThe purpose of this page is to explain what migration is, why is it necessary and if i is necessary, how to do it.",
        "Testing the migration",
        "Migration - The Testing",
        "## 1. Pricing API with one Pricing Generic  \nHave a Pricing Generic holding all the Pricing Excel versions (extended over time).  \n*This approach holds a possible performance issue once the number of excels grows too large [must be confirmed with platform team]. If the excels used are relatively small in size it should not be an issue for quite a long time.*  \n*Product - Pricing Generic relation*"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions, demonstrating perfect alignment between the actual output and the retrieval context. Great job!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0107775,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Deleting specific attributes can sometimes be necessary during migration.\",\n    \"For data migration, using the XLS Excel format is recommended for performance reasons.\",\n    \"XLSX format may still be used for smaller Excel files due to acceptable performance.\",\n    \"Excel files larger than 1 MB should be used with the XLS format only.\",\n    \"The use of the Excel function 'SUMIFS' in XLSX has a negative performance impact.\",\n    \"The performance of Excel files is affected exponentially by their size.\",\n    \"Excels larger than 1-2 MB should be avoided due to performance issues.\",\n    \"Excel functions like VLOOKUP and INDEX + MATCH can negatively impact performance if the Excel file contains extensive lookups.\",\n    \"Elastic Search indexes perform better than Excel lookups and can handle millions of rows better.\",\n    \"XLS format has high performance for all Excel sizes.\",\n    \"XLS format is limited to 264 columns.\",\n    \"XLSX format is limited to 16384 columns.\",\n    \"XLS format is not compatible with Excel evaluate.\",\n    \"The problem of missing values may indicate a failed migration.\",\n    \"Inconsistent values in a database can result from unsupported objects in an implementation referencing missing definitions during migration.\",\n    \"Excels used in a Pricing Generic approach must be relatively small to avoid performance issues.\"\n] \n \nClaims:\n[\n    \"Deleting excels can create migration issues.\",\n    \"It may lead to missing values in the migration process.\",\n    \"Missing values can cause application misbehavior.\",\n    \"Migration issues may result in objects referencing non-existent definitions.\",\n    \"Inconsistent values in the database can occur due to deleted excels.\",\n    \"For more information, refer to the documentation on testing migration at the provided URL.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.8571428571428571,
          "reason": "The score is 0.86 because the answer contained largely relevant content addressing whether deleting excels will create a migration issue. However, the inclusion of a documentation link, while potentially helpful, wasn't directly linked to the inquiry, slightly impacting the relevance score.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.005915,
          "verboseLogs": "Statements:\n[\n    \"Deleting excels can create migration issues.\",\n    \"It may lead to missing values.\",\n    \"Missing values can cause application misbehavior.\",\n    \"Objects in the implementation might reference a definition that is no longer present.\",\n    \"Referencing missing definitions can lead to inconsistent values in the database.\",\n    \"For more information, refer to the documentation on testing migration.\",\n    \"Documentation link: Testing the migration at https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1759543505.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The statement providing a documentation link doesn't directly address whether deleting excels will cause migration issues, though it might offer supporting details.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.2,
          "reason": "The Retrieval Context lacks the specific mention of 'compact database' and its impact on migration as outlined in the Context. Additionally, there is no link provided as expected, failing Step 2, and there are discrepancies related to the detailed migration process described in the Context.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0059225,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Step 1: Verify the presence of all key elements from CONTEXT in the RETRIEVAL_CONTEXT to ensure complete retrieval.\",\n    \"Step 2: Confirm that RETRIEVAL_CONTEXT includes a link, as expected.\",\n    \"Step 3: Identify and note any crucial discrepancies between CONTEXT and the corresponding sections in RETRIEVAL_CONTEXT.\",\n    \"Step 4: Evaluate the surplus information in RETRIEVAL_CONTEXT to ensure it does not contradict or misrepresent the core elements of CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.4,
          "reason": "Actual Output contradicts Expected Output in stating that deleting excels can cause migration issues. However, it correctly includes a link to documentation and provides additional clarification on potential problems.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.003045,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Step 1: Compare the Actual Output to the Expected Output to determine if they align closely in terms of information and context.\",\n    \"Step 2: Verify that the Actual Output includes a link to the documentation, as this is a required element.\",\n    \"Step 3: Ensure that any additional information in the Actual Output does not contradict the Expected Output.\",\n    \"Step 4: Check for consistency and coherence between the Actual Output and the Expected Output, ensuring no discrepancies exist unless they provide additional clarification.\"\n]"
        }
      ],
      "runDuration": 14.221590541001206,
      "evaluationCost": 0.02566,
      "order": 6
    },
    {
      "name": "test_customer_chatbot[test_case7]",
      "input": "What are the best practices to build integration with Skye?",
      "actualOutput": "For best practices to build integration with Skye, you can refer to the documentation that provides useful tips and tricks regarding REST APIs in Skye. This resource will help you understand how to effectively integrate with Skye and avoid common pitfalls.\n\nHere is the link to the relevant documentation: [Tips & Tricks for REST APIs in Skye](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/595329025). \n\nAdditionally, you may want to consider the general guidelines for integration analysis, which can help identify potential issues early in the process. You can find that information here: [Integration Analysis Guidelines](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1596719345). \n\nThese resources should provide a solid foundation for building integrations with Skye.",
      "expectedOutput": "Yes, there is a best practice documentation available for integrations. You can find it in the following link:\u00a0Best Practices Documentation. This document outlines ideas and accepted practices for making configurations easy to read and understand, which can be helpful when dealing with integration tickets.",
      "context": [
        "# Purpose \n\nIt is a common requirement from the customer to integrate either with their system(s) or with third parties to insert the application into an ecosystem or extend with functionalities which are not available in Skye. \n\n#Prerequisites\nBefore you start the analysis, you need the following:\n    - API documentation\n    - Sample requests / responses to every API method\n    - Test endpoint and credentials\n\nThese are quite general and basic needs, if the API provider did not provide them at first, feel free to ask for them. If they are unable or unwilling to provide this in some way, it is an alarming sign.\nEither the API is not really ready to be used or the provider is not really committed to have this integration.\n\n#API management\nThere is a few things, which is good to know about the API. These information can be useful later.\n    - Who owns the API? Customer or third party\n    - Is the API specifically developed for this project or it is a general purpose API?\n        - If the API is developed for you project, you have a higher change to request changes, but the API might be less stable / reliable.\n    - Is it an ongoing / recent development or an existing API?\n    -  If it is an ongoing / recent development you can expect some changes / issues with the system.\n    - Is anyone else using the API right now?\n       -  If the server\u2019s capacity is low, another party using the API can impact your work (slow / unavailable API) "
      ],
      "retrievalContext": [
        "Skye development Checklist",
        "Skye development & debugging basics",
        "# Purpose  \nIt is a common requirement from the customer to integrate either with their system(s) or with third parties to insert the application into an ecosystem or extend with functionalities which are not available in Skye. This document lists a collection of questions and topics, that you should keep in mind when you are doing the analysis.  \nThe document hopefully will help you to avoid some problems ( or at least identify them early) , but this is not a comprehensive, step-by-step guide how to execute it. Every API will be different and you need to analyze it properly.",
        "# Purpose  \nThis is your go-to place for anything related to the Skye ecosystem.  \nFor configuration related topics, visit the Skye page.",
        "# Skye Configuration Review  \nThe purpose is to review the quality of the configuration. It is done recurringly on internal projects and is done as per request on partner-led projects.  \nPlease note, that for a full configuration review we need to understand all requirements and might take weeks, depending on the level of detail we would review.  \nThis page assumes that we review the project from a high-level overall perspective and not on attribute or screen-level.  \nFor that, we would need to understand all requirements and as it is a weeks-long activity needs to be planned 4 weeks upfront.  \nMain areas the architecture team focuses on are:  \n| **Area** | **Expectation** |\n| --- | --- |\n| **Definition structure** | *Naming convention & readability of definitions must match architecture standards* |\n| **Modularization** | *The application must not have relatively large definitions & uses microservices* |\n| **Unused Definitions** | *Only definitions used in the project should be part of the Skye configuration* |  \nTemplate can be found at [yyyy.MM.dd] - Skye Configuration Review - [Project]",
        "Which Skye version should I use on my project?",
        "# Purpose  \nThe purpose of this page is to explain how you have to build authorization in Skye. **This must be followed if you are building a system that will go live at some point in time.**",
        "# Purpose  \nThis page collects useful tips & tricks regarding REST APIs in Skye.  \nYou can also check out Solution Library for re-usable APIs.",
        "# Purpose  \nThis page collects useful tips & tricks for working with Skye.",
        "How to execute a project as a Skye Partner",
        "# Purpose  \nThis is your go-to place for anything Skye configuration related (of course only after the Skye User Guide)",
        "How to use Git for Skye development",
        "## Prepare for the Skye ecosystem.  \nThere are number of tools and websites used while working with Skye. The Partners will also need to use these tools & it is recommended to check and install them (if necessary, whitelist them).  \nRequired softwares to work with Innoveo  \nPlease also read our Security Guide, to be prepared while starting the project.",
        "### The Support Process  \n#### Tickets  \nWe use tickets as the main source of support: please open a ticket for every issue you have: This helps us: most of the time, as the collaboration matures your questions will start to be more complicated and we will not be able to resolve them on the spot. It helps you because your issues will be searchable.  \n##### Support yourself!  \nWe are constantly generating new and new documentation. Please make sure that you went through this guide before you reached out help to us: Config 101 - What to do when I am stuck?  \n##### What to include in your support ticket  \nA properly written ticket saves time for all parties. We ask you to please always add:  \n* Skye Version\n* Reproduction steps\n* Relevant definitions & attributes\n* What you tried to do & What your expectations are & What you experience\n* If you have trouble with building an integration, then make sure that you attach a postman collection or a wsdl + sample request so we can trigger the integration ourselves.  \nPlease consider that we provide application support and not function support: in case there is an issue you must do an analysis on it before reporting to us.  \n#### Meetings  \nWe offer daily meetings during the Honeymoon period, this typically decreases to 2-3x weekly meetings \u2013 this is up for discussion at the end of the honeymoon period.",
        "# Context  \nTo understand the Partner Hub better, you can find a brief description of our key modules below:  \n| **Module** | **Description** |\n| --- | --- |\n| Skye | Anything about the platform, including public roadmap, best practices, guides |\n| Innoveo Ecosystem | How to work with us, how to become a partner, how to communicate with different departments and entities inside Innoveo. |\n| Skye Ecosystem | What is an environment, how to connect to it, how to do deployments and development. In general, everything you need to do Skye development. |",
        "### Preparation for discovery  \nYou have to go to the discovery with an understanding of the scope. The artifact that helps is the Presales Handover Document. You should have a solid understanding of the project from that. You need to be able to have a high-level design done for the application before you go to the discovery. This will help you to ask more targeted questions.  \nEvery discovery is unique and you will have to be able to adapt to the situation. This shouldn't mean that you should not go prepared - it will increase your chances to handle the diversions as well.  \n#### Skye gap analysis  \nEven though Skye is an extremely flexible system, as a no-code platform it has some limitations. It is your responsibility to identify if the project is executable with the platform and identify the gaps, if not. Of course, if you have any questions or doubts, you should ask Innoveo to consult. If there is a gap, you have to start the discussion with Innoveo to address it before you start the project.  \n##### Typical things to check during the gap analysis  \n* Integration points  \n+ Review the protocols used for integration and confirm Skye supports them\n+ Pay special attention to SSO and Reporting\n* UI  \n+ Skye is not fully flexible, as an example, it doesn't support popups.\n* Pay attention to complex requirements  \n+ There is no clear guide to this, in general, you should have a guess on how to execute every part of the Handover Document, if not, then seek for consultancy from Innoveo.  \n#### Requirements to start discovery  \n1. A documented understanding of the project\n2. Eagle-eye-level solution design\n3. Schedule for the discovery\n4. Prepared questions",
        "# Purpose  \nThis page aims to collect all details required for an external partner company to onboard a new member to Skye configuration.",
        "## A new partner company  \nplanning on delivering projects using Skye. Start at Onboarding for a Partner company",
        "# Discovery  \nUnderstanding and documenting the requirements and preparation for the first sprint.  \nPrepare environment  \n* Validate if Skye's stages are working properly  \n+ I can activate\n+ I can deploy\n+ My custom properties are working\n* Document your environment details on Project Confluance (sample)\n* Add your project to Change and Service Request Approval Policy\nDiscovery Artifacts  \n* PMO  \n+ Project phases with minimum inputs and outputs - summary based on project categories\n* Architecture items  \n+ Skye gap analysis\n+ Application Landscape\n+ Review other architecture artifacts depending on project size & Priority\n+ Agree on security related items with the customer",
        "# Skye ecosystem  \nDeep dives in deployment,\nmigration, etc.  \nTroubleshooting"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions present, indicating that the actual output aligns perfectly with the retrieval context. Keep up the great work!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.016297500000000003,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The Skye development & debugging basics document is not a comprehensive, step-by-step guide.\",\n    \"Every API is different and needs proper analysis during integration with Skye.\",\n    \"For a full configuration review in Skye, understanding all requirements might take weeks and planning should be done 4 weeks upfront.\",\n    \"Unused definitions should not be part of the Skye configuration.\",\n    \"The Skye Configuration Review is performed on internal projects and as per request on partner-led projects.\",\n    \"Authorization in Skye must be built as stated if the system is going to go live at some point.\",\n    \"Partners must prepare for the Skye ecosystem by checking required tools and websites.\",\n    \"Support requests in Skye are done through tickets, and they help to develop the collaboration.\",\n    \"A properly written support ticket for Skye must include Skye version, reproduction steps, relevant definitions & attributes, and expectations vs. experience.\",\n    \"Daily meetings during the initial \"Honeymoon\" period can decrease to 2-3 times weekly meetings.\",\n    \"The Skye ecosystem encompasses everything required for Skye development, including environments, deployments, and connections.\",\n    \"Discovery preparation for Skye involves having a solid understanding of project scope and a high-level design ready before starting.\",\n    \"Skye is a no-code platform with some limitations, and a gap analysis should be done to identify if the project is executable with Skye.\",\n    \"Before starting the discovery phase for Skye, certain requirements must be fulfilled, including a documented understanding and a solution design.\",\n    \"Partners planning to deliver projects using Skye should begin with 'Onboarding for a Partner company'.\",\n    \"Discovery artifacts for Skye projects include PMO summaries, architecture items, and a security agreement with the customer.\"\n] \n \nClaims:\n[\n    \"The documentation provides useful tips and tricks regarding REST APIs in Skye.\",\n    \"The resource helps understand how to effectively integrate with Skye and avoid common pitfalls.\",\n    \"The link to the documentation is: [Tips & Tricks for REST APIs in Skye](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/595329025).\",\n    \"General guidelines for integration analysis can help identify potential issues early in the process.\",\n    \"The link to the general guidelines for integration analysis is: [Integration Analysis Guidelines](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1596719345).\",\n    \"These resources provide a solid foundation for building integrations with Skye.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The documentation's inclusion of tips and tricks cannot be directly verified as it is not stated in the retrieval context.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": \"The document mentions the need for understanding during integration, suggesting it could help avoid pitfalls.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not provide information about specific links to documentation.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context doesn't directly cover details on general guidelines for integration analysis.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"No information about specific links to guidelines is provided in the retrieval context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The context does not explicitly state if these resources alone are sufficient for building integrations.\"\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the response perfectly aligns with the query on best practices for Skye integration, addressing the topic without any unrelated content. Excellent focus and relevance!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0054525,
          "verboseLogs": "Statements:\n[\n    \"Refer to the documentation for best practices to build integration with Skye.\",\n    \"The documentation provides useful tips and tricks for REST APIs in Skye.\",\n    \"The resource helps you effectively integrate with Skye.\",\n    \"The resource helps you avoid common pitfalls.\",\n    \"There is a link to the relevant documentation.\",\n    \"The general guidelines for integration analysis can help identify potential issues early.\",\n    \"These resources provide a solid foundation for building integrations with Skye.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.27389988281833216,
          "reason": "The retrieval context includes the key purpose of integration but lacks details on prerequisites, API management, and guidelines, and there is no reference link.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0075225,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if the key information from CONTEXT is present in RETRIEVAL_CONTEXT.\",\n    \"Ensure that RETRIEVAL_CONTEXT includes a link for reference.\",\n    \"Compare both contexts to identify any missing critical details from CONTEXT in RETRIEVAL_CONTEXT.\",\n    \"Verify that the additional information in RETRIEVAL_CONTEXT does not contradict or misinterpret the key details in CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.7,
          "reason": "The Actual Output includes a link to documentation as required and provides relevant information, aligning well with the Expected Output. However, the Actual Output contains additional links and slightly different focus on REST APIs and integration analysis guidelines rather than the simplicity focus highlighted in the Expected Output.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0030575,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Check if the Actual Output contains a link to documentation.\",\n    \"Compare the Actual Output with the Expected Output to determine closeness in content and structure.\",\n    \"Verify that the Actual Output does not contain contradicting information compared to the Expected Output.\",\n    \"Ensure that any additional information in the Actual Output does not contradict the Expected Output.\"\n]"
        }
      ],
      "runDuration": 20.58518683299917,
      "evaluationCost": 0.03233,
      "order": 7
    },
    {
      "name": "test_customer_chatbot[test_case8]",
      "input": "AutoMigration is running for all the definitions due to the batch auto-migration, can we skip the automigration for events?",
      "actualOutput": "Yes, you can skip automatic migration for events by ensuring that no recurring events are configured and by disabling any events that are set to trigger when activating a definition. This is particularly important to prevent concurrent updates and inconsistencies during the migration process.\n\nFor detailed steps on how to manage this, refer to the section on **Batch auto-start** in the documentation, which outlines the prerequisites for disabling events before starting the batch migration. \n\nYou can find the relevant documentation here: [Batch auto-start](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1999438350).",
      "expectedOutput": "No, you cannot skip the auto-migration for events when batch auto-migration is running for all definitions. The automatic implementation migration is designed to ensure consistency across all implementations, including events, during the migration process.",
      "context": [
        "# Overview\n\nThe purpose of the automatic implementation migration functionality is to simplify and automate the process of migrating existing implementations to match the latest changes made to the definitions as these are developed/modified over time. The goal is to save the effort and troubles of developing and running error-prone SQL scripts that use to accompany the changes made to definitions.\n\n## How it works\n\nThe way it works can be summarized as follows:\n- Each definition has a version based on its \u2018last modified\u2019 field. This means that each time a definition is modified it will have a new and unique version.\n- Each implementation also has a \u2018definition version\u2019 field which indicates the version of the definition that this particular implementation is associated with. This field is only set when an implementation is created or migrated.\n- When a new version of a definition is activated, all existing implementations' \u2018definition version\u2019 still point to the previous version, and are now considered outdated.\n- The application will compare the source (old) definition with the target (new) definition and, based on the differences, generate a migration plan which describes the necessary transformations. These may include, for example, adding/removing/renaming bricks or attributes. The target definition is always the latest activated.\n- The migration plan is applied to each implementation associated with the source definition. The implementation 'definition version' is also updated to match the target definition.\n\nIn certain cases, the need for custom scripts (SQL or another form) cannot be fully eliminated when, for business reasons, the migration requires transformations that cannot be generated automatically (see Manual migration), but these cases should be rare.\n\n## Batch\n\nImplementations can also be migrated as part of a batch process, running on the admin application as a background thread, iterating over each outdated implementation and migrating it. This process may run over long periods of time, generally without affecting the normal operation of the system, although there are some limitations and exception cases that should be considered, which are described in more detail in Limitations and best practices.\n\nIn deployment scenarios with Freetext re-indexing and Skye event runs, it is beneficial to not activate batch auto-migration but trigger automatic migration manually through JMX after re-indexing and event runs. With automatic migration enabled, on re-indexing or event run, implementations are migrated on-the-fly. \n\nThe batch migration is separated into different jobs. Each job migrates all outdated implementations associated only with one particular definition version. More than one job might be created if there are multiple definitions or implementations in different source versions for the same definition. The jobs are queued and run one at a time.\n\nThe progress of each job and other migration-related metrics can be monitored with JMX.\n\nSometimes, even though the definition changed, there are no structural changes (e.g. the case of modifying a text). In these cases, the implementations \u2018definition versions\u2019 still need to be updated to the current one but no further modifications are needed. To accomplish this without incurring the overhead cost of loading each implementation, a different type of job is launched which doesn\u2019t load the implementations into memory.\n\n# Limitations and best practices\n## Events selection criteria\n\nRecommendation: Skye event execution shall be inactive until the batch migration is completed.\n\n## Stale implementations in cache\n\nRecommendation: batch auto-migration shall not run in an environment with online users on the system. Either the environment needs to be put offline or use JMX commands to start and stop auto-migration jobs during low usage times."
      ],
      "retrievalContext": [
        "### Events selection criteria  \nIt should be expected that, if the selection criteria for an event involve attributes that are yet to be migrated, then the implementations might not be properly selected by the event. The reason for this is that the implementations are selected before they are loaded (so on-load migration won\u2019t play a role here) and batch migration might take a long time, depending on how many implementations there are. So when an event runs, it\u2019s possible that it will find a DB that\u2019s only partially migrated, with some subset of the implementations being up to date, and the remaining being outdated. This can result in an unreliable/unpredictable selection of implementation. This might be acceptable or not depending on the business use case. For example, an event might that runs periodically might select fewer implementations than otherwise would if the implementation were fully migrated, in which case the missed one would be selected on the next iteration. If the selection criteria, on the other hand, would select more implementations from the \u201cnot yet migrated\u201d subset, then this might not be acceptable.  \n**Recommendation** : Skye event execution shall be inactive until the batch migration is completed.",
        "# On-load vs. batch migration  \nSkye offers two distinctive approach to automatic implementation migration, both with their own benefits and disadvantages.  \n**On-load**  \nAn implementation can be migrated individually just while it\u2019s being loaded - the first time it\u2019s loaded after the new definition is activated. If the automatic migration feature is enabled and the implementation is outdated, then this will happen automatically.  \nThis is the default behavior once auto-migration is enabled.  \n**Batch**  \nImplementations can also be migrated as part of a batch process, running on the admin application as a background thread, iterating over each outdated implementation and migrating it.  \nA batch job can be started manually via JMX or can be configured to trigger automatically after deployment.  \nThis section is a digest of [**Automatic implementation migration - Innoveo Skye User Guide**](https://confluence.innoveo.com/is911/automatic-implementation-migration-149626988.html)**.**  \n|  | **On-load** | **Batch** |\n| --- | --- | --- |\n| **Trigger** | Automatically, when an implementation is loaded | Automatically after deployment **OR**Manually via JMX. |\n| **Performance** | First load time of implementations slightly increase after deployment. | Runtime is comparable to Export events: the larger the database the longer batch migration runs. |\n| **Risk of concurrent update** | No. | Yes. |\n| **Downtime** | Does not require downtime when used. Migration runs on implementation load - cannot cause concurrent update exception. | Requires downtime or must be run in low-usage times to reduce risk of concurrent update exceptions. |\n| **Coverage** | Risk of outdated implementations kept on the server if no action (event or user) affects them. | Migrates all outdated implementations.No risk of outdated implementations kept on the server. |",
        "## Activating the same definition while batch migration is running  \nThis use-case is common in development environment - where batch migration is enabled and a new version of a definition is being activated while implementations of the same definition are still being migrated, the automatic implementation migration can throw an error.  \nTo avoid this scenario you must ensure to use on-load migration on non-production environments.  \n<https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1999438350/Automatic+implementation+migration#Non-production-environments>",
        "## Batch auto-start  \n**Pre-requisites**  \nWhen batch auto-start migration is enabled on your environment a set of pre-requisites must be met before the deployment is started.\nThis is to ensure that no parallel updates on the same implementation can happen resulting in a concurrent update and inconsistencies in the data-set.  \n* **Disable Events** PRE Skye 9.14Blue  \n+ Ensure that no recurring events are configured: How events work and how to manage recurring events on production\n+ Request infra to stop any JMX jobs.\n+ Ensure that no Events are configured with \u2018Trigger Event when activating\u2019 enabled.\n* **Disable Task schedulers** POST SKYE 9.14Green  \n+ Disable recurring Task schedulers\n+ Ensure that no Task schedulers are configured with \u2018Schedule tasks when activating\u2019 enabled.  \n**Deployment**  \nThe batch migration will start as soon the deployer activates a specific definition to your environment.\nMigration jobs are created based on the definition version difference and executed in batches updating all implementations to the most recent version.  \nDepending on your database size this can take hours to complete.  \nThe maintenance page must be kept enabled and the application unused while the migration job runs.  \n**Post-deployment**  \nOnce the migration jobs finished you must verify the results (refer [Get migration results](https://confluence.innoveo.com/is916/automatic-implementation-migration-158619725.html#Automaticimplementationmigration-Getmigrationstatus(report))).\nIf the migration was successful the events can be restarted.  \n* **Enable Events** PRE Skye 9.14Blue  \n+ Request infra to restart all recurring JMX jobs.\n+ Trigger one-time jobs via JMX.\n* **Enable Task schedulers** POST SKYE 9.14Green  \n+ Enable recurring Task schedulers via JMX or from the Admin Console.\n+ Trigger one-time jobs via JMX or from the Admin Console.",
        "## Batch (manual start)  \nThis migration type is not necessarily connected to deployments.\nIdeally batch migrations must be run in low-usage periods of the application.  \n**Pre-requisites**  \n* Plan with migrations only in a low-usage period.\n* **Request infra** (via an ICSP) to start & stop migration jobs.\n* **Disable Events** PRE Skye 9.14Blue  \n+ Ensure that no recurring events are configured: How events work and how to manage recurring events on production\n+ Request infra to stop any JMX jobs.\n+ Ensure that no Events are configured with \u2018Trigger Event when activating\u2019 enabled.\n* **Disable Task schedulers** POST SKYE 9.14Green  \n+ Disable recurring Task schedulers\n+ Ensure that no Task schedulers are configured with \u2018Schedule tasks when activating\u2019 enabled.  \n**Execution**  \nInfra will start batch-migration at the start of defined time-window.\nMigration jobs are created based on the definition version difference and executed in batches updating all implementations to the most recent version.\nInfra will stop the running job at the end of the defined time-window and share the results.  \n**Post-execution**  \nOnce the migration jobs finished you must verify the results (refer [Get migration results](https://confluence.innoveo.com/is916/automatic-implementation-migration-158619725.html#Automaticimplementationmigration-Getmigrationstatus(report))).\nBased on the results further runs can be planned.",
        "## Usage  \n### Configuration  \nFor activating automatic migration please request it from Innoveo, for both on-load and batch mode.  \n**Auto-migration requires consistent implementation data in Skye datastore** , which is achieved when implementation migration was always properly executed before. If not then data cleanup first needs to be done before activating auto-migration, especially on production environments!  \nWhen batch (autostart) migration is enabled, batch auto-migration will start to run in following cases:  \n- on application startup\n- on definition activation  \nThere are some limitations and points to consider when enabling batch auto-migration in a multi-node setup, which are described [here](#limitations-in-multi-node-setups).  \n#### Skye properties  \nFollowing lists the `.yaml` and Skye properties for auto-migration for reference, please don't add those in a custom section but request their setting to Innoveo Operating!  \n| <div style=\"width:400px\">Property</div> | <div style=\"width:500px\">Description</div> | Default |\n| --------| ------------| --------|\n| skye.migration.enabled <br> yaml: `skye::core::config::migration::enabled` | Main toggle. When set to false, all migration related features are disabled. | false |\n| skye.migration.batch.autostart <br> yaml: `skye::core::config::migration::batch_autostart` | When set to true, the batch migration is initiated automatically. | false |\n| skye.migration.batch.load | CPU time that the batch migration thread is allowed to take. Takes a value between 0 (exclusive) and 1 (inclusive). E.g. 0.25 means that the batch migration is allowed to use up to 25% of CPU time. | 0.25 |\n| skye.migration.batch.chunk | Chunk size of migration job. Determines how many implementation are processed at a time (transaction scope). | 10 |",
        "## Limitations and best practices  \n### Limitations in multi-node setups  \nThe batch migration runs on the admin application. Currently, we deploy Skye with one admin application per tomcat instance. This means that in high-availability environments, there might be several admin applications running. This could result in parallel running batch migrations. As there isn\u2019t any synchronization mechanism between these two processes, it would be inefficient because it might result in a high number of concurrent update exceptions. To prevent this, batch migration shall only run on the eventing node and the batch-autostart property shall be disabled in the remaining nodes.  \nThis solves the problem of multiple batch migrations running in parallel but gives origin to another possible problem. When a definition activation goes through another node that has autostart disabled, then the migration node won\u2019t know that the definitions changed and the migration won\u2019t be automatically started. In this case, the autostart feature cannot be relied on and the migration should be started manually instead. On-load migration will still work in this case.",
        "### Pre-validation  \nAs a result of faulty past manual migrations, there might be data inconsistencies in existing Skye databases. Examples of these are missing attributes or bricks. The migration process has to make sure that it\u2019s not adding to the problem by creating inconsistencies that didn\u2019t exist before (e.g. duplicated attributes or bricks in case the implementation was manually migrated but the 'definition version' was not updated).  \nTo prevent this, each implementation is validated for consistency relative to its current definition, prior to the migration being applied. If a given implementation doesn\u2019t satisfy the preconditions for migration, it won\u2019t be migrated until it\u2019s fixed.  \nIf the pre-validation fails during batch migration, the problematic implementation will be skipped and the errors encountered will be stored in the DB. The migration of that particular implementation will not be reattempted until it\u2019s manually fixed. The process to handle these cases is described [here](#dealing-with-inconsistent-implementations). The migration job still proceeds with the remaining implementations.  \nIf, on the other hand, the pre-validation fails during an \u201con-load\u201d migration, then an exception will be thrown and inconsistencies found will be logged (in this case the errors are not stored in the DB).",
        "### Manual migration  \nWe expect that most custom logic migrations can be handled with the variable resolver capability. In cases where that isn\u2019t possible and manual migration is required through database scripts, there isn\u2019t a straightforward way of coordinating automatic migration with manual migrations. For this reason, it\u2019s recommended that automatic is not enabled when manual migrations are being run.",
        "# Common issues  \nIn case automatic implementation migration is enabled on your stage, there are still a set of scenarios you need to consider where it might not be suitable for the use-case.  \nPurpose of this section is to collect these scenarios and provide you guidance / solutions.  \nSome of these items may be mentioned on [**Limitations and best practices**](https://confluence.innoveo.com/is904/automatic-implementation-migration-134845159.html#Automaticimplementationmigration-Limitationsandbestpractices) page as well or resolved in newer Skye versions, **always use the documentation for reference**.",
        "### Migration flows  \nThere are 2 possible flows that result in the migration of an implementation: on load and in batch mode.  \n#### On-load  \nAn implementation can be migrated individually just while it\u2019s being loaded - the first time it\u2019s loaded after the new definition is activated. If the automatic migration feature is enabled and the implementation is outdated, then this will happen automatically.  \n#### Batch  \nImplementations can also be migrated as part of a batch process, running on the admin application as a background thread, iterating over each outdated implementation and migrating it. This process may run over long periods of time, generally without affecting the normal operation of the system, although there are some limitations and exception cases that should be considered, which are described in more detail in [Limitations and best practices](#limitations-and-best-practices).  \nThe batch migration is separated into different **jobs** . Each job migrates all outdated implementations associated only with one particular definition version. More than one job might be created if there are multiple definitions or implementations in different source versions for the same definition. The jobs are queued and run one at a time.  \nThe progress of each job and other migration-related metrics can be [monitored with JMX](#administration-and-monitoring).  \nSometimes, even though the definition changed, there are no structural changes (e.g. the case of modifying a text). In these cases, the implementations \u2018definition versions\u2019 still need to be updated to the current one but no further modifications are needed. To accomplish this without incurring the overhead cost of loading each implementation, a different type of job is launched which doesn\u2019t load the implementations into memory.",
        "### Event-heavy applications  \nFor event-heavy applications where a large number of recurring events updates implementations we can safely assume that on-load migration covers most outdated implementations ( over 75% ). In this scenario a combination of on-load and batch migration can be used to eliminate the required downtime for migration yet aiming at a complete migration coverage.  \n**On-load migration**  \n* Partial coverage.\n* No downtime.\n* Most implementations are updated during normal use of application.  \n**Hybrid approach**  \n* Complete coverage.\n* No downtime.\n* Most implementations are updated during normal use of application.\n* A batch job an be started in low-usage time window(s) to cover the remaining outdated implementations.  \n**Batch migration**  \n* Complete coverage.\n* Requires longer downtime.\n* All implementations are updated in a long running job.",
        "## UAT & PROD environments  \nInnoveo recommend two distinctive approach to automatic implementation migration based on the number of events running on the project.",
        "# Type of events  \nThis should apply **to all batch events**. What are batch events (as of Skye 7.31). [More details](https://confluence.innoveo.com/display/IS731/Event#Event-Singlevs.batchevents/)",
        "# Why do I have to change anything?  \nAs explained in the Migration - The Why part, post the first Go-Live you will have to adapt your existing implementations when your definitions change. This means that **you will have to add to/modify/delete from the production database using SQL scripts**. This shouldn\u2019t sound too scary, but scary enough to take this seriously.",
        "## Non-production environments  \nFor non-prod environments the **on-load migration** should be sufficient \u2013 this means no migration is started after a deployment and implementations are migrated on-the-fly when needed.  \nThis is to reduce deployment times on environments where deployment / activation is more frequent.",
        "## On-load  \n**Pre-requisites**  \nThere are no pre-requisites when planning with an on-load migration.  \n**Deployment**  \nThere are no particular changes in the deployment when planning with an on-load migration.  \n**Post-deployment**  \nVerify occasionally if there are any unmigrated implementations. If the number don\u2019t decrease over a couple of days, consider running a batch migration to cover the rest.",
        "## Dry run  \nIt is possible to perform a dry run of the migration by setting appropriate configuration property (see section *Configuration* ). The dry run performs all the operation like the real migration run but without updating the implementation_attribute table. Therefore, the tool works on the real data from the database, performs conversion, so that the migration can be verified, but doesn't modify any original data.  \nAll status and log information is written to the database tables \"*vr_migration_status_dry_run* \" and \"*vr_migration_log_dry_run* \" with the same data as for the real run.",
        "# Pre-requisites  \nAutomatic implementation migration expects a consistent Skye database.  \nFor details, refer [**Pre-validation | Automatic implementation migration - Innoveo Skye User Guide**](https://confluence.innoveo.com/is911/automatic-implementation-migration-149626988.html#Automaticimplementationmigration-Pre-validation)**.**",
        "# Purpose  \nThe purpose of this page is to give a step-by-step guide how to run migrations manually."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Fantastic job! The perfect faithfulness score of 1.00 indicates a seamless alignment between the actual output and the retrieval context, showcasing accurate and reliable information.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0174425,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Event selection criteria using attributes yet to be migrated may lead to improper implementation selection.\",\n    \"Batch migration can cause a database to be partially migrated, affecting event implementation selection.\",\n    \"Implementations can be migrated individually on-load or through batch processes.\",\n    \"On-load migration occurs automatically when an implementation is loaded for the first time after a new definition activation.\",\n    \"Batch migration runs as a background thread, updating outdated implementations in an admin application.\",\n    \"Batch migration requires downtime or low usage to avoid concurrent update exceptions.\",\n    \"Batch migration covers all outdated implementations without leaving any outdated on the server.\",\n    \"On-load migration might leave outdated implementations if no action affects them.\",\n    \"In high-availability setups, batch migration should only run on an eventing node to prevent parallel running issues.\",\n    \"Pre-validation checks for consistency relative to the current definition before migration.\",\n    \"If an implementation doesn't meet pre-validation, it will not be migrated until fixed.\",\n    \"Pre-validation failure logs errors during migration for on-load but skips problematic implementations for batch migration.\"\n] \n \nClaims:\n[\n    \"You can skip automatic migration for events by ensuring that no recurring events are configured.\",\n    \"Disabling events that are set to trigger when activating a definition is crucial to avoid concurrent updates and inconsistencies.\",\n    \"Detailed steps for managing this process are outlined under the section 'Batch auto-start' in the documentation.\",\n    \"The documentation for managing batch auto-start is available at https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1999438350.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.7142857142857143,
          "reason": "The score is 0.71 because while the answer partially addresses the question of skipping auto-migration for events, it includes references that are not directly relevant, such as prerequisites and documentation redirections. Nonetheless, the response provides some useful context relating to auto-migration processes, which justifies its current score.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.006060000000000001,
          "verboseLogs": "Statements:\n[\n    \"You can skip automatic migration for events.\",\n    \"Ensure no recurring events are configured.\",\n    \"Disable any events set to trigger when activating a definition.\",\n    \"This is important to prevent concurrent updates and inconsistencies.\",\n    \"Refer to the section on Batch auto-start for detailed steps.\",\n    \"The documentation outlines prerequisites for disabling events before batch migration.\",\n    \"Relevant documentation can be found on the provided link.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"This statement does not directly address skipping auto-migration for events but refers to prerequisites for disabling them.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"This statement directs to documentation, which may not be directly relevant to skipping auto-migration for events without checking the content.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.9,
          "reason": "The Retrieval Context includes all key aspects from the Context, such as the process and effect of batch vs. on-load migration, and limitations like the need for downtime or manual migration. It offers additional details on events selection criteria and process guidelines, enhancing the understanding of the implementation migration. There is a valid link provided enhancing utility. Minor context-specific recommendations are present but minimal differences do not affect comprehension significantly.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.01421,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Compare the content of CONTEXT and RETRIEVAL_CONTEXT to ensure all key information from CONTEXT is present in RETRIEVAL_CONTEXT.\",\n    \"Verify the presence of a valid link within RETRIEVAL_CONTEXT.\",\n    \"Assess whether the additional information in RETRIEVAL_CONTEXT enhances the understanding of CONTEXT.\",\n    \"Ensure that no critical information from CONTEXT is missing in RETRIEVAL_CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.3,
          "reason": "The Actual Output suggests skipping automatic migration by disabling events, which contradicts the Expected Output's statement that skipping is not possible. However, it provides additional documentation link and information that is not in Expected but not conflicting with it.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.00311,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the Actual Output and Expected Output to assess the closeness in content and meaning.\",\n    \"Verify if the Actual Output includes a link to documentation and ensure it aligns with the Expected Output requirements.\",\n    \"Check if the Actual Output contains any contradicting information compared to the Expected Output; contradictions are not acceptable.\",\n    \"Ensure that the Actual Output may contain more information than the Expected Output, as long as it does not contradict it.\"\n]"
        }
      ],
      "runDuration": 28.88950450000266,
      "evaluationCost": 0.040822500000000005,
      "order": 8
    },
    {
      "name": "test_customer_chatbot[test_case9]",
      "input": "is it possible to configure popup dialog windows in multibricks and action buttons within the same popup dialogs?",
      "actualOutput": "Yes, it is possible to configure pop-up dialog windows in multibricks and include action buttons within the same pop-up dialogs. You can create a pop-up dialog that displays attributes from the current process object or an entire process embedded inside the dialog. The action buttons can be configured to close the dialog or perform other actions as needed.\n\nFor detailed steps on how to configure pop-up dialogs and action buttons, you can refer to the following documentation links:\n\n1. **Pop-up dialogs**: [Pop-up dialogs documentation](https://confluence.innoveo.com/dosearchsite.action?queryString=pop-up-dialogs)\n2. **Action attributes**: [Action attribute documentation](https://confluence.innoveo.com/dosearchsite.action?queryString=action)\n\nThese resources will provide you with the necessary information to set up your desired configuration.",
      "expectedOutput": "-Currently not possible.\n-Popups can be opened via action attributes.\n-we can not put action attributes into multibricks dinamicaly.",
      "context": [
        "Pop-up dialogs\n# Overview\n\nPop-up dialogs can enhance the user experience of an Innoveo Skye application in many different ways.They can be used to display additional information, ask for the user's confirmation or display an entire process inside the dialog to structure a larger workflow.\n\n# Display attributes in a pop-up dialog\n\nThe dialogs that display attributes are configured in the UI definition using the Popup dialog UI element. The attributes that are assigned to the UI element and are visible in the context from which the dialog is opened will be displayed inside the dialog. These pop-up dialogs can be opened using the Action attributes.\n\n\nMultibricks\n# Overview\n\nIn different business cases it may be useful to define a set of attributes once in the definition but create multiple implementations of it.\n\nExamples:\n- Insure multiple drivers in one Motor policy\n- Insure multiple vehicles in one Motor policy\n- Insure multiple children in a family health insurance policy\n- Insure multiple locations in one Home policy\n- Insure multiple valuable items in one Home policy \n\nIn all of these cases the attributes to be captured for every single item (driver, vehicle, child, location, valuable item) are always the same. When you want to insure for example multiple drivers you will need the same information from the second and the third \u2013 e.g. first name, last name, date of birth and driving experience. In the product definition you don\u2019t want to define a specific number of additional drivers on different bricks and replicate all attributes n times. The idea is more to define the attributes to be captured for additional drivers once and then create them n times if needed.\n\n# Limitations\n- It is only possible to use fiedsets to group attributes belonging to multibricks (no panels or tabs).\n- Only one level of fieldsets is supported. No further bricks below the ones representing the fieldsets are possible.\n- In case fieldsets are configured for multibricks, it is not possible to assign attributes to the multibrick ui group itself.\n- It is not possible to make the fieldset group visible via dependencies configured on the attributes assigned to the fieldset groups.\n\n# Not supported\n## Use both components together\n\nIt is not possible to use for one multibrick the two configuration options in different channels. You have to decide for one or the other."
      ],
      "retrievalContext": [
        "## How to configure  \nThere are some configuration steps that have to be done for both options at the beginning. Beside adaptions in the product definition also some modification in the ui definition where the multibrick should be displayed in is needed. These configurations are described in the following section. Afterwards the steps specific for both options are listed in separate sub-chapters.  \nIn the UI definition a UI group needs to be defined which represents the multibrick. This multibrick UI group always has to be a child of another UI element (tab, panel, fieldset). The attributes of the multibrick in the product definition are then assigned to this brick in the ui definition.  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607140/1/1711441267000/UIDef.PNG)  \n1. In the UI definition add a UI group of type panel, tab, no style or fieldset to the UI Definition in which you want to display the multibrick attributes (here Valuables).\n1. Add multibrick UI group below the UI group where you want to display it in.\n1. Edit the text-id\n1. In the product definition add a brick where you add all attributes that belong to the multibrick (here Category, Sum insured, Description).\n1. Set minimum, initial and maximum usage as required.\n1. Set the visibility, sort order etc of all attributes created in step 5 as required and add the backend info 'DisplayGroups' where you put the text-id of the multibrick UI group brick created in step 2 as a value.",
        "## Fieldsets within multibricks  \nIt is possible to group the attributes which are assigned to a multibrick by fieldsets. Therefore the fieldset group brick and all bricks representing the fieldsets need to be added in the UI definition below the brick represents the multibrick UI group. Below you find the configuration details and mock ups with the according UI definitions for both multibrick options.",
        "### Display attributes in a pop-up dialog  \nThe dialogs that display attributes are configured in the[UI definition](../model-types/ui_definition/process-layout/_index.md) using the Popup dialog UI element. The attributes that are assigned to the UI element and are visible in the context from which the dialog is opened will be displayed inside the dialog. These pop-up dialogs can be opened using the [Action attributes](../attributes/specialized/action.md).  \n#### Steps to configure  \n1. Create and configure the attributes that will be displayed in the pop-up dialog in the process object definition. The attributes must be visible in the same context the dialog will be opened from.  \n1. If the user will use an action button to close the pop-up dialog, add the Action attribute in the process definition to the process step the dialog will be opened from. Set the \"Navigation\" property of the attribute to \"Close popup dialog\". You can find more information about the configuration in [Action attribute](../attributes/specialized/action.md).  \n1. Add a Popup dialog UI element to the root of the UI definition and assign the attributes from the process object and process definitions to the UI element. You can find more information about the configuration in[Process layout](../model-types/ui_definition/process-layout/_index.md).  \n1. Add an Action attribute in the process definition to the process step the dialog will be opened from. Set the \"Navigation\" property of the attribute to \"Open popup dialog\" and the \"Source of the dialog content\" property to \"UI element\". Select UI element created in step 3 in the \"Dialog UI group\" property. You can find more information about the configuration in [Action attribute](../attributes/specialized/action.md).",
        "### Limitations  \nThe following is not supported by multibricks using fieldsets:  \n- It is only possible to use fiedsets to group attributes belonging to multibricks (no panels or tabs).\n- Only one level of fieldsets is supported. No further bricks below the ones representing the fieldsets are possible.\n- In case fieldsets are configured for multibricks, it is not possible to assign attributes to the multibrick ui group itself.\n- It is not possible to make the fieldset group visible via dependencies configured on the attributes assigned to the fieldset groups.",
        "# Not supported  \n### Use both components together  \nIt is not possible to use for one multibrick the two configuration options in different channels. You have to decide for one or the other.",
        "### Add/remove component  \nIn this approach, some more configuration on the UI definition is needed:  \n1. On the UI definition, on the Multibrick UI group edit the following properties:  \n| Property | Value |\n| --- | --- |\n| Multibrick type   | Add/remove component   |\n| Multibrick text-id | _TextId of the multibrick that should be displayed (here \"Valuable\")_ |\n| Display with empty content | true (as you want to display the \"+\" section initially) |  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607137/1/1711441267000/image2019-3-1_10-42-40.png)  \n1. Add a text of type \u201caddButtonLabel\u201d to the brick and enter the text you want to be displayed next to the \u201c+\u201d icon (here \"Add valuable item\u201d).\n1. It is possible to display a text on the left of the \"-\" icon. Therefore add a text of type \"deleteButtonLabel\" to the brick (here \"Remove valuable item\").\n1. On the multibrick in the product definition you can add a text of type header using the function %indexNr() to number the created items  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607171/1/1711441268000/image2018-8-10_9-10-7.png)",
        "# Configuration  \n1. Create a multibrick in BC under the Product definition\n2. Add the attributes you need and set the visibility context\n3. Set the multibrick header: *Item #%indexNr()*\n4. Add a multibrick element to the UI definition and assign the attributes to be displayed\n5. Add the style class \u201cmulti-brick--tabs\u201c to the multibrick\n6. Open the UI-Theme folder under the project repository in VS Code\n7. Open the custom.js and place the snippet provided under [Attachments](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2016575610#III.-Attachments)\n8. Open a terminal under UI-Theme folder and execute: gulp watch-sass\n9. Open *\\_process-uigroups-multibrick.scss* file and place the snippet provided under [Attachments](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/2016575610#III.-Attachments)\n10. Save the scss file in order to compile a new css\n11. Add the custom.js, custom.css and custom.css.map files to the Resources definition ( or to the definition that includes these files in your project )\n12. Activate the changes",
        "### Configuration steps  \n1. In the UI definition below the multibrick UI group brick Add a UI group of type fieldset and specify the number of fieldsets required\n1. Edit the text-id.\n1. Edit the texts of type 'Header' of the UI elements. These headers are displayed as the titles of the fieldsets.\n1. In the product definition assign the attributes from the multibrick to the fieldsets, by adding the backend info 'DisplayGroups'. The value of this backend info is the brick text-id of the fieldset brick in the UI definition, where the attribute should be displayed in.  \n#### Service option - Example  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607170/1/1711441268000/image2018-8-10_9-10-50.png)  \nBelow you find the UIdefinition for the example above. The brick 'Valuables' represents the panel 'Valuables'. The brick 'ValuableMultibrick' is a multibrick with the Multibrick type set as service attribute'. The UI group 'FieldsetGroup' with 2 UI elements is added to the multibrick UI group.The attributes in the product definition are either assigned to the bricks 'Mandatory' or 'Optional' which are representing the fieldsets. (The header 'Valuable item #' is configured in the product definition on the multibrick as text of type 'Header'.)  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607138/1/1711441267000/image2019-3-1_10-54-45.png)",
        "---\ntitle: \"Pop-up dialogs\"\nweight: 40\n---  \nPop-up dialogs can enhance the user experience of an Innoveo Skye application in many different ways.They can be used to display additional information, ask for the user's confirmation or display an entire process inside the dialog to structure a larger workflow.  \nThe opening of a pop-up dialog is always initiated by a user interaction, such as clicking on an action button or a link. The content of a dialog can either be a set of attributes from the current process object or an entire Skye standalone process can be displayed inside the dialog. The dialog can be closed by its exit button and/or by action buttons inside the dialog (when configured accordingly).",
        "### Service attribute  \nThe main idea of this approach is to create a service attribute that controls via its value the number of created bricks.  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607152/1/1711441267000/image2013-9-30+17%3A32%3A36.png)  \nTo configure the multibricks using this component please continue with the following steps:  \n1. On the product definition create a service attribute on the parent brick of the multibrick and enter a name.\n1. Set its data type to \"Integer\".\n1. Add a value range to the attribute to restrict the number of valuables to the number specified as maximum usage (the configuration depends on the chosen input type).\n1. Set default value to the number of bricks that you would like to have. Note that in case you don't specify any default value or it's '0', the number of bricks created will be equal to the initial usage of the multibrick.\n1. Add a labeltext to the attribute.\n1. In the service tab enter the following value: DynamicBrickCountServiceDelegate\n1. Add a backend info of type \u201cTargetBrick\u201d and set as value the textId of the brick that should be created (here: Valuable).\n1. Configure this attribute as required (visibility, sort order, mandatory, display group,...)\n1. On the multibrick you can add a text of type header using the function %indexNr() to number the created items  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607134/1/1711441267000/image2018-8-10_9-9-27.png)\n1. On the UIdefinition, on the multibrick UI group select the 'Multibrick type' as 'Service attribute'  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607135/1/1711441267000/image2019-3-1_10-32-32.png)",
        "### Add/Remove component - Example  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607172/1/1711441268000/image2018-8-10_9-11-18.png)  \nBelow you find the UI definition for the example above. The brick 'ValuableMultibrick' is a multibrick with the Multibrick type set as 'Add/remove'. Also the properties 'Multibrick text-id' and 'Display with empty content' have to be considered. The UI group 'FieldsetGroup' with 2 UI elements is added to the multibrick UI group.The attributes in the product definition are either assigned to the bricks 'Mandatory' or 'Optional' which are representing the fieldsets. (The header 'Valuable item #' is configured in the product definition on the multibrick as text of type 'Header'.)  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607139/1/1711441267000/image2019-3-1_11-2-27.png)",
        "## Different ways to configure pop-up dialogs  \nBased on the content of the dialog, there is two main types of pop-up dialogs in Innoveo Skye: a dialog that displays attributes from the current process and process object and a dialog that has an entire process embedded.",
        "### Embed a process in a pop-up dialog  \nThe dialogs that display a process inside are either opened using the[Link attribute](../attributes/specialized/link.md) or the[Action attribute](../attributes/specialized/action.md). In both cases the process that is displayed inside the dialog is specified by the process start URL. Please note, that currently only standalone process component URLs are supported to be embedded in pop-up dialogs. You can find more information about standalone process URLs in [URLs](../urls.md).",
        "## Configure the Link attribute  \n### Link attribute properties  \n| Property | Description |\n| --- | --- |\n| Link URL | The target URL of the link. |\n| Link text | The label displayed in the link. |\n| Open link in | Specifies the behavior that happens when the user opens the link with a single click in the browser. <br> The possible options are: <ol><li>Current window or tab (depending on the user's browser settings)</li><li>New window or tab (depending on the user's browser settings)</li><li>Popup dialog</li></ol>  |\n| Dialog title | Specifies the title of the dialog in case the link is opened in a pop-up dialog. |\n| Display exit button | Specifies if an exit button is displayed in case the link is opened in a pop-up dialog. <br> In case the exit button is not displayed, the process inside the dialog must contain at least one action button that allows the user to close the pop-up dialog. |\n| Visibility | The visibility of the link when displayed on its own. When the visibility is set to \"read\" the link is visible and clickable for the user. |\n| Sort order | The sort order of the link when displayed on its own. |\n| Style class | The custom CSS classes that are applied to the attribute. |",
        "Multibrick as Tabs\ud83d\udcce",
        "# Limitations  \nWhen the link is configured to be opened in a pop-up dialog, the 'Link URL' must be the URL of a standalone process component. You can find more information about standalone process URLs in[URLs](../../urls.md).",
        "### Info texts  \nIn case an attribute is displayed as part of a container attribute, then its info text will not be displayed. To add some information for the user, the info text of the container attribute can be used.  \n#### Multibricks  \nTo use a container attribute on a [multibrick](../../multi-bricks.md), the attribute itself and all its assigned ones need to be located on the multibrick.",
        "### Service attribute  \nIf you use this possibility to add/delete multibricks you need a service attribute that controls the creation of the multibricks. The value (integer) of this attribute dictates how many bricks are created. The value of this attribute can either be set by the user or automatically by dependency or via excel. If set automatically, the service attribute can be hidden.  \nIn our example below this service attribute is displayed in the screen (No of valuables) and controls the number of valuable items to create.  \nIf you increase the value of the service attribute the respective number of valuable items will be added after the already existing ones. If you decrease the value the number of bricks will be reduced to the specified value starting by the last item. So it is not possible to directly delete e.g. the second valuable item but not the third.  \n![screenshot](https://confluence.innoveo.com/is914/files/158607130/158607131/1/1711441267000/image2018-8-10_9-8-15.png)",
        "# Purpose  \nThe user can create multibrick element in Skye, however, the default output is to have all multibrick items visible and in a column layout. This implementation allows turning multibrick items into tabs. The benfit of this is to save space on the page.",
        "---\ntitle: \"Multibricks\"\n---  \nIn different business cases it may be useful to define a set of attributes once in the definition but create multiple implementations of it.  \n**Examples:**  \n- Insure multiple drivers in one Motor policy\n- Insure multiple vehicles in one Motor policy\n- Insure multiple children in a family health insurance policy\n- Insure multiple locations in one Home policy\n- Insure multiple valuable items in one Home policy  \nIn all of these cases the attributes to be captured for every single item (driver, vehicle, child, location, valuable item) are always the same. When you want to insure for example multiple drivers you will need the same information from the second and the third \u2013 e.g. first name, last name, date of birth and driving experience. In the product definition you don\u2019t want to define a specific number of additional drivers on different bricks and replicate all attributes n times. The idea is more to define the attributes to be captured for additional drivers once and then create them n times if needed."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the actual output perfectly aligns with the information in the retrieval context, demonstrating full faithfulness and accuracy.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0185175,
          "verboseLogs": "Truths (limit=None):\n[\n    \"A UI group definition is required to represent the multibrick in the UI definition.\",\n    \"A multibrick UI group must be a child of another UI element, such as a tab, panel, or fieldset.\",\n    \"Attributes in the product definition are assigned to the multibrick in the UI definition.\",\n    \"Pop-up dialogs enhance the user experience in Innoveo Skye applications by displaying additional information or entire processes.\",\n    \"Service attributes control the number of created bricks via their value.\",\n    \"Attributes in the product definition are displayed based on their visibility, sort order, and backend info 'DisplayGroups'.\",\n    \"The multibrick UI can be configured to display with empty content initially.\",\n    \"Only one level of fieldsets is supported in multibricks; no further bricks below them are allowed.\",\n    \"Configuration steps must define UI elements with specified properties in the UI definition.\",\n    \"The Link attribute can open pop-up dialogs if the URL points to a standalone process component.\",\n    \"Multibricks are used in scenarios that require repeated similar information, like insuring multiple drivers under one policy.\"\n] \n \nClaims:\n[\n    \"It is possible to configure pop-up dialog windows in multibricks and include action buttons within the same dialogs.\",\n    \"Pop-up dialogs can display attributes from the current process object or an entire process embedded inside the dialog.\",\n    \"Action buttons within pop-up dialogs can be configured to close the dialog or perform other actions as needed.\",\n    \"Documentation for configuring pop-up dialogs and action buttons can be accessed online.\",\n    \"The provided documentation links offer steps for setting up pop-up dialogs and action buttons.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.7777777777777778,
          "reason": "The score is 0.78 because while the response touches upon configuring pop-up dialogs and action buttons, it includes details about process attributes and displaying entire processes, which diverts slightly from the main query.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.006685000000000001,
          "verboseLogs": "Statements:\n[\n    \"It is possible to configure pop-up dialog windows in multibricks.\",\n    \"Action buttons can be included within the same pop-up dialogs.\",\n    \"A pop-up dialog can display attributes from the current process object.\",\n    \"The dialog can display an entire process embedded inside it.\",\n    \"Action buttons can be configured to close the dialog or perform other actions as needed.\",\n    \"Detailed steps can be found in documentation links.\",\n    \"Pop-up dialog configuration details are on the provided documentation link.\",\n    \"Action attribute configuration details are in the provided documentation link.\",\n    \"These resources offer necessary information to set up the desired configuration.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Displaying attributes from the current process object doesn't directly address the query about configuring pop-up dialogs and action buttons.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Displaying an entire process within a pop-up dialog does not directly relate to the configuration query about dialog and action buttons.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.9,
          "reason": "RETRIEVAL_CONTEXT accurately covers pop-up dialogs and multibricks from CONTEXT, including configuration details and Limitations. Hyperlinks are present as required. There is no contradiction with CONTEXT information. The tone and terminology are consistent between CONTEXT and RETRIEVAL_CONTEXT.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0137725,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Verify that all key points in CONTEXT are accurately covered in RETRIEVAL_CONTEXT.\",\n    \"Ensure that RETRIEVAL_CONTEXT contains a hyperlink as expected.\",\n    \"Confirm that any additional information in RETRIEVAL_CONTEXT does not contradict or misinterpret CONTEXT.\",\n    \"Check for consistency in tone and terminology between CONTEXT and RETRIEVAL_CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.2,
          "reason": "The Actual Output contradicts the Expected Output by stating it is possible to configure pop-up dialogs with action buttons, unlike the Expected Output which states it is not currently possible. It does include documentation links, but the content conflicts significantly with the expectations.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.003215,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"1. Compare the Actual Output and Expected Output to determine how similar they are in content and structure.\",\n    \"2. Check if the Actual Output includes a link to documentation as stated in the Expected Output.\",\n    \"3. Ensure that any additional information in the Actual Output does not contradict the Expected Output.\",\n    \"4. Verify that the Actual Output aligns with all key points of the Expected Output without opposing them.\"\n]"
        }
      ],
      "runDuration": 25.821580665997317,
      "evaluationCost": 0.04219,
      "order": 9
    },
    {
      "name": "test_customer_chatbot[test_case10]",
      "input": "How can I access a jumphost from putty?",
      "actualOutput": "To access a jumphost from PuTTY, follow these steps:\n\n1. **Open PuTTY**: Launch the PuTTY application on your computer.\n\n2. **Configure the Session**:\n   - In the \"Session\" category, enter the **Host Name** of the jumphost (e.g., `jumphost.ext.innoveo.net`).\n   - Set the **Port** to `22`.\n   - Ensure that the **Connection type** is set to `SSH`.\n\n3. **Save the Session**:\n   - Under \"Saved Sessions\", type a name for your connection (e.g., \"MyJumphost\") and click the **Save** button.\n\n4. **Connect to the Jumphost**:\n   - Click the **Open** button to initiate the connection.\n   - If prompted, enter your username and password for the jumphost.\n\n5. **Using Tunnels (if needed)**:\n   - If you need to set up tunnels to access other stages or databases, navigate to **Connection > SSH > Tunnels** in the left-hand menu.\n   - Enter the **Source port** and **Destination** as required, then click **Add**.\n\n6. **Save Configuration**: After setting up any tunnels, return to the \"Session\" category and save your configuration again.\n\nFor detailed instructions, you can refer to the documentation here: [Setting up jumphost connection and tunnels](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1798701129).",
      "expectedOutput": "Mention private-public keys\nGive SSH Authentication related steps\nExplain choosing desired stage from jumphost",
      "context": [
        "# How to connect to a SkyeStage\n\nThere are two types of Skye stages: \n- where we have jumphost (saas), usually used for customer environments\n- where we don't have jumphost (local), usually used for demo/training/SkyeTest stages\n\n# How to connect\n\n1. Add the host name you have\n2. Install pageant and load your ssh key\n3. Go to Connection/SSH/Auth and browse your private key and tick in \"Allow agent forwarding\"\n4. Save your connection on the session tab and click open\n5. In the Connection/Data points you can define your username. This is something Innoveo generates for you, usually with the following pattern: inn+first two letter of first name + first to latter of last name. So for John Doe, it would be innjodo.\n6. Once you are connected to jumphost, type \"ssh \" (there is a space at the end) and press tab twice. Copy the stage you want to connect.\n7. Type \"ssh STAGENAME\" and press enter. Change STAGENAME to value you copied in point 5."
      ],
      "retrievalContext": [
        "## Setting up jumphost connection and tunnels  \n**Step 1:**  \n* Open Putty, navigate to \u201csession\u201d, and set up your connection to the jumphost stage as usual - provide \u201cHost Name\u201d of jumphost, set port as \u201c22\u201d, select \u201cSSH\u201d as connection type.  \n**Step 2:**  \n* Type a name under \u201cSaved Sessions\u201d for your connection, and save the session  \n**Step 3:**  \n* Navigate to SSH/Tunnels on the left hand side  \n**Step 4:**  \n* You now have to type a port number into \u201cSource port\u201d, and add as \u201cDestination\u201d the host name of your stage (that you would like to access the database of), along with port \u201c22\u201d\n* Source port should be \u201c2222\u201d\n* Destination should be your stage. You can connect to your jumphost, type \u201cssh\u201d, press space, and press tab twice to see the available host names for your stages, as seen on the below screenshot  \n* I will connect to UAT database eventually, so I will take the host name of UAT, and append port 22 to the end, like so: [app01.uat.int.oman.innoveo-skye.net:22](http://app01.uat.int.oman.innoveo-skye.net:22)\n* Enter these details and press \u201cAdd\u201d  \n* Now navigate to \u201csession\u201d and save the configuration",
        "# Scope  \nThis document intends to describe how to configure multi-hop tunneling in Putty to connect to a DB, if database connection is not allowed directly from jumphost, but only from a stage.",
        "How to use Putty",
        "# Putty  \nFrom a jumphost, you will be able to connect to each host or node, it will look something like below (use ssh{space}{tab}{tab} to view shortcuts):  \nYou can see how the UAT instance has multiple hosts which the user can connect to.  \nevent01 generally handles the running of all events in the Skye application  \napp01 and app02 generally handle traffic, business logic etc.  \nAfter connecting to either host, the usual commands will be available (e.g. -log, -properties, -log4j).",
        "# Overview  \nPreviously the database connections were enabled from jumphost. You could create a tunnel from jumphost in Putty client, and you could access the database with MySQL Workbench. This set-up is described here: How to connect to database (regular)  \n* Due to security reasons this has been changed and database connections are no longer allowed from jumphost. Database connections are only possible from the stage directly. Some projects are already operating with this in mind.  \nDue to this reason some modifications have to be made in both the Putty client and the MySQL Workbench connection\u2019s configuration to set up a database connection. This will be described below.",
        "# SSH  \nWe use SSH (with SSH keys for authentication) to connect to the server to have the ability to restart it or change some parameters. You can connect to a jumphost and you can connect to the actual environments from there.  \n* Recommended software: [PuTTY](https://www.putty.org/)\n* Example endpoint: jumphost.ext.innoveo.net",
        "# Putty  \nFrom a jumphost, you will be able to connect to each node, it will look something like below. You can use the command ssh{space}{tab}{tab} to view shortcuts.  \nnoneapp01.uat.int.example.innoveo-skye.net app02.uat.int.example.innoveo-skye.net event01.uat.int.example.innoveo-skye.net  \nIn this example you can see that for the \u2018example\u2019 project in the \u2018uat\u2019 cluster we have three nodes called \u2018app01\u2019, \u2018app02\u2019, \u2018event01\u2019.  \n* event01 generally handles the running of all events in the Skye application.\n* app01 and app02 generally handle traffic, business logic etc.  \nAfter connecting to either node, the usual commands will be available (e.g. -log, -properties, -log4j).",
        "# Infrastructure  \nIn general, for security reasons we are not letting anybody to connect the database directly, you have to join with ssh first and use putty to be a tunnel between your computer and the database. Note: on a stage which uses jumphost, you connect to jumphost first. It makes no difference if you connect to the particular stage (like dev/uat). For security reasons, sometimes infra does not enable you to connect to UAT from jumphost directly - so if at the end it still does not work on a UAT, but it works on a DEV, reach out to the infra team to make sure that they enabled the database connections from jumphost.",
        "## Configuring MySQL Workbench  \n**Step 7:**  \n* Open MySQL Workbench and set up a new connection  \n* Set up a connection name (can be anything)\n* Connection method must be TCP/IP\n* Host name should be \u201c127.0.0.1\u201d, and port should be the port that you have set in Putty under \u201cSource port\u201d in **Step 6** - In my case, \u201c3011\u201d\n* Username and password can be taken from Putty, through typing this command while connected to the stage: grep config::db: /opt/skyeconfig/hiera/data/\\* -R  \n* Set the details  \n* Before being able to test the connection, you must:  \n1, Connect with Putty to jumphost that we have set up in **Steps 1-4**  \n2, Connect with Putty to the second session (127.0.0.1 or localhost) that we have set up in **Steps 5-6**  \n* If you are connected to both, test the connection to make sure everything is working as expected",
        "# Instructions  \n1. Open Putty \u2192 Connection \u2192 SSH \u2192 Tunnels \u2192\nSource Port : 5011 (selectable range 5000-6000)\nDestination: <node>:8080 \u2192 for example: [app01.dev.int.oman.innoveo-skye.net:8080](http://app01.dev.int.oman.innoveo-skye.net:8080)\n2. Run Putty (no need to ssh any stage)\n3. Open Postman \u2192 Select the gear icon)  \n(gear icon)\n4. Settings \u2192 Proxy \u2192 Add a custom proxy configuration \u2192\nProxy Type: HTTP / HTTPS\nProxy Server: 127.0.0.1 : 5001 (port should be equal with the Source Port)\nProxy Auth: OFF\n5. You can call the API \u2192 <http://localhost:8443/apis/><api endpoint> (If your API is having Authorization header, please include it in the header)  \nIf you don\u2019t want to use Postman, you can call APIs inside Putty, to do this ->\n1. ssh to the node \u2192 for example: ssh [app01.dev.int.oman.innoveo-skye.net:8080](http://app01.dev.int.oman.innoveo-skye.net:8080)\n2. curl -v <http://localhost:8443/apis/><api-endpoint>  \nIn case if you have auth header(Basic Authorization/Oauth Authorization) :  \ncurl -v http://localhost:8443/apis/<api-endpoint> -H \u201cAuthorization: Basic: <base64code>\u201c\ncurl -v <http://localhost:8443/apis/><api-endpoint> -H \u201cAuthorization: Bearer: <code>\u201c  \nSkyeapp \u2192 <http://localhost:8443>\nSkyeum \u2192 http://localhost:8082/skyeum",
        "# How to connect to a SkyeStage  \nThere are two types of Skye stages  \n* where we have jumphost (saas), usually used for customer environments\n* where we don't have jumphost (local), usually used for demo/training/SkyeTest stages  \n**Jumphost**  \nWhat is jumphost?*A jump host (also known as a jump server) is an intermediary host or an SSH gateway to a remote network.*Jumphost is a middle layer between you and the stage which enables outside connections (for specific IP-s). Usually every remote connection to a Skye server is closed, you can only connect to it from jumphost.",
        "### **Why should you use it?**  \nSetting up and using Windows' built-in SSH is simpler and more convenient than PuTTY.  \nHere's why:  \n* **Easy Integration:**  \n+ It works seamlessly with Windows, no extra hassle.\n* **Straightforward Usage:**  \n+ You can use it directly from the command line, making things easier.\n* **Useful Features:**  \n+ It lets you log your sessions and set up secure communication tunnels.\n* **Reliability:**  \n+ Expect stable connections with minimal disruptions, unlike PuTTY. ( after a couple of months of testing )\n+ Faster\n* **Simple Setup:**  \n+ No need for extra configurations or checkboxes, just enter your username and the jump host.\n* **Key Management Made Easy:**  \n+ No more dealing with PuTTYgen; key management is integrated.\n* **User-Friendly:**  \n+ Setting up logging and tunnels is a breeze.",
        "# What do you need to perform it?  \n* SSH access to the server\n* Putty or another SSH client (Windows also has a built-in SSH client)",
        "# Purpose  \nThis page aims to collect all you need to know about working with Putty on your Skye environment.  \n**What is Putty?**  \nPutty is basically a terminal simulator which allows us to access the LINUX servers safely. After you set up your connection and opened it, a terminal will open. Here you can use linux terminal commands (in case you need to google how to do something, this is were you can start)",
        "## Differences between jumphost and non-jumphost  \nOn a Point 5 and 6 is not required. When you open the connection, you get connected to the stage directly.",
        "Access blocked/restricted internal APIs from Postman (Putty Tunneling)",
        "Jumplead Documentation",
        "# Access the logs  \nWhen you want to use putty to debug some problem, you can access the log with the StageName-log keyword (StageName is the stage you are currently using).  \nBut sometimes the log doesn\u2019t give you enough information, so you have to change the log settings. You can do this by using the StageName-log4j command. This opens up an editor where you can modify the settings.",
        "# Instructions  \nUsually, you can not connect to customer stages directly, you need to use putty to create a tunnel first and connect through that tunnel.",
        "## Connect to the database  \n1. Open the session and copy paste (you can paste commands on putty if you right click) the following command:\n1. stages with jumphost: connect to your stage (not only jumphost) and execute:*grep config::db: /opt/skyeconfig/hiera/data/\\* -R*\n2. stages without jumphost: connect to your stage and execute:*grep config::db: /opt/skye\\_install/hiera/data/\\* -R*\n2. Copy paste the information you get to a different file, because you will need it in step 8\n1. Since 7.30 only the database's host is stored in this file. You can grab the password with the following command:\n`puppet lookup skye==fchbdev1a==config==db==schema_owner_password --hiera_config /opt/skyeconfig/hiera/hiera_custom.yaml`\nchange**fchbdev1a** to your projects small code (what you see in front of -log)\n3. Open Putty again, load the created session and go to Connection\\SSH\\Tunnels\n1. on the *Add new forwarded port* section\n1. add a port to the *Source port*, e.g. 3011 (can be anything), it represents the port you will connect to the database\n1. jumphost stages: to the destination add: what you see in the host and add :3306 to the end. eg:[rakbank-skyedb-dev.int.saas11.innoveo-skye.net](http://rakbank-skyedb-dev.int.saas11.innoveo-skye.net):3306\n2. non-jumphost stages: to the *destination* add: localhost:3306\n2. click add\n4. Save the session again and open it\n5. Open MySQL Workbench and start setup a new connection with the plus button next to MySQL Connections\n1. Define the *Connection Name*: e.g.: \u201ctest connection\u201d\n2. *Connection method* is *Standard (TCP/IP)*\n3. To *hostname* add \u201c127.0.0.1\u201d\n4. To *port* add the port defined in the Putty Tunnels Source port e.g.: 3011\n5. To *username* copy the username from the file you created on step 4 (name of the schema, in the example: *rakbankdev1a*)\n6. To the *password* choose *Store in Vault\u2026* and copy the password from the file as well.\n7. Test the connection\n1. If you can\u2019t connect check whether you connected to the VPN and the Putty session is opened and connected\n6. Save the connection"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions, ensuring complete alignment and harmony between the actual output and the retrieval context. This impeccable result demonstrates a perfect faithful representation of the original information.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.01841,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Putty is used as a terminal simulator to access Linux servers safely.\",\n    \"Setting up SSH connections and tunneling is a process that can be managed through Putty.\",\n    \"Jumphost serves as an intermediary host or SSH gateway to a remote network.\",\n    \"For security reasons, direct database connections from jumphost are not allowed; connections must be made from the stage.\",\n    \"Setting up SSH connections and tunneling is essential for accessing secure environments.\",\n    \"Multiple host nodes like app01, app02, and event01 handle specific tasks like traffic, business logic, and event handling.\",\n    \"Sessions on Putty allow for secure communication tunnels and session logging.\",\n    \"Various configurations must be modified in Putty and MySQL Workbench to establish a successful database connection.\",\n    \"Putty allows SSH connections to jumphosts and other intermediate servers before connecting to a target environment.\",\n    \"Skye environments may differ with jumphost and non-jumphost setups, impacting how access and connections are configured.\"\n] \n \nClaims:\n[\n    \"To access a jumphost from PuTTY, you must first launch the PuTTY application on your computer.\",\n    \"In the 'Session' category of PuTTY, you need to enter the Host Name of the jumphost.\",\n    \"The Port should be set to 22 when configuring a session in PuTTY for accessing a jumphost.\",\n    \"The Connection type must be set to SSH in PuTTY when accessing a jumphost.\",\n    \"To save a session in PuTTY, type a name for your connection under 'Saved Sessions' and click the Save button.\",\n    \"To connect to the jumphost in PuTTY, click the Open button and enter your username and password if prompted.\",\n    \"If tunnels are required, navigate to Connection > SSH > Tunnels in PuTTY's left-hand menu.\",\n    \"In the Tunnels section, enter the Source port and Destination as needed and click Add.\",\n    \"After configuring tunnels, return to the 'Session' category in PuTTY to save your configuration again.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the response perfectly addresses the query on how to access a jumphost from Putty, without including any irrelevant information. Excellent job!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0067800000000000004,
          "verboseLogs": "Statements:\n[\n    \"Open PuTTY application on your computer.\",\n    \"In the 'Session' category, enter the Host Name of the jumphost.\",\n    \"Set the Port to 22.\",\n    \"Ensure the Connection type is set to SSH.\",\n    \"Under 'Saved Sessions', type a name for your connection.\",\n    \"Click the Save button.\",\n    \"Click the Open button to initiate the connection.\",\n    \"Enter your username and password if prompted.\",\n    \"Navigate to 'Connection > SSH > Tunnels' to set up tunnels.\",\n    \"Enter the Source port and Destination as required.\",\n    \"Click Add to set up tunnels.\",\n    \"Return to the 'Session' category and save your configuration again.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.5290887705313339,
          "reason": "The retrieval context includes relevant details such as setting up a connection using SSH and configuring ports, similar to the context. However, it lacks specific steps like adding hostname, installing pageant, and defining the username pattern in detail. It also contains additional information about database connections and Putty configurations not present in the context, which could potentially confuse readers due to its complexity and lack of direct relevance.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.011260000000000001,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if RETRIEVAL_CONTEXT contains the main points and critical information present in CONTEXT.\",\n    \"Verify that RETRIEVAL_CONTEXT includes any necessary links even if they are not present in CONTEXT.\",\n    \"Ensure that additional information in RETRIEVAL_CONTEXT does not contradict or misrepresent the core content of CONTEXT.\",\n    \"Assess if RETRIEVAL_CONTEXT maintains consistency with CONTEXT in terms of factual accuracy and relevance.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.3,
          "reason": "The Actual Output provides detailed steps to connect to a jumphost using PuTTY, contains a link to relevant documentation, and includes information on setting up tunnels. However, it lacks instructions on using private-public keys, SSH Authentication, and choosing the desired stage, as mentioned in the Expected Output.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0035125,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the Actual Output to the Expected Output to determine similarity in content and intention.\",\n    \"Check the Actual Output for the presence of a link to relevant documentation.\",\n    \"Assess whether the Actual Output contains additional information beyond the Expected Output; ensure this information is supplementary and not contradictory.\",\n    \"Verify that there is no conflicting information between the Actual Output and the Expected Output.\"\n]"
        }
      ],
      "runDuration": 23.209917125001084,
      "evaluationCost": 0.039962500000000005,
      "order": 10
    },
    {
      "name": "test_customer_chatbot[test_case11]",
      "input": "What do I have to provide in my ticket when asking for support?",
      "actualOutput": "When asking for support and raising a ticket, you should include the following information to ensure a properly written ticket that saves time for all parties involved:\n\n1. **Skye Version**: Specify the version of the Skye application you are using.\n2. **Reproduction Steps**: Clearly outline the steps to reproduce the issue you are facing.\n3. **Relevant Definitions & Attributes**: Include any definitions or attributes that are pertinent to your issue.\n4. **What You Tried to Do**: Describe the actions you took in an attempt to resolve the issue.\n5. **What Your Expectations Are**: Explain what you expected to happen.\n6. **What You Experience**: Detail what actually happened instead of your expectations.\n7. **Attachments**: If applicable, attach a Postman collection or a WSDL + sample request if you are having trouble with building an integration.\n\nAdditionally, it is helpful to provide screenshots and any other relevant information that can assist in resolving your issue.\n\nFor more detailed guidance, you can refer to the documentation here: [How to raise a support ticket](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1798930435).",
      "expectedOutput": "Skye version and environment specs\nDetailed description of the issue\nAffected definitions\nURLs when relevant",
      "context": [
        "# What is a support ticket\n\nIncludes, but is not restricted to:\n- acquiring a new service from Partner Service Catalog \n- you don\u2019t know how to configure something\n- you know how to configure something but it does not work\n- you have a question regarding the application\n- you need help designing a solution for your requirements\n\n# What to include in the support ticket\n\nIn general, share all information necessary for analysis.\nTo be able to work on reported issues it is important, that the following information is provided in each ticket:\n\n- The version of Skye where the issue happens\n- A detailed description of the issue (step by step description) and expected behavior: \n    - Please also specify the involved attributes by <Brick.TextId>\n- Url to access the stage and Business Canvas server settings in order to reproduce\n- In case a private journey, a link to a confluence page where the username/password is available\n- If you think is a UI issue please specified: \n    - Browser\n    - Check behavior without the custom CSS / custom js\n        - this means deleting the custom CSS, restarting the stage and then checking again\n- Define which definition you have a problem with and share which stage we can pull the definitions from"
      ],
      "retrievalContext": [
        "How to raise a support ticket",
        "# What is a support ticket  \nIncludes, but is not restricted to:  \n* acquiring a new service from Partner Service Catalog\n* you don\u2019t know how to configure something\n* you know how to configure something but it does not work\n* you have a question regarding the application\n* you need help designing a solution for your requirements",
        "How to raise an infra-ticket",
        "### The Support Process  \n#### Tickets  \nWe use tickets as the main source of support: please open a ticket for every issue you have: This helps us: most of the time, as the collaboration matures your questions will start to be more complicated and we will not be able to resolve them on the spot. It helps you because your issues will be searchable.  \n##### Support yourself!  \nWe are constantly generating new and new documentation. Please make sure that you went through this guide before you reached out help to us: Config 101 - What to do when I am stuck?  \n##### What to include in your support ticket  \nA properly written ticket saves time for all parties. We ask you to please always add:  \n* Skye Version\n* Reproduction steps\n* Relevant definitions & attributes\n* What you tried to do & What your expectations are & What you experience\n* If you have trouble with building an integration, then make sure that you attach a postman collection or a wsdl + sample request so we can trigger the integration ourselves.  \nPlease consider that we provide application support and not function support: in case there is an issue you must do an analysis on it before reporting to us.  \n#### Meetings  \nWe offer daily meetings during the Honeymoon period, this typically decreases to 2-3x weekly meetings \u2013 this is up for discussion at the end of the honeymoon period.",
        "## **4.2 Send the support ticket to the senior team member**  \n* The senior members within your project / unit are responsible for the quality of outgoing questions. Ask them to verify the quality of your ticket if you are not sure!",
        "# What is an infra ticket  \nIncludes, but is not restricted to:  \n* anything related to the environments\n* anything related to accesses\n* change in infrastructure / question about infrastructure\n* Incidents  \nFor deployment-related questions, please read this guide before opening a ticket: What to do if my deployment failed?",
        "## What to add to the ticket  \nAs a general thumb rule, we prefer if the tickets from one project are handled by one person - due to holidays and possible conflicts, this is not always possible.  \nPlease provide all the relevant information in connection with the support activity. (The more accurate this field is, the less back and forth we have to do). Screenshots are really helpful, please provide them if possible.  \nPlease make sure, that in one form or the other, these details are available:",
        "# Types of Support  \n## Infrastructure support  \nInfrastructure support happens via [ICSP](https://innoveo.atlassian.net/servicedesk/customer/portals) portal. The responsible for infrastructure and operations support is the Customer Support Manager (currently: Shebu). For these tickets, consider him as your escalation path. Typical infrastructure topics are:  \n* Accesses\n* IP whitelisting\n* Certificates\n* Stage issues\n* Deployment issues (read What to do if my deployment failed? first!)",
        "### Reporting an issue  \n* The best is to report it with a screenshot.\n* Make sure that the link and steps to reach the page are shared in the ticket (or another ticket with the description is shared)",
        "# What to do  \nThis is being set up by infra. You have to gather some input from the customer and then open an infra ticket so they can set it up.",
        "## **4.3 Collaborate with SolEng on the resolution**  \n* **Ticket distribution**  \n+ In case a support ticket is not very urgent, just leave it in an open status and sol. eng. will take it up on best effort basis.\n+ In case of a blocking issue, do the following:  \n- Send a message to [Sol. Eng. support channel](https://teams.microsoft.com/l/channel/19%3Af890918dd26a478b8fcf8e830556379d%40thread.skype/SolEng%20Support%20(Ex%20Product%20BA)?groupId=e879c7c3-18f2-477d-9ee1-5deaf4b6b81c&tenantId=de9dd080-6e04-4524-9010-e747ec897e4b)\n- This message should contain  \n* JIRA ticket number\n* A short description of the issue (e.g. ticket summary)\n* Url of the ticket in order to access the ticket easily",
        "# How to open infra ticket  \nYou can open a ticket here: <https://innoveo.atlassian.net/servicedesk/customer/portals>",
        "### Ticket-specific details  \n* Application url\n* Credentials\n* How to reach the part of the application",
        "## Access:  \nPost the instance creation, multiple tickets need to be created for below listed tools.  \nAs a first step, ticket needs to be created for IP whitelisting for partners to access Sandbox / Lab instances and environments.  \nNote: These IPs are not specific to any user's system but from the Partners network level which is static in nature.  \n| **Requirement** | **Details Required** | **Ticket** |\n| --- | --- | --- |\n| **IP whitelisting** | Static IP address from Partner company (Note: Not user system specific IPs) | Need to create a request ticket in Support portal <https://innoveo.atlassian.net/servicedesk/customer/portal/13> |  \n| **Tools** | **Details Required** | **Ticket** |\n| --- | --- | --- |\n| **Putty / SSH Access** | Public Keys is required from user. | Need to create one request ticket in Support portal <https://innoveo.atlassian.net/servicedesk/customer/portal/13> |\n| **Repository Access required (GIT, GrayLog, Teamcity)** | If applicable |\n| **JIRA Support Portal Access & Project Access** | If project access is required need to specify the project details in the ticket |",
        "## Access to Customer support Portal  \nRespective Innoveo project manager is also responsible to create a ticket on behalf of partners SPOC for customer support portal access, Jira project access & confluence access.  \nOnce the partner SPOC is granted required access, he / she can submit tickets on behalf of others in the partner organization for all other access including Jira, SSH, GIT. etc.  \nUse the below link to request access:  \n<https://innoveo.atlassian.net/servicedesk/customer/portal/13/group/62/create/208>  \nSummary: write a short description of your request, e.g.: \u201cNew accesses for the customer portal\u201d  \nDescription: Share the email addresses of the people who needs Customer Portal access.  \nServices: Other",
        "## **4.1 Create a Support ticket in JIRA**  \n### What your ticket must always include  \nnote  \nPlease make sure to follow these key points when opening a support ticket:  \n* You need to make an effort to fix on your own which you are expected to document when reaching higher level of support with the included artifacts (so they know you tried it!)  \n+ + You always score a few brownie points if you show that you tried to resolve the issue yourself!\n* The SUP ticket is for a Skye related problem. A certain attribute or feature in Skye is not behaving how you would expect. Avoid opening tickets with your project context problem  \n+ Good example  \n- *\u201cWhen the excel at Referrel.LogicExcel in the attached Referral definition gets triggered I would expect that it sets the value to of Referral.noIssuesFound to TRUE. I see in the log, but when I verify in the database I don\u2019t find the value. Please find attached the logs, the definitions, a screenshot of the usages of that attribute and we have tried this and this and that so far below\u201d.*\n+ Bad example  \n- *\u201cThere is an issue with offer generation on the second process step. It shows error message when it should show success message\u201d*  \nPlease make sure to follow these key points when opening a support ticket:  \n* You need to make an effort to fix on your own which you are expected to document when reaching higher level of support with the included artifacts (so they know you tried it!)  \n+ + You always score a few brownie points if you show that you tried to resolve the issue yourself!\n* The SUP ticket is for a Skye related problem. A certain attribute or feature in Skye is not behaving how you would expect. Avoid opening tickets with your project context problem  \n+ Good example  \n- *\u201cWhen the excel at Referrel.LogicExcel in the attached Referral definition gets triggered I would expect that it sets the value to of Referral.noIssuesFound to TRUE. I see in the log, but when I verify in the database I don\u2019t find the value. Please find attached the logs, the definitions, a screenshot of the usages of that attribute and we have tried this and this and that so far below\u201d.*\n+ Bad example  \n- *\u201cThere is an issue with offer generation on the second process step. It shows error message when it should show success message\u201d*\n#### **Mandatory task before opening a SUP ticket.**  \n* All items in [Step1), try on your own](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/199753981/Config+101+-+What+to+do+when+I+am+stuck#Step-1%3A-Try-on-your-own)\n* Try to resolve the issue yourself and document what you tried! **It is important to understand that support in Innoveo is not to resolve the issue, it is to enable you to resolve the issue yourself if possible!**\n* Find the component that is not working as expected in the [user guide](https://confluence.innoveo.com/is910/9-10-1-02-10-2023-149622836.html), and check if your configuration is correct.\n* Try your component with a simple example from the [user guide](https://confluence.innoveo.com/is910/9-10-1-02-10-2023-149622836.html), and check where your logic differs from what's written there preferably outside of your project context. \u2192 *Read about this in the section* <https://innoveo.atlassian.net/wiki/spaces/SA/pages/2100461569/How+to+raise+a+ticket+for+the+higher+level+support#How-to-test-functionalities-on-Skye-test-server.>\n***Always start your investigation based on the logs!***\nIf the logs for your component are not visible (or only contain basic information) increase the log level. You can find more information about logging on the following pages:  \n+ [Logging Configuration](https://confluence.innoveo.com/is911/logging-configuration-149623288.html)\n+ [Log4j settings and logger types](https://confluence.innoveo.com/is911/log4j-logging-and-configuration-149626990.html)\n* Check the browser logs as well, especially the **console** and **network** tabs in the inspect tool.  \n+ UI-related issues, like a JavaScript error, won\u2019t be visible on the server logs.\n* If your issue is UI related, try deleting the custom CSS and custom JS. If that resolves your issue, reach out to the Frontend Developer in your unit!\n* Check the **release notes of the latest Skye version**, in many cases, bugs identified on previous releases got patched in one of the newest releases.  \n+ If this is the case, you have two options: upgrade to the newer version or request a patch to your Skye version.\n* Check the https://innoveo.atlassian.net/wiki/spaces/IPH if there is already a solution or guide for your issue.\n* Check for your issue on **Project BA Support** (Teams Group) and on the [ICSP Jira board](https://innoveo.atlassian.net/jira/servicedesk/projects/ICSP/queues/custom/150).  \n+ The most effective way of doing this is to search for your error message, if that gives back 0 hits then search for your component which is not working.\n* If none of the above gives you any help, ask your query in the **Project BA Support** Teams Group.",
        "# Purpose  \nThis page aims to explain how you can ask for support if you have a question or if you want to leverage on of our services from the Partner Service Catalog .",
        "# Tasks before creating ticket  \nMake sure that the maintenance page is ready and you have a fixed deployment date and time",
        "# Restrictions per release category  \n|  | **Minor** | **Major** | **Emergency** |\n| --- | --- | --- | --- |\n| Allowed content | Update of existing definitions Addition of new definitions Implementation migration Skye version change | Update of existing definitions Addition of new definitions Implementation migration Skye version change | Update of existing definitions Addition of new definitions Implementation migration Skye version change |\n| Deployment request creation deadline | **1 business day** (24 hours)before scheduled activity | **3 business days** (72 hours)before scheduled activity | **ASAP** |\n| Business justification required | No | No | **Yes**High severity ICSP (bug)ticket linked |\n| Release plan | Mandatory for ticket creation | Mandatory for ticket creation | Mandatory for ticket creation |\n| Release plan freeze (no changes\\* after) | **24** hoursbefore scheduled activity | **24** hoursbefore scheduled activity | N/A |\n| Approvals | CSM P-SPOC Customer | CSM P-SPOC Customer | CSM P-SPOC Customer |  \nChanges accepted up until 24 hours before scheduled activity:  \n* **Release tag**: the planned release tag must be part of the initial Release Plan document but can be updated in the provided window.\n* **Migration scripts**: the need for implementation migration must be part of the initial Release Plan document but minor change of the scripts can be shared in the provided window.\nPlease not that it is mandatory to test all migrations way more than 24 hours prior to a production release!",
        "# Purpose  \nThis page aims to explain how a partner member can open a new infra ticket related his project."
      ],
      "success": true,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Great job! The score is 1.00 because there are no contradictions, meaning the actual output aligns perfectly with the retrieval context. Keep up the good work!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.019385,
          "verboseLogs": "Truths (limit=None):\n[\n    \"A support ticket can be created for acquiring a new service from a Partner Service Catalog.\",\n    \"Support tickets involve issues such as application-related questions or configuration problems.\",\n    \"It is important to open a ticket for every issue as it helps in collaboration and makes issues searchable.\",\n    \"Users should go through the available documentation before seeking help through a support ticket.\",\n    \"A support ticket should include Skye Version, reproduction steps, relevant definitions, and previous attempts.\",\n    \"Attachments such as a postman collection or a wsdl + sample request are helpful for building integration tickets.\",\n    \"Application support involves performing an issue analysis before reporting.\",\n    \"Daily meetings are offered during the Honeymoon period, which typically decreases to 2-3x weekly meetings.\",\n    \"Senior team members are responsible for verifying the quality of outgoing questions.\",\n    \"An infra ticket includes environment-related issues, accesses, changes in infrastructure, and incidents.\",\n    \"Infrastructure support is handled via the ICSP portal, and the Customer Support Manager (Shebu) serves as the escalation path.\",\n    \"Credentials, application URL, and detailed steps are required details when opening an infra ticket.\",\n    \"Screenshots and accurate information in the ticket reduces back-and-forth communication.\",\n    \"Roles such as Partners SPOC are responsible for customer support portal access tickets.\",\n    \"Creating a support ticket in JIRA for Skye problems requires registering all self-resolution attempts.\",\n    \"A good support ticket contains details such as the component that is not working as expected.\",\n    \"Efforts to resolve issues on one's own should be documented when reaching higher-level support.\",\n    \"Reporting an issue should ideally be accompanied by a screenshot and detailed reproduction steps.\",\n    \"Tickets from one project are ideally handled by one person but this may vary due to conflicts or holidays.\",\n    \"The Innoveo Support System encourages self-effort in resolving issues to aid customer self-sufficiency.\"\n] \n \nClaims:\n[\n    \"When raising a support ticket, including the Skye version you are using is important.\",\n    \"Providing clear reproduction steps for the issue is essential when raising a ticket.\",\n    \"Relevant definitions and attributes should be included in the support ticket.\",\n    \"Describing the actions attempted to resolve the issue is necessary in the support request.\",\n    \"Stating expectations versus actual experiences is needed in the support ticket.\",\n    \"Attachments such as Postman collections or WSDL samples can be included if necessary.\",\n    \"Screenshots and additional relevant information can assist in resolving support issues.\",\n    \"Detailed guidance for raising a support ticket is available in the documentation.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.9,
          "reason": "The score is 0.90 because the answer is largely relevant and directly addresses the input query by discussing essential information to include in a support ticket. However, the score isn't higher due to the mention of referencing documentation, which, while somewhat related, doesn't specify details needed in a ticket. Overall, the response is strong with room for slight refinement.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0067375,
          "verboseLogs": "Statements:\n[\n    \"Include important information when raising a support ticket.\",\n    \"Specify the version of the Skye application you are using.\",\n    \"Clearly outline the steps to reproduce the issue.\",\n    \"Include relevant definitions or attributes related to the issue.\",\n    \"Describe actions taken to resolve the issue.\",\n    \"Explain what you expected to happen.\",\n    \"Detail what actually happened instead.\",\n    \"Attach a Postman collection or a WSDL + sample request if applicable.\",\n    \"Provide screenshots and other relevant information to assist in resolution.\",\n    \"Refer to the documentation for more detailed guidance.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Referencing documentation serves as a general guideline, but it\\u2019s not a piece of information to be included in a ticket.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.8,
          "reason": "RETRIEVAL_CONTEXT includes key information such as what constitutes a support ticket and detailed submission guidelines. It contains a link to a portal and related documentation. No contradictions are present. Some additional details on infra tickets and meeting processes are not directly linked to the CONTEXT, leading to a minor deduction.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.011592500000000002,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Verify if RETRIEVAL_CONTEXT contains all the key information present in CONTEXT.\",\n    \"Check for the presence of a link within the RETRIEVAL_CONTEXT.\",\n    \"Ensure that any additional information in RETRIEVAL_CONTEXT does not contradict or misinterpret the information in CONTEXT.\",\n    \"Evaluate the clarity and relevance of the information in RETRIEVAL_CONTEXT in enhancing or supporting the key points in CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.8,
          "reason": "The actual output includes all required elements and a link to the documentation, closely matching the expected output. It includes Skye version, issue description, and additional helpful details, but does not explicitly mention environment specs and URLs as stated in the expected output.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0034400000000000003,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Step 1: Compare actual output to expected output ensuring all required elements are present.\",\n    \"Step 2: Verify if the actual output includes a link to documentation as expected.\",\n    \"Step 3: Check for additional information in the actual output; confirm there is no contradicting information compared to expected output.\",\n    \"Step 4: Evaluate overall closeness of actual output to expected output, considering presence of required elements and absence of contradictions.\"\n]"
        }
      ],
      "runDuration": 23.398477457998524,
      "evaluationCost": 0.041155,
      "order": 11
    },
    {
      "name": "test_customer_chatbot[test_case12]",
      "input": "How to change flex data search filtering?",
      "actualOutput": "To change the filtering criteria for flex data search, you need to follow these steps:\n\n1. **Create or Modify Filtering Configuration**: You can create or modify the filtering configuration in the `@FilterCriteria` attribute.\n\n2. **Restart the Application**: After making changes to the filtering configuration, it is necessary to restart the application.\n\n3. **Reindex Affected Products**: You will need to reindex the affected products. This can be done using the Skye admin console or through JMX. For production deployments, it is recommended to request a re-index of the free text search indexes.\n\nFor more detailed information, you can refer to the documentation on [changing the filtering criteria](https://confluence.innoveo.com/dosearchsite.action?queryString=free-text).",
      "expectedOutput": "The flex data filtering will always serach in the whole data and not just the first characters. So if you type \"eng\" the results could be: England, Software engineer",
      "context": [
        "# Overview\n\nWildcards are special characters that can be used in search terms to represent one or more other characters. Wildcards can be useful in improving search results.\nThe use of wildcard characters, specifically '*', and '?', is now feasible within the following Skye search components:\n    - Free text search\n    - Automatic search queries\n    - Flexdata attributes\n    - Reference attributes\n\n# Supported wildcards\n\nSkye search components support the following wildcard characters:\n    Asterisk (*) - matches any number of characters (wh* will return what, why and where)\n    Question mark (?) - matches any single character in a specific position (b?ll will return bell, bill and ball)\n\n# Example\n(Examples are given for the following dataset: Software engineer & QA engineer)\n\n    - Search query: *er\n    Flexdata: Software engineer, QA engineer\n\n    - Search query: So*\n    Flexdata: Software engineer\n\n    - Search query: engin?er\n    Flexdata: Software engineer, QA engineer"
      ],
      "retrievalContext": [
        "### Wildcard search  \nFlexdata supports the use of wildcard characters. You can learn more about that at [Wildcard search](../../wildcard-search.md).",
        "# Basic features  \n- It looks for a given value in an index and sets the id of the unique search result to the linked flexdata attribute.",
        "## Trigger search service attribute properties  \n| Property | Description | Mandatory | Default value | Example |\n| --- | --- | --- | --- | --- |\n| Flexdata attribute | Defines the flexdata attribute where the unique search result should be set to. Only single flexdata attributes can be selected. | Yes | - | Brick.SingleFlexdata |\n| Clear flexdata if no result found | If this option is selected the value of the flexdata attribute will be cleared in case no result has been found. | No | - | - |",
        "# Limitations  \nTrigger search service attributes set values only on flexdata attribute with input type 'Auto complete'.",
        "### Single flexdata attribute texts  \n| Text Type | <div style=\"width:500px\">Description</div> | Mandatory | Default Value | HTML Support | Variable Resolver Support | <div style=\"width:300px\">Example</div> |\n| --- | --- | --- | --- | --- | --- | --- |\n| placeholder | Text to be shown inside the search field before the user enters it. Will be replaced by what the user enters. | No | (none) | Yes | Yes | Enter postal code or city |\n| searchTooManyRecords | On this text type the user defines the text which is displayed below the last displayed search result entry if the number of search results exceeds the maximum number of search results. | No | (none) | Yes | No | Too many records were found. Only the first 20 are displayed. |\n| label | Text to be shown as the label of this field | No | (none) | Yes | Yes | City |",
        "## Configure single flexdata attribute  \n### Single flexdata attribute properties  \n![screenshot](https://confluence.innoveo.com/is914/files/158604288/158604299/1/1711440416000/image2018-2-17_22-54-42.png)  \n| Property | <div style=\"width:500px\">Description</div> | Mandatory | Default value | Variable resolver support | Example |\n| --- | --- | --- | --- | --- | --- |\n| Label field | Column name of the column in the csv that should be displayed as search result. | Yes | (none) | no | postalCodeAndCity |\n| Single search field | Defines the single field in which the search should be executed in case of input type \"Auto complete\". If no single search field is defined, the search is executed in all index fields. | No | (none) | No | \\- |\n| Max. number of search results | Maximum number of results displayed. This property is only enabled in case of input type 'Auto complete'. | Yes | 20 | No | 20 |\n| Characters to trigger search | Number of characters required to trigger the search results list. This property is only enabled in case of input type 'Auto complete'. <br> <br> If the value is 0, the auto complete will be automatically open when the focus is in that field with all the possible suggestions. <br> <br> More on the use of Elasticsearch reserved characters (+ - = && \\| \\| > < ! ( ) { } [ ] ^ \" ~ * ? : \\ / ) can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/query-dsl-query-string-query.html#_reserved_characters). | Yes | 3 | No | 3 |\n| Sorting fields | The automatic ordering of search results can be overridden by mentioning the column in the csv that should first be taken into account for ordering. Multiple columns can be mentioned comma separated. The second column will be taken into account if the ordering by the first column of two lines is not determinate. | No | (none) | No | postalCode |\n| Sorting order | Per sorting column mentioned above you can define if the ordering should be ascending or descending. Possible values: Ascending, Descending. If multiple columns are mentioned above the sorting rules for all of them can be defined comma separated. | No | Ascending | No | Ascending |\n| Mapping | Mapping of definition attributes (left) and index fields (right). When selecting a search result entry all fields that are mentioned here are mapped to the corresponding attributes. <br> <br> **CSV upload** <br> In case of index creation via CSV upload the value to be entered in the field on the right must be equal to a csv column name of the csv file that was used to create the index. <br> <br> **Create index event / On the fly by web service** <br> In case of index creation via web service the value to be entered in the field on the right must be equal to the text-id of an attribute in the transformation definition that is used to create the index. <br> <br> Mapping has an ordered setting of values. The first attribute in the list is mapped and after setting the value everything that is triggered by this set value is performed before continuing with the next mapping. | No | (none) | No | Index field \"city\" is mapped to attribute \"Customer.city\". |",
        "### Set data source attribute  \nIt is possible to change that Data source attribute associated to a Flexdata (Single or Multi) attribute using the dependency action called \"Set data source attribute\".  \nYou can find more information about this dependency action at[Flexdata - Single attribute](./attributes/specialized/flexdata-single.md) and[Flexdata - Multi attribute](./attributes/specialized/flexdata-multi.md).",
        "---\ntitle: \"Flexdata - Single attribute\"\nweight: 200\n---  \nA Single flexdata attribute can be used to display an index that was created either in advance or on the fly. Depending on the input type the user can search a value or select from a list or radio button. A mapping can be configured to set values to several attributes when selecting an entry.",
        "# How to trigger the service  \nThe search service attribute is triggered when setting a value to it. After the service is triggered, the attribute's value is automatically set back to empty.  \nAfter being triggered, the service does the following:  \n1. It searches for the given value in the index (if the 'Single search field' is specified on the linked flexdata attribute in that field only)\n2. It looks up for the id of the record with this value (the id is specified in the data source attribute on the field 'Id field')\n3. It sets the id to the flexdata attribute (in case of a single search result only)",
        "---\ntitle: \"Flexdata - Multi attribute\"\nweight: 190\n---  \nA Multi flexdata attribute can be used to display values of an index e.g. via checkboxes and then allow the user to select multiple values from the index.",
        "### Changing the filtering criteria  \nIf any filtering configuration is **created or modified** in the @FilterCriteria attribute, it is necessary to:  \n- Restart the application\n- Reindex affected products  \nReindex may either be executed with Skye admin console or through JMX. For productive deployments, please request a re-index of freetext search indexes.",
        "## Configure Multi flexdata attribute  \n### Multi flexdata attribute properties  \n![screenshot](https://confluence.innoveo.com/is914/files/158604281/158604283/1/1711440413000/image2018-2-17_22-15-41.png)  \n| <div style=\"width:150px\">Property</div> | Description | Mandatory | <div style=\"width:200px\">Default value</div> | Variable resolver support | Example |\n| --- | --- | --- | --- | --- | --- |\n| Data source attribute | A attribute picker allows the selection of [data source attribute](./data-source.md) which will supply the data from the index file. The [data source attribute](./data-source.md) can also present on another definition and navigated to via reference attributes. e.g. <br> `ref[Product.shoppingcartItemRef].ref[ShoppingcartItem.insuredObject].Shoppingcart.DataSource` | Yes | (none) | Yes | Product.DatasourceAttribute |\n| Label field | Column name of the column in the index that should be displayed as the labels of the displayed options | Yes | (none) If the label field is not defined correctly the 'Id field' of the respective data source attribute is used' | No | option |\n| Sorting fields | The automatic ordering of search results can be overridden by mentioning the column in the index that should first be taken into account for ordering. Multiple columns can be mentioned comma separated. The second column will be taken into account if the ordering by the first column of two lines is not determinate. | No | (none) | No | id |\n| Sorting order | Per sorting column mentioned above you can define if the ordering should be ascending or descending. Possible values: Ascending, Descending. If multiple columns are mentioned above the sorting rules for all of them can be defined comma separated. | No | Ascending | No | Ascending |",
        "### Not supported for CSV with data types  \n- In the data source attributes constraints, the operators \"contains\"and \"not contains\" are not supported for data types \"Decimal\", \"Integer\" and \"Timestamp\"\n- Fordata types \"Decimal\", \"Integer\" and \"Timestamp\" the prefix is not searchable in a flexdata with input type \"Autocomplete\" eg 2004 will not be found if 200 is searched, only if 2004 is searched.",
        "# Advanced Search with APIs  \n* our exposed APIs are supporting multiple dynamic filters\n* call the API within Skye using HTTP invokers\n* store the results in multibrick\n* represent them as a table",
        "## APP  \nIn the app, you will use a simple <https://confluence.innoveo.com/is808/data-source-attribute-112897135.html> and <https://confluence.innoveo.com/is808/flexdata-single-attribute-112897231.html> to allow the user to select a user from the list.  \nWhat to consider:  \n* The page does not load if it has a data source to a non-existing index. This means, that when you deploy it for the first time, you need either to create an entry to the list (by creating a user) OR upload a simple CSV with fake data temporary\n* the index created with WS is the same index if you would have created it via CSV upload.\n* We recommend mapping out the value of the username to a field called \u201cAssignedTo\u201d instead of building logic to the Flexdata attribute itself.  \nIf you want to filter for the assigned person in an autosearch, you should simply use the \u201cAssignedTo\u201d attribute. If you have a trouble with the search, check How to debug auto searches first.",
        "---\ntitle: \"Data source attribute\"\nweight: 140\n---  \nThis attribute serves as 'Data container' where other attributes can get and display data from an index.  \nCurrently the following attributes can get data from the Data source attribute:  \n- [Flexdata - Multi attribute](./flexdata-multi.md)\n- [Flexdata - Single attribute](./flexdata-single.md)",
        "### Dependencies  \nThe Flexdata - Single select has an additional action on the dependency: 'Set datasource attribute'.  \nWhenever the dependency condition is fulfilled, the data of the data source attribute specified in the dependency is displayed by the 'Flexdata' attribute. The data source specified in the property 'Data source attribute' is overwritten by the one set by the dependency.  \n![screenshot](https://confluence.innoveo.com/is914/files/158604288/158604289/1/1711440416000/image2018-3-9_17-42-22.png)  \n**Note:**It is not possible to have two data source attributes which are active for a Flexdata attribute at the same time (e.g. two different dependencies fulfilled with two different data source attributes). In that case an exception will be thrown and a message is displayed in the logs.",
        "### Response mapping into Data source  \nA different use case would be to map a list in the response to a data source attribute so that it can displayed using a flexdata attribute as a drop-down list or suggestion box. This mapping would be temporary, only available for the current implementation. In the example below we are mapping response containing information about cars into a data source attribute.  \n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<root>\n<cars>\n<element>\n<manufacturer>Porsche</manufacturer>\n<model>911</model>\n<price>135000</price>\n</element>\n<element>\n<manufacturer>Nissan</manufacturer>\n<model>GT-R</model>\n<price>80000</price>\n</element>\n<element>\n<manufacturer>BMW</manufacturer>\n<model>M3</model>\n<price>60500</price>\n</element>\n</cars>\n</root>\n```  \n![screenshot](https://confluence.innoveo.com/is914/files/158604417/158604422/1/1711440436000/image2019-11-29_12-2-12.png)  \nNotice that in this case the mapping is done in two parts, first we select the list to be mapped, using XPath (/root/cars/element[*]) and then for each of the elements in the selected list, we map the properties in the element to fields. It's important to note that the XPath in the response field list is relative to the element in the list and no absolute like in the case of the mapping into multibricks.",
        "### Response mapping into Data source  \nA different use case would be to map a list in the response to a data source attribute so that it can displayed using a flexdata attribute as a drop-down list or suggestion box. This mapping would be temporary, only available for the current implementation. In the example below we are mapping response containing information about cars into a data source attribute.  \n```\n{\"cars\": [\n{\n\"manufacturer\": \"Porsche\",\n\"model\": \"911\",\n\"price\": 135000\n\n},\n{\n\"manufacturer\": \"Nissan\",\n\"model\": \"GT-R\",\n\"price\": 80000\n},\n{\n\"manufacturer\": \"BMW\",\n\"model\": \"M3\",\n\"price\": 60500\n}\n]}\n```  \n![screenshot](https://confluence.innoveo.com/is914/files/158604437/158604440/1/1711440441000/image2019-8-30_16-11-37.png)  \nNotice that in this case the mapping is done in two parts, first we select the list to be mapped, using JSONPath ($.cars) and then for each of the elements in the selected list, we map the properties in the element to fields. Important to note that the JSON path in the response field list is relative to the element in the list and no absolute like in the case of the mapping into multibricks.",
        "### Dependencies  \nThe Flexdata - Multi select has an additional action on the dependency: 'Set datasource attribute'.  \nWhenever the dependency condition is fulfilled, the data of the data source attribute specified in the dependency is displayed by the 'Flexdata' attribute. The data source specified in the property 'Data source attribute' is overwritten by the one set by the dependency.  \n![screenshot](https://confluence.innoveo.com/is914/files/158604281/158604282/1/1711440413000/image2018-3-9_17-42-22.png)  \n**Note:**It is not possible to have two data source attributes which are active for a Flexdata attribute at the same time (e.g. two different dependencies fulfilled with two different data source attributes). In that case an exception will be thrown and a message is displayed in the logs."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Fantastic work delivering an output that perfectly aligns with the retrieval context! Keep up the great coordination and accuracy!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.016615,
          "verboseLogs": "Truths (limit=None):\n[\n    \"Flexdata supports the use of wildcard characters in searches.\",\n    \"The 'Flexdata attribute' is mandatory when defining where a unique search result should be set.\",\n    \"Single flexdata attributes have a placeholder text that can be customized.\",\n    \"An 'Auto complete' input type is allowed for single flexdata attributes.\",\n    \"When no result is found, the flexdata attribute can be cleared if the option is selected.\",\n    \"Trigger search service attributes set values only on flexdata attributes with 'Auto complete' input type.\",\n    \"Maximum number of search results for 'Auto complete' input type is pre-defined and mandatory.\",\n    \"Sorting order for search results can be defined as ascending or descending.\",\n    \"Data source attribute can serve as a data container for other attributes.\",\n    \"Only single flexdata attributes can be selected for the flexdata attribute property.\"\n] \n \nClaims:\n[\n    \"To change the filtering criteria for flex data search, you need to create or modify the filtering configuration in the @FilterCriteria attribute.\",\n    \"After making changes to the filtering configuration, it is necessary to restart the application.\",\n    \"You need to reindex the affected products using the Skye admin console or through JMX after changing the filtering configuration.\",\n    \"For production deployments, it is recommended to request a re-index of the free text search indexes.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the response is perfectly relevant, directly addressing the input query about changing flex data search filtering without any deviations or unrelated information. Well done!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.005265000000000001,
          "verboseLogs": "Statements:\n[\n    \"Create or modify the filtering configuration in the '@FilterCriteria' attribute.\",\n    \"Restart the application after making changes to the filtering configuration.\",\n    \"Reindex the affected products.\",\n    \"Reindexing can be done using the Skye admin console or through JMX.\",\n    \"Request a re-index of the free text search indexes for production deployments.\",\n    \"Refer to the documentation for more information on changing the filtering criteria.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.2839362958182717,
          "reason": "RETRIEVAL_CONTEXT mentions wildcard search but lacks detailed examples and supported wildcard characters from CONTEXT. It links to a resource but fails to include critical specifics like use in different search components. No contradictions are noted between contexts.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0120625,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check that RETRIEVAL_CONTEXT includes all critical information present in CONTEXT.\",\n    \"Ensure that RETRIEVAL_CONTEXT contains a functional link.\",\n    \"Verify that any additional information in RETRIEVAL_CONTEXT does not contradict the information in CONTEXT.\",\n    \"Evaluate if the central theme or main idea of CONTEXT is clearly expressed in RETRIEVAL_CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.2,
          "reason": "Actual Output diverges significantly from Expected Output, focusing on technical setup rather than search behavior. It provides non-conflicting additional information, like configuration and actions required for filtering criteria changes, which is not found in Expected Output. No contradicting information exists. Document link presence aligns with step 2, despite mismatch in content focus.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0034325,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the content of the ACTUAL OUTPUT to the EXPECTED OUTPUT to determine similarity and closeness.\",\n    \"Verify that the ACTUAL OUTPUT includes a link to documentation as specified in the EXPECTED OUTPUT.\",\n    \"Check for any contradicting information between ACTUAL OUTPUT and EXPECTED OUTPUT and ensure none is present.\",\n    \"Review the ACTUAL OUTPUT for additional information not found in the EXPECTED OUTPUT to ensure it is acceptable and non-conflicting.\"\n]"
        }
      ],
      "runDuration": 25.36860504199649,
      "evaluationCost": 0.037375,
      "order": 12
    },
    {
      "name": "test_customer_chatbot[test_case13]",
      "input": "Prevent duplicated usernames eve if the validation pop up?",
      "actualOutput": "To prevent duplicated usernames in your system, you should ensure that the username attribute is configured to be unique. This can be achieved by using the `UniqueRootAttributeImplValueServiceDelegate` service for the username attribute. This service ensures that the value of the username attribute is unique within the user definition.\n\nHere are the steps you can follow:\n\n1. **Set Up Unique Username Attribute**: Ensure that the `@Username` attribute is defined as a service attribute using `UniqueRootAttributeImplValueServiceDelegate`. This will enforce uniqueness at the database level.\n\n2. **Validation Configuration**: Configure the validation rules to check for existing usernames before allowing the creation of a new user. This can be done by implementing a validation service that checks the database for existing usernames.\n\n3. **User Interface Feedback**: Provide immediate feedback in the user interface (UI) when a user attempts to enter a username that is already taken. This can be done through AJAX calls that validate the username as the user types.\n\n4. **Error Handling**: Ensure that appropriate error messages are displayed to the user if they attempt to use a duplicate username, guiding them to choose a different one.\n\nFor more detailed information on how to configure the username attribute and ensure its uniqueness, you can refer to the following documentation: [UniqueRootAttributeImplValueServiceDelegate](https://confluence.innoveo.com/dosearchsite.action?queryString=custom-id).\n\nBy implementing these steps, you can effectively prevent duplicated usernames in your system.",
      "expectedOutput": "In a somewhat similar scenario I had to ensure the uniqueness of values in update processes (multiple values had to be unique), there the issue is worse as you already had something saved, so you cannot prevent the saving with disabling a button.",
      "context": [
        "Unknown user: hi Project BA Support do you know a way to prevent the below scen..."
      ],
      "retrievalContext": [
        "### validate User Delegate  \n- **General usage**\nThis service is only used in user managementas input field on the login page and to validate if there is a user created with the user name and password on the login page.\n- **Trigger behavior**\nThe service is triggered with the next server call when the value of the service attribute is set.\n- **Further configuration**\n- This service attribute needs to be created on the root of the \"TransientUser\" definition.\n- Backend info of type \u201clogin.SupportedLoginDefinitions\u201d with supported model text-ids of user definitions\n- Backend info of type \u201clogin.UniqueBusinessKeyAttributesTextId\u201d with value \u201cuserName;password\u201d in order to specify that those are the two attributes to validate for the login.\n- Text of type \u201cplaceholder\u201d with text to be displayed inside the input.\n- Text of type \u201cshort\u201d with text \u201c&nbsp;\u201d in order keep the attribute at the same position as if it had a label.",
        "### Attributes on the root  \n| **Attribute text-id** | **Attribute mandatory** | **Description** |\n| --- | --- | --- |\n| @Username | Yes | Used as unique identifier for users of the same model text-id. If you try to create a user of the same type (same definition) and with the same username, a type validation error is displayed. <ul><li>Attribute type: Service</li><li>Service: UniqueRootAttributeImplValueServiceDelegate</li></ul> |\n| organizationRef | Yes | Used to assign every user to an organization. <ul><li>Attribute type: Reference attribute</li><li>Input type: Reference auto complete</li><li>Search text type: Text type in which the system will search for the entered value (e.g. fullTextIndexSearchSuggestion)</li><li>Model type: User group</li><li>Model text-id: Model text-id of the user group definition to which this user type belongs to (e.g. InternalOrganization)</li></ul> |\n| @Email | Yes | Used to send the activation email to the users email address. <ul><li>Attribute type: generic</li><li> Input type: Textbox</li><li>Class: EmailValidator</li></ul> |\n| firstName | Yes | Used in the web application to display the first name of the logged in user in the header. <ul><li>Attribute type: generic</li><li>Input type: Textbox</li></ul> |\n| lastName | Yes | Used in the web application to display the last name of the logged in user in the header. <ul><li>Attribute type: generic</li><li>Input type: Textbox</li></ul> |\n| @Status | Yes | User state machine (description below) |\n| @CanSeeBelowOrganization | Yes | Used to define whether the user can see only quotes created by him or quotes of all users of his organization and sub-organizations.<ul><li>Attribute type: generic</li></ul><br> Possible values: <ul><li>true</li><li>false</li></ul> |\n| @LoginAttempts | Yes | This control attribute is used to define how many times a user can try to login with a wrong password before he is blocked automatically. If the number of unsuccessful login attempts reaches this number, the status of this user is set to \u201cBlocked\u201d automatically. <br> Possible values: 1-10. |\n| @Password | Yes | Used to store the current password of the user <ul><li>Attribute type: generic</li><li>Data security: Hashing</li><li>Input type \u201cPassword\u201d (makes the entered value unreadable in the screen)</li><li>Text of type \u201ccustomTypeValidationError\u201d in order to specify a message displayed when the password doesn\u2019t fulfill the syntactic requirements (see also below).</li></ul> |\n| repeatPassword | Yes | Used to force the user to enter the password twice and to specify the syntactic rules for the password. Check that the value is the same as the one entered in \u201cpassword\u201d. <ul><li>Attribute type \u201cService\u201d</li><li>Data security: Hashing</li><li>Input type \u201cPassword\u201d (makes the entered value unreadable in the screen)</li><li>Output formatter \u201cPasswordFormatter\u201d</li><li>Serivce: SkyePasswordValidator</li><li>Backend infos passwdrule.XXX to specify syntactic rules (see below)</li><li>Backend info \u201cPassword.DependantAttribute\u201d with value \u201c@Password\u201d to specify which attribute should be checked for validity against password rules.</li><li>Fix value range with value %{InternalUser.@Password->rawValue} in order to ensure that the user enters the same password twice (replace \u201cInternalUser\u201d by your model text-id)</li></ul> |\n| newPassword | Yes |Used to let the user enter a new password as part of the \u201cForgotPassword\u201d process. <ul><li>Attribute type: generic</li><li>Data security: Hashing</li><li>Input type \u201cPassword\u201d (makes the entered value unreadable in the screen)</li><li>Text of type \u201ccustomTypeValidationError\u201d in order to specify a message displayed when the password doesn\u2019t fulfill the syntactic requirements (see also below).</li></ul> |\n| repeatNewPassword | Yes | Used to force the user to enter the password twice and to specify the syntactic rules for the password. Check that the value is the same as the one entered in \u201cnewPassword\u201d. <ul><li>Attribute type \u201cService\u201d</li><li>Data security: Hashing</li><li>Input type \u201cPassword\u201d (makes the entered value unreadable in the screen)</li><li>Serivce: SkyePasswordValidator</li><li>Backend infos passwdrule.XXX to specify syntactic rules (see below)</li><li>Backend info \u201cPassword.DependantAttribute\u201d with value \u201cnewPassword\u201d to specify which attribute should be checked for validity against password rules.</li></ul> |\n| @PasswordExpirationDate | Yes | Used to force the user to change his password after a definable period. Its value stores the expiration date and should be set by dependency via date resolver (e.g. %{TODAY+ 6MONTH}) that is updated every time the value of the attribute @Password changes. In case of an empty value, this attribute is not taken into account.<ul><li>Data type: Date</li><li>Input formatter: Date</li><li>Output formatter: Date</li></ul> |\n| @PasswordHistory |    | Used to store the old passwords in case the password rule 'passwdrule.CheckPwdHistoryRule' is used (descripition below). <ul><li>Attribute type: generic</li><li>Input type: Textbox</li></ul> |\n| lastForgotPasswordUuid | Yes | Used to store the uuid of the last transient user which was used to start a \u201cForgot password\u201d process (or \"Expired password\" process). <ul><li>Attribute type: generic</li><li>Input type: Textbox</li></ul> |\n| activationEmail |    | Used to specify the email that should be sent to the user after he was created in order to enter a password and activate his account. <ul><li>Attribute type: Email</li><li>Text of type \u201cemailContext\u201d to specify the email content (at least the activation [URL](../user-mgmt-urls/_index.md))</li><li>Text of type \u201cemailSendToAddress\u201d to specify the email address the email should be sent to.</li><li>Text of type \u201cemailSubject\u201d to specify the subject of the email.</li></ul> |\n| @ReadyForFullTextIndex | Yes | To be able to find a user implementation e.g. in the free text search, the control attribute @ReadyForFullTextIndex is needed on the root of the definition. In order to be able to find an implementation, this attribute needs to have value \u201ctrue\u201d. <br> The value could be set to \u201cfalse\u201d by dependency if an implementation should not be found anymore in certain conditions. |\n| @LastLoginDate |    | Used to store the last time a user was logged in a Skye application.<ul><li>Data type: Timestamp</li><li>Value format:yyyy.MM.dd HH**:**mm**:**ss (internal Skye format)</li><li>The attribute can be used in different criteria lists.</li></ul> |\n| @Enable2FA  | Yes | Defines id the user has enabled or not the 2FA when using Skye user management. Possible values: <ul><li>True: 2FA is enabled</li><li>False: 2FA is not enabled</li></ul> |\n| @2FAKey  |    | Contains the value of the key used to obtain 2FA authentication code. The key can be shared with the user just by acceding the value of the attribute using variable resolver.<br> The attribute is mandatory in case@Enable2FA is enabled. |\n| @Regenerate2FAKey |    | Defines under which circumstances a key should be generated for a specific user. <br> The attribute is mandatory in case@Enable2FA is enabled. |\n| @SendKeyEmail  |    | Defines the configuration of the email that the user will receive with the 2FA key information. <br> The attribute is mandatory in case@Enable2FA is enabled. |\n| createdConfirmationMessage <br> activatedConfirmationMessage <br> editedConfirmationMessage <br> changedPasswordConfirmation <br> blockConfirmationMessage <br> blockedConfirmationMessage <br> unblockConfirmationMessage <br> unblockedConfirmatonMessage <br> expiredPasswordConfirmation |    | Used to display confirmation messages in different processes. <ul><li>Attribute type: Message</li><li>\"Style\" with value \u201cSuccess\u201d or \u201cWarning\u201d</li><li>Text of type \u201clabel\u201d with text to be displayed.</li></ul> |",
        "# Uniqueness  \nThe control attribute @AutoInitialCreate is unique within a definition.",
        "# Purpose  \nThis page will give you a step-by-step guide on how to modify the Initial User in the database so it will be compliant with the security guidelines.",
        "## Validation errors  \nAs explained above, It's possible to configure the 'Analytics' definition to send analytics event messages every time a validation error occurs.  \n![screenshot](https://confluence.innoveo.com/is914/files/158605440/158605441/1/1711440643000/image2018-2-23_15-4-26.png)",
        "# Purpose  \nThe purpose of this page is to give you a template you can use when you ask Innoveo to disable the Initial User before going live.",
        "How to disable InitialUser on Prod after Go-live",
        "## Service 'UniqueRootAttributeImplValueServiceDelegate'  \nTo ensure that the value of this attribute is unique, this attribute is of type service using the \"UniqueRootAttributeImplValueServiceDelegate\".",
        "# Purpose  \nThere is a known issue with the Business Canvas username, where multiple people might have the same username, by default it is the base windows username which is \u2018user\u2019 and renaming the local profile does not change this name, but there is a simple way to do it.",
        "Complex validation with dynamic validation error",
        "## Example Solution  \n1. We have the date of registration as an attribute\n2. It has a value range  \nThe value is a rawValue resolver to the carInformation.dateOfRegistation attribute.\n3. There is an excel, which gets triggered every time the date of registration changes\n4. It calculates the validation based on different rules\n5. Outcome  \n1. if the value is correct, it copies the value of the dateOfRegistration to the dateOfRegistrationValidation\n2. if the value is not correct, it sets a static incorrect value to the dateOfRegistrationValidation\n6. Optional: dynamic validation messages  \n1. create a new attribute (eg: dateOfRegistrationValidationMessage)\n2. set any value to this attribute with the ValidationExcel\n3. create a resolver in the dateOfRegistration attribute\u2019s valueRangeValidationError\n7. The excel used as the sample can be downloaded from here:",
        "Disabling Initial User on stage",
        "# Purpose  \nWhen the first, initial Go-live happens then we are using the initial user to create the first real admin user. This guide describes how to make that user unusable in the future so the development team does not have access to prod and we don't leave a security vulnerability.",
        "---\ntitle: \"Authentication web service\"\nweight: 10\n---  \nInnoveo Skye\u00ae Usermanagement may integrate an external user store for password validation via web service. The expected web service specification is provided through a WSDL which needs be implemented by a web service provider with access to the external user store.  \nUsers to be authenticated must exist in the Innoveo Skye\u00ae user store and in the external user store. The external user store is used only for password validation. Any other user data, like first and last name, and role information used for authorization, are configured in the Innoveo Skye\u00ae user store. Users may be created and configured either with Innoveo Skye\u00ae Usermanagement application or a user import mechanism.",
        "Modifying Initial User for proper security",
        "# Control attributes  \n| Control attribute | Configuration | Comments |\n| --- | --- | --- |\n| @CustomId | No special configuration is done on this attribute. A label text is added in order to have a label for it when it is displayed. <br> <br> The attribute will be visible and mandatory on the first page of the \"CreateCampaignProcess\" to ensure that it always has a value. | The fact that this control attribute is a service attribute with service <br> \"UniqueRootAttributeImplValueServiceDelegate\" ensures that the custom Id is always unique. It has to be made sure by configuration that this attribute will have a value when the campaign is valid. |\n| @ValidFrom | The attribute will be visible and mandatory on the first page of the \"CreateCampaignProcess\" to ensure that it always has a value. | |\n| @ValidTo | The value range is configured to not allow a \"Valid to\" date which is before the \"Valid from\" date. The maximum value is set to 99 years after the \"Valid from\" date. <br> <br> The attribute will be visible and mandatory on the first page of the \"CreateCampaignProcess\" to ensure that it always has a value. |  |\n@ValidModelTextId | The input type is set to \"Select one list\". A value range with two values \"Home\" and \"Motor\" is defined. <br> <br> So marketing users can decide for every campaign they create, whether it is valid for product \"Home\" or \"Motor\". | It has to be made sure that the user can only select one value as the system expects one and only one model text-id for which a campaign is valid. |\n| @ReadyForFullTextIndex | If you want to be able to find a campaign implementation e.g. in the free text search, the control attribute @ReadyForFullTextIndex is needed on the root of the definition. In order to be able to find an implementation, this attribute needs to have value \u201ctrue\u201d. <br> <br> The value could be set to \u201cfalse\u201d by dependency if an implementation should not be found anymore in certain conditions. | |",
        "## Generic/Shared User IDs  \n> Generic/Shared user IDs should not be created and used for production environments.\n> Generic/Shared user ID is permitted to be used for Test & Development environment only  \nIf you create admin users or test users throughout development which you share with each other, you should delete them before going live. This is important because if a shared user makes changes in the system we won\u2019t know who actually made the changes, furthermore if the credentials are not securely shared (not in password protected encrypted vaults) the credentials would be considered unsafe.",
        "### Skye Password Validator  \n- **General usage**\nThis service is only used in user managementto validate passwords against some configurable rules.\n- **Trigger behavior**\nThe service is triggered with the next server call when the value of the service attribute is set.\n- **Further configuration**\nFor further configuration information please refer to the user management documentation.",
        "---\ntitle: \"LDAP authentication\"\nweight: 20\n---  \nInnoveo Skye\u00ae Usermanagement may integrate an external user store for password validation via LDAP.  \nUsers to be authenticated must exist in the Innoveo Skye\u00ae user store <u>and</u> in the external user store. The external user store is used only for password validation. Any other user data, like first and last name, and role information used for authorization, are configured in the Innoveo Skye\u00ae user store. Users may be created and configured either with Innoveo Skye\u00ae Usermanagement application or a user import mechanism.",
        "# When should I modify this Initial User?  \nYou should modify it before going live. On a live system the initial user cannot be used and should be disabled as much as you can. Read more about the release process here.  \nBefore modifying the initial user make sure that there is a super admin user created for the client."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because there are no contradictions present in the actual output, indicating full alignment with the retrieval context. Great job!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.023137500000000005,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The 'validate User Delegate' service is used for user management on the login page.\",\n    \"The service is triggered with a server call when its value is set.\",\n    \"The service attribute needs to be part of the 'TransientUser' definition.\",\n    \"Username is a unique identifier for users of the same model text-id.\",\n    \"Users are assigned to organizations using 'organizationRef.'\",\n    \"An email is sent to the user's email address to activate their account after creation.\",\n    \"The 'repeatPassword' attribute forces users to enter the password twice for validation against rules.\",\n    \"'newPassword' is used when a user goes through the 'ForgotPassword' process.\",\n    \"'repeatNewPassword' is validated against 'newPassword.'\",\n    \"The 'PasswordExpirationDate' attribute forces users to change their password after a set period.\",\n    \"'LastLoginDate' stores the last time a user logged in a Skye application.\",\n    \"'Enable2FA' indicates if 2FA is enabled for a user, with possible values 'True' or 'False.'\",\n    \"Control attribute '@AutoInitialCreate' is unique.\",\n    \"Innoveo Skye\u00ae Usermanagement can integrate an external user store for password validation via web service or LDAP.\",\n    \"Generic/Shared user IDs are not allowed in production environments.\",\n    \"'Skye Password Validator' is used to validate passwords based on configurable rules.\",\n    \"Modify the Initial User before going live to ensure proper security.\",\n    \"'UniqueRootAttributeImplValueServiceDelegate' ensures the uniqueness of certain attribute values.\"\n] \n \nClaims:\n[\n    \"To prevent duplicated usernames in your system, you should ensure that the username attribute is configured to be unique using the `UniqueRootAttributeImplValueServiceDelegate` service.\",\n    \"The `UniqueRootAttributeImplValueServiceDelegate` service ensures that the value of the username attribute is unique within the user definition.\",\n    \"An `@Username` attribute should be defined as a service attribute using `UniqueRootAttributeImplValueServiceDelegate` to enforce uniqueness at the database level.\",\n    \"Validation configuration should include rules to check for existing usernames before allowing the creation of a new user.\",\n    \"A validation service can be implemented to check the database for existing usernames to enforce unique usernames.\",\n    \"The user interface should provide immediate feedback through AJAX calls when a user attempts to enter a username that is already taken.\",\n    \"Appropriate error messages should be displayed to users attempting to use duplicate usernames.\",\n    \"Guidelines for ensuring the uniqueness of a username attribute are available in the documentation: [UniqueRootAttributeImplValueServiceDelegate](https://confluence.innoveo.com/dosearchsite.action?queryString=custom-id).\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not provide details about the `UniqueRootAttributeImplValueServiceDelegate` service specifically managing usernames.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not include information about the function of `UniqueRootAttributeImplValueServiceDelegate` regarding username uniqueness.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"There is no mention of how the `UniqueRootAttributeImplValueServiceDelegate` service relates to the `@Username` attribute in the retrieval context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context lacks specific details on validation configuration guidelines for checking existing usernames.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not discuss the implementation of a validation service to check username uniqueness.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not mention using AJAX for providing feedback on username availability.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"Details about displaying error messages for duplicate usernames are not mentioned in the retrieval context.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": \"The retrieval context does not discuss guidelines specifically about username uniqueness related to documentation on `UniqueRootAttributeImplValueServiceDelegate`.\"\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.8461538461538461,
          "reason": "The score is 0.85 because the output effectively addresses the request for preventing duplicated usernames, and offers a general summary of necessary steps. However, it could be higher if it provided detailed, direct answers rather than referring to documentation and summarizing broadly.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.007957500000000001,
          "verboseLogs": "Statements:\n[\n    \"Ensure that the username attribute is configured to be unique.\",\n    \"Use `UniqueRootAttributeImplValueServiceDelegate` for the username attribute.\",\n    \"The service ensures the uniqueness of the username within the user definition.\",\n    \"The `@Username` attribute should be a service attribute using `UniqueRootAttributeImplValueServiceDelegate`.\",\n    \"Uniqueness is enforced at the database level.\",\n    \"Validation rules should check for existing usernames before allowing a new user.\",\n    \"A validation service should check the database for existing usernames.\",\n    \"Provide immediate feedback in the UI if a username is already taken.\",\n    \"AJAX calls can validate the username as the user types.\",\n    \"Display appropriate error messages if a duplicate username is attempted.\",\n    \"Guide users to choose a different username if needed.\",\n    \"Refer to documentation for more information on configuring unique usernames.\",\n    \"Implement these steps to prevent duplicated usernames in your system.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The statement is about referring to documentation, which indirectly relates but does not directly answer preventing duplicate usernames.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"This statement summarizes steps rather than providing detailed instructions on preventing duplicate usernames.\"\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.2,
          "reason": "The Retrieval Context lacks a direct link, which is a requirement per the evaluation criteria, and does not comprise any elements from the Context, making it difficult to assess key information relevance and alignment of purpose.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.01233,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Verify that the key information in CONTEXT is also present in RETRIEVAL_CONTEXT, ensuring relevancy is maintained.\",\n    \"Check that RETRIEVAL_CONTEXT contains a link, confirming it meets the evaluation criteria expectations.\",\n    \"Evaluate if the additional information in RETRIEVAL_CONTEXT enhances understanding without deviating from the core relevance of CONTEXT.\",\n    \"Assess the alignment in the purpose of both CONTEXT and RETRIEVAL_CONTEXT, ensuring that the retrieved context supports the reference context accurately.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.1,
          "reason": "Actual Output addresses duplicated usernames, whereas Expected Output deals with ensuring uniqueness in update processes involving multiple values.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0030175,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the Actual Output to the Expected Output for content similarity and completeness.\",\n    \"Check if the Actual Output contains a link to documentation as expected.\",\n    \"Ensure any additional information in Actual Output does not contradict the Expected Output.\",\n    \"Confirm that the Actual Output fulfills all key elements presented in the Expected Output.\"\n]"
        }
      ],
      "runDuration": 31.78430795800159,
      "evaluationCost": 0.046442500000000005,
      "order": 13
    },
    {
      "name": "test_customer_chatbot[test_case14]",
      "input": "Reference auto search not returning details?",
      "actualOutput": "If your reference auto search is not returning details, there are several steps you can take to troubleshoot the issue:\n\n1. **Check Implementations**: Ensure that there are indeed implementations that should be visible. You can verify this by checking the values in the database.\n\n2. **Modify the Query**: Change the query to search for everything. For example, using `QUERY:()` might help in identifying if there are any results at all.\n\n3. **Inconsistent Implementations**: Make sure there are no inconsistent implementations that could be breaking the search. You might need to delete all implementations of the definition and create a new one that should be visible.\n\n4. **Reindexing**: If the above steps do not work, try reindexing the definition.\n\n5. **Restart the Stage**: Sometimes, simply restarting the stage can resolve issues with searches.\n\n6. **Clear Cache**: Clear your browser cache or try accessing the application in a different browser or incognito mode, as cached data can sometimes interfere with searches.\n\n7. **Authorization Model**: Ensure that the Default Authorization Model is correctly set up, as it can filter what is visible in the search.\n\nFor more detailed guidance, you can refer to the documentation on debugging auto searches: [How to debug auto searches](https://innoveo.atlassian.net/wiki/spaces/IPH/pages/1798832170).",
      "expectedOutput": "The reference should only have the uuid 1 time and not 2 times with semi colon between as the search will not work properly in those cases.",
      "context": [
        "# Overview\n\nReference attributes are used to link implementations. Some of them are set automatically at creation time of an implementation structure, others are set by configuration. References between implementations are needed in order to use values of attributes of one implementation in the other one. Therefore it is possible to navigate through implementation references via dependencies, excels and variable resolver expressions.\n\n# Reference attribute properties\n\nProperty: Set Reference\nDescription:\nDefines how a reference can be set if it is not done by a user via the user interface (e.g. by dependency, excel etc.). The effective value of the reference attribute is not affected by this property. It is always \"{rootUUID};{rootUUID}\".\n\nSet reference by UUID\nIf this option is chosen, the UUID of the implementation root to be referenced must be set as value in the following format: {rootUUID};{rootUUID} in order to set the reference.\n\nSet reference by @CustomId\nIf this option is chosen, the value that is set must be equal to the value of the attribute \"@CustomId\" on an implementation of a model text-id specified below in order to set the reference.\nMandatory: Yes\nDefault value: by UUID\nExample: by @CustomId\n\n# The value of a reference attribute\n\nThe value of a reference attribute is the concatenation of the root uuid and the brick uuid (or again the root uuid if the reference points to the root) separated by \";\". This is also true if the reference is set via @CustomId! \n- {rootUUID};{brickUUID}\n- {rootUUID};{rootUUID}"
      ],
      "retrievalContext": [
        "# Result  \n1. In the App we have to create a new implementation of the CustomerGeneric\n2. Enter all the necessary data, and save the implementation.\n3. The implementation is created, but the Log Auto search is empty. Let's modify it the Phone number and the Email address data.  \n4. Now we can see the Log Auto search not empty.",
        "# Result  \n1. In the App we have to create a new implementation of the CustomerGeneric\n2. Enter all the necessary data, and save the implementation.\n3. The implementation is created, but the Log Auto search is empty. Let's modify it the Phone number and the Email address data and click on the SAVE button.\n4. Now we can see the Log Auto search not empty.",
        "# Reference attribute \"campaign Ref\"  \nIn order to apply a campaign to a quote we refer from the product implementation to the corresponding campaign implementation and use several features of the reference attribute. Please find the reference attribute's configuration below:  \n| Property | Value | Comments |\n| --- | --- | --- |\n| Input type | Reference auto complete | This input type is used because the attribute shall be displayed to call center users who could search for currently valid campaigns after creating a new quote and apply the campaign by selecting it. For public users the reference attribute won't be visible as this option of searching for campaigns should not be given to them. |\n| Search text type | searchDiscountCampaign | The search text type must match to the search text type of all campaign definitions to which this reference attribute can refer to. In case of a search via reference auto complete, the system will search in this text type for valid campaigns. |\n| Alias | campaignRef | The alias is set because we want to provide the option to set the reference via unencoded URL. |\n| Allow value set via unencrypted URL | selected | This checkbox is selected because we want to provide the option to set the reference via unencoded URL. |\n| Visibility | Read-write for call center users in first process step. <br> Hidden to public users. <br> Read-write in context page \"setCampaign\". | As mentioned above the reference attribute should be visible to call center users in order to give them the option to search for valid campaigns on an existing quote and apply it. For public users it is always hidden. <br> <br> In all channels and roles on context page \"setCampaign\" the attribute is set to \"read-write\" because this context page is used in URLs in order to set the reference via URL. |\n| Set reference | by @CustomId | In our example the reference \"campaignRef\" can only be set via @CustomId. So if ever the value of the reference attribute is set via a dependency, an excel, a URL or similar the @CustomId value of the campaign implementation must be set. This gives the option to provide an unencoded URL to partners for example who will replace the value for \"campaignRef\" with their campaign code (customId). Example: <br> <br> [https://skye2.innoveo.com/page/callcenter/en/us/process/enter/HomeCreatePolicy?productId=Home&activeZone=myproduct&set=campaignRef:**3006DISC11**,context:setCampaign](https://skye2.innoveo.com/page/callcenter/en/us/process/enter/HomeCreatePolicy?productId=Home&activeZone=myproduct&set=campaignRef:3006DISC11,context:setCampaign) |\n| Check validity | selected | As we want to make sure that a reference can only be set to a valid campaign, this is selected. |\n| Initial copy of values from target to source | selected | In the \"Attribute mapping\" tab we define a set of values that are overtaken from the campaign when the reference is set. |\n| Display validation error | selected | As the input type is set to 'Reference auto complete' the checkbox is ticked. A validation error will be displayed in case an invalid value is entered manually to the reference attribute. |\n| Referenced models | DiscountCampaign <br> CoverageCampaign | All model text-ids of campaign implementations to which this reference can refer must be listed here. |\n| Attribute mapping | For the example of the \"DiscountCampaign\" the following mappings are defined: <br> <table> <thead>  <tr> <th> Attribute in this def </th>  <th> Attribute in referenced definition </th> </tr> </thead>  <tbody>  <tr>  <td>DiscountCampaign.discountPercentage</td>  <td>DiscountCampaign.discount (ref\\[Campaign.campaignRef\\])</td> </tr>  <tr>  <td>DiscountCampaign.campaignName</td>  <td>DiscountCampaign.CampaignName (ref\\[Campaign.campaignRef\\])</td> </tr> <tr>  <td>DiscountCampaign.campaignTypeDiscount</td>  <td>DiscountCampaign.campaignType (ref\\[Campaign.campaignRef\\])</td> </tr> </tbody>  </table> | The discount percentage is overtaken as it will be used by the pricing. <br> <br> The campaign name is overtaken as it will be used in a message that appears when the campaign is applied. <br> <br> The campaign type is overtaken as it will be used in the pricing excel in order to distinguish which type of campaign was applied (if any). |\n| Dependency | ![screenshot](https://confluence.innoveo.com/is914/files/158605804/158605807/1/1711440822000/image2019-3-14_10-22-40.png) | One dependency is created on the reference attribute. The value of the attribute \"setCampaignViaCampaignCode\" is overtaken if set. The attribute \"setCampaignViaCampaignCode\" is the textbox that is displayed to public users in which they could enter a campaign code if they received one. <br> <br> Only if this code corresponds to a valid campaign, the reference will be set and the campaign is applied. |",
        "## Search query configuration  \nBelow are recommendations for configuring the search query and search text type of automatic searches.",
        "## Search usages  \nSearching all the areas where an object (e.g attribute) is referenced. This could be in variable resolvers, dependency rules, attribute pickers etc. On the contextual menu of the object for which usages want to be found, select 'Search usages' and the 'Usages' tab in the Search project panel will show all the fields in the project where the object is referenced. Hyperlinks will navigate to these fields.  \n**Note:** Currently the usages are not covered on value ranges and values and will work only in \"fields\" (not in Excel or any other attached resource files).",
        "How to debug auto searches  \nThe most common problem with an autosearch is that you think there are implementations that should be visible but for some reason, they don\u2019t appear.  \n1. Delete Default Authorization Model from the stage and only activate it back once there are implementations visible.\n2. Check if there are really implementations that should be visible  \n1. check the values in DB\n2. change the query so it searches for everything (I believe *QUERY:()* should work)\n3. Make sure there are no inconsistent implementation that breaks the whole search  \n1. delete all implementations of the definition\n2. create one new implementation which should be visible\n3. if this is not an option, try to reindex the definition\n4. Restart the stage\n5. Delete your cache / try it in a different browser or incognito mode  \n1. This is not a joke, sometimes your browser caches the search and does not realize that you changed the definitions.",
        "## Automatic search dashboard  \nThe automatic search in the default definition set in configured to not display anything. If this is needed, please refer to the [search documentation](../model-types/search/_index.md) for configuration instruction.",
        "# Configuration  \nConnection between the Automatic Search, Process and Generic/Product where the query is being defined must be set up correctly.",
        "# Configuration  \nConnection between the Automatic Search, Process and Generic/Product where the query is being defined must be set up correctly.",
        "# Autosearch  \n* Autosearch is filtered by Authorization\n* Imagine a free text search but with a fixed query\n* Supports Tab, which helps you to structure your searches better  \n+ Imagine like \u201cWork in Progress\u201d & \u201cMy Issued Policies\u201d tabs  \n* Columns and column-width the user can filter for their self\n* Typically, there is a column for actions.  \n+ it's a recommended practice to have info acting by opening a model dialog (like /ui-showcase/modaldialog) to share more details\n* Autosearches can be sorted (looks as on screenshot)  \n+ More details at <https://confluence.innoveo.com/is810/search-118334508.html#Search-SearchSortingSearchsorting/>\n* Filtering  \n+ If your autosearch is on a process, not on a zone (because we need to have an attribute saved to the database) you can do filtering.  \n- Filter attribute needs to be on a separate attribute\n- To do filtering, in the query of the autosearch, use double bracket resolvers and go through the component owner attribute and point to the filter attribute\n* You can set values on the selected objects (as on screenshot)  \n+ More details at <https://confluence.innoveo.com/is810/search-118334508.html#Search-Definitionstructure>\n+ Note: you can only set a static value!",
        "---\ntitle: \"Automatic search\"\nweight: 10\n---  \nAutomatic search component consists of one or more predefined searches which are represented as separate tabs in the user interface. Each tab will display the implementations matching the predefined query configured for that tab.  \nAutomatic search can be displayed in a process or in a zone. To do that, a [component attribute](../../attributes/specialized/component.md) pointing to the automatic search has to be created in the current process object or in the zone. The position of the automatic search within the process or a zone can be defined using the visibility and sort order properties of the component attribute.  \nThe search query of the automatic search can use the attributes of the current process object or the zone in which the automatic search is displayed.",
        "### Automatic search  \n* **@ComponentOwner** must be set to either the  \n+ Product/Generic\n+ Zone  \n* A **Query generic attribute** must be added with a default value set to a double bracket resolver pointing to the query parameter attribute of the generic definition.  \n+ This reference must be set by a direct reference pointing to the @ComponentOwner.\ne.g., *%{{ref[AutomaticSearch.@ComponentOwner to HomePageGeneric].root.QueryParameter->rawValue}}*",
        "### Text types  \nThe following text types can be configured for an automatic search:  \n| Text Type | Location | Description |\n| --- | --- | --- |\n| header | Root | Text displayed as the header of the automatic search component. |\n| searchInfo | Root | Text displayed below the search results. <br> For example: Showing records _START_ to _END\\_ of a total of _TOTAL\\_ entries |\n| searchNoRecords | Root | Text displayed if no search results are found. |\n| header | Brick | Text displayed as the header of the tab represented by this brick. |  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606703/1/1711441104000/SearchTexts_2.png)",
        "## Example  \nThe following example shows the search model for a home quote (productId=Home and processId=HomeB2CCreatePolicy). The Home implementation should only be found if the quote is in state\u2018MakePayment\u2019 and the values of the following three attributes match the implementation (\"email\", \"dateOfBirth\" and \"quoteNumber\").  \n#### **Search Model - Service attribute backend infos configuration:**  \n![screenshot](https://confluence.innoveo.com/is914/files/158605154/158605172/1/1711440550000/image2018-11-30_16-15-38.png)  \n#### **Search Model - Attribute configuration:**  \n| Attribute text-id | Attribute type | Additional information | <div style=\"width:500px\">Description</div> |\n| --- | --- | --- | --- |\n| homeRef | Reference | - | Referring to the product definition \u2018Home\u2019. |\n| email | Generic | Visible in the correct context (i.e. Context: public; Role: anonymous; Page: \"process_step_text_id\") | One of the search attributes on the search process step. |\n| dateOfBirth | Generic | Visible in the correct context (i.e. Context: public; Role: anonymous; Page: \"process_step_text_id\") | One of the search attributes on the search process step. |\n| quoteNumber | Generic | Visible in the correct context (i.e. Context: public; Role: anonymous; Page: \"process_step_text_id\") | One of the search attributes on the search process step. |\n| noRootFound | Generic | Dependency to set the attribute visible (read) and mandatory in case no root was found. | The generic attribute that prevents the page redirection in case the search criteria does not match an existing implementation. The attribute\u2019s text-id is specified in the corresponding backend info of the service attribute. |\n| @Status | Generic | Default value: MakePayment | Defines the state in which the quote must be in orderto be able to search for it. |\n| SetReferenceToRootFoundByAttributeCriteriaServiceDelegate | Service | <ul><li>Service: SetReferenceToRootFoundByAttributeCriteriaServiceDelegate</li><li>3 backend infos</li><li>Dependency for each search attribute</li></ul> | To set the reference in case a matching implementation is found.  |  \n#### **Search Model - Dependency on \"noRootFound\" attribute:**  \n![screenshot](https://confluence.innoveo.com/is914/files/158605154/158605178/1/1711440550000/image2018-3-6_16-57-33.png)  \n#### **Search Model - Dependency on service attribute \"SetReferenceToRootFoundByAttributeCriteriaServiceDelegate\":**  \n![screenshot](https://confluence.innoveo.com/is914/files/158605154/158605179/1/1711440550000/image2018-3-6_16-58-42.png)  \n#### **Search Process (in this case \"SearchProcess\"):**  \n![screenshot](https://confluence.innoveo.com/is914/files/158605154/158605155/1/1711440549000/image2018-11-30_16-12-34.png)  \n| Attribute text-id | Attribute type | <div style=\"width:1000px\">Additional information</div> | <div style=\"width:300px\">Description</div> |\n| --- | --- | --- | --- |\n| @RedirectUrl | Generic | Default value: <br> `%{SkyeConfigurationProperty['applicationContextName']}/page/public/en/us/process/enter/HomeB2CCreatePolicy?productId=Home&data=%encrypt('load=source:%{ref[SearchProcess.@CurrentProcessObject].ref[HomeQuotationSearchModel.homeRef].root->uuid'})` | Loading the existing implementation.` |  \n#### **Result (On the page with URL: \u2026/page/public/en/us/process/enter/SearchProcess?productId=HomeQuotationSearchModel):**  \nThe user can search for an implementation matching the three values \u2018Email\u2019, \u2018Date of Birth\u2019 and \u2018Quote number\u2019. In case one is found the page is redirected to the appropriate quote, otherwise the validation error message of the \u2018noRootFound\u2019 attribute is displayed:  \n![screenshot](https://confluence.innoveo.com/is914/files/158605154/158605181/1/1711440550000/image2018-3-6_17-2-46.png)",
        "### Process  \n* The process where the automatic search is visible must use Product / Generic mentioned above as **@CurrentProcessObject.**",
        "### Process  \n* The process where the automatic search is visible must use Generic mentioned above as **@CurrentProcessObject.**",
        "## Configuration examples  \n### Example 1 - automatic search displayed as a list  \nIn this example we will configure an automatic search which will be displayed in a zone and return a list of internal users.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606744/1/1711441105000/image2023-7-4_15-13-26.png)  \nThe configuration is as follows:  \n1. Add a new automatic search definition \"UsersAutomaticSearch\".  \n1. Define the texts on the root.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606724/1/1711441105000/image2022-11-29_10-1-12.png)\n1. Add the @SearchForModelTextIds, @SearchForModelTypes and @SearchSorting control attributes to the brick.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606746/1/1711441105000/image2023-7-4_14-40-16.png)  \n1. Add \"InternalUser\" to the list of model text-ids in the @SearchForModelTextIds control attribute.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606731/1/1711441105000/image2022-11-29_8-54-0.png)  \n1. In the @SearchQuery control attribute, enter value:\nQUERY:(InternalUser)  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606729/1/1711441105000/image2022-11-29_8-58-41.png)  \n1. In @SearchTextType control attribute, add a new search text type \"UsersAutoSearch\".  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606728/1/1711441105000/image2022-11-29_9-51-48.png)  \n1. In the InternalUser definition, on the Search texts tab, add a search text type of the same name as in the previous step \"UsersAutoSearch\" and define how the search results should be displayed and what should be stored in the index for the InternalUser implementations.  \nExample:  \n```\n<div style=\"display:block\">\n<b>Username: </b>%{InternalUser.@Username->shortOrFormattedValue}\n<p>Full name: %{InternalUser.firstName->shortOrFormattedValue} %{InternalUser.lastName->shortOrFormattedValue},\nemail address: %{InternalUser.@Email->shortOrFormattedValue}, created on %{root->creationDate}</p>\n</div>\n<div style=\"display:none\">InternalUser</div>\n```  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606728/1/1711441105000/image2022-11-29_9-51-48.png)  \n1. On the Zone definition, add a component attribute to the corresponding brick where the search should be displayed. Add \"UsersAutomaticSearch\" to the \"Component model text-id\" field in the Component tab of the attribute.  \nMake sure the visibility of the component attribute is set to \"read write\" in the default or a specific context.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606699/158606726/1/1711441105000/image2022-11-29_9-59-1.png)  \n1. Activate the definitions. All newly created internal users will be displayed in the search.  \nIn order to display the already existing internal users, a reindex would have to be done.",
        "# Limitations  \nTrigger search service attributes set values only on flexdata attribute with input type 'Auto complete'.",
        "### Search model / Generic definition  \nOn the search model, which is of model type \u2018Generic\u2019 the following information should be defined:  \n-Reference attribute referring definitions of model type that can be process objects (e.g. Product, Campaign, User, Event, etc)\n-The service attribute which triggers the search and sets the reference in case a unique concordant implementation is found\n-Search attribute(s) (e.g. \u2018Quote number\u2019 or \u2018State\u2019)\n-Behavior / message in case no implementation can be found which matches the search attribute criteria",
        "### Automatic search  \n* **@ComponentOwner** must be set to either the  \n+ Generic, in case it is a transient object (not saved to database).\n+ Process, in case values from an existing implementation must be used for calculation.  \n* A **Number of results generic attribute** must be added with a default value set to a double bracket resolver pointing to the number of results attribute of the generic definition.  \n+ This reference must be set either  \n- by a direct reference pointing to the @ComponentOwner, in case it is a transient object (not saved to database).\ne.g., *%{{ref[AutomaticSearch.@ComponentOwner to HomePageGeneric].root.NumberOfResults->rawValue}}*\n- or a \u201cmulti-hop\u201d reference pointing to the @ComponentOwner's @CurrentProcessObject, in case values from an existing implementation must be used for calculation.\ne.g., *%{{ref[AutomaticSearch.@ComponentOwner to HomePageProcess].ref[root.@CurrentProcessObject to HomePageGeneric].root.NumberOfResults->rawValue}}*\n+ Make sure to add a leading zero to the default value to ensure the automatic search won\u2019t fail in case the referenced attribute cannot be resolved."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the actual output perfectly aligns with the retrieval context, demonstrating complete faithfulness without any contradictions. Great job maintaining consistency!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0220325,
          "verboseLogs": "Truths (limit=None):\n[\n    \"A new implementation of CustomerGeneric must be created in the app.\",\n    \"Necessary data must be entered and saved to implement the CustomerGeneric.\",\n    \"Modifying the phone number and email address allows the Log Auto search to become unempty.\",\n    \"The reference attribute 'campaign Ref' is for applying a campaign to a quote.\",\n    \"Reference auto complete input type is used for displaying valid campaigns to call center users.\",\n    \"Campaign implementation uses 'searchDiscountCampaign' as the search text type.\",\n    \"The reference attribute's alias is 'campaignRef'.\",\n    \"Reference can be set via unencrypted URL for setCampaign.\",\n    \"Visibility of the reference attribute is read-write for call center users and hidden from public users.\",\n    \"Reference attribute set by '@CustomId' can be replaced with a campaign code in the URL.\",\n    \"Validation is ensured for the reference to be set to a valid campaign.\",\n    \"Referencing 'DiscountCampaign' requires specific attribute mappings.\",\n    \"There exists a dependency related to 'setCampaignViaCampaignCode'.\",\n    \"Automatic search dashboard requires proper configuration for visibility.\",\n    \"Components of the automatic search include predefined searches represented as separate tabs.\",\n    \"The header, search info, and searchNoRecords are text types configured for automatic searches.\"\n] \n \nClaims:\n[\n    \"If your reference auto search is not returning details, there are several steps you can take to troubleshoot the issue.\",\n    \"You can verify if implementations should be visible by checking values in the database.\",\n    \"Changing the query to 'QUERY:()' might help in identifying if there are any results at all.\",\n    \"Ensuring there are no inconsistent implementations might prevent breaking the search.\",\n    \"Reindexing the definition can be tried if other steps do not work.\",\n    \"Restarting the stage sometimes resolves issues with searches.\",\n    \"Clearing your browser cache or trying a different browser or incognito mode might help with search issues.\",\n    \"Ensuring the Default Authorization Model is correctly set up can affect search visibility.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.9,
          "reason": "The score is 0.90 because the response accurately addresses the issue with the reference auto search feature, providing valuable insights into potential causes for it not returning details. The single irrelevant statement pertaining to Default Authorization Model slightly detracted from complete precision, preventing a perfect score. Overall, the relevant information effectively guides the resolution of the core concern, achieving a high relevancy score.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0068675,
          "verboseLogs": "Statements:\n[\n    \"Verify if reference auto search returns details.\",\n    \"Check if implementations are visible by examining values in the database.\",\n    \"Modify the query to search for everything to identify if there are any results.\",\n    \"Ensure implementations are consistent and visible.\",\n    \"Consider deleting and recreating inconsistent implementations.\",\n    \"Reindex the definition if previous steps fail.\",\n    \"Restart the stage to resolve issues with searches.\",\n    \"Clear browser cache or use incognito mode for troubleshooting.\",\n    \"Ensure Default Authorization Model is set up correctly.\",\n    \"Refer to documentation for more guidance on debugging auto searches.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The Default Authorization Model is a configuration setting not directly related to reference auto search functions.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.2,
          "reason": "The main topics do not align; Context focuses on reference attributes, while Retrieval Context discusses automatic searches and campaign references. Key details about reference attribute properties are missing in Retrieval Context, which focuses on unrelated search functionality and process categories. There are no functional links in Retrieval Context, violating step 3. Additional information regarding 'campaignRef' does not contradict the main topic but is unrelated.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.015905000000000002,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Compare the main topic of CONTEXT and RETRIEVAL_CONTEXT to ensure they align.\",\n    \"Verify that key details from CONTEXT are present within RETRIEVAL_CONTEXT.\",\n    \"Check if RETRIEVAL_CONTEXT contains a link, confirming it is functioning properly.\",\n    \"Assess if additional information in RETRIEVAL_CONTEXT does not contradict the main topic of CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.2,
          "reason": "The Actual Output includes troubleshooting steps and a link to documentation as required, but it does not align with the content or structure of the Expected Output, which mentions a specific issue related to UUID formatting.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0032624999999999998,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the Actual Output to the Expected Output for similarity in content and structure.\",\n    \"Verify that the Actual Output includes a link to relevant documentation as expected.\",\n    \"Check for any additional information in the Actual Output and ensure it complements rather than contradicts the Expected Output.\",\n    \"Evaluate any instances of contradicting information; if found, mark the Actual Output as unacceptable.\"\n]"
        }
      ],
      "runDuration": 29.08553404200211,
      "evaluationCost": 0.048067500000000006,
      "order": 14
    },
    {
      "name": "test_customer_chatbot[test_case15]",
      "input": "Is it possible to navigate from one process into an another and load the implementation's data?",
      "actualOutput": "Yes, it is possible to navigate from one process to another and load the implementation's data. You can achieve this by using specific URLs that include parameters for loading the implementation.\n\nFor example, you can use the following URL pattern to load an existing implementation:\n\n```\n/page/{channel}/{language}/{country}/process/enter/{processId}?data=%encrypt('load=source:%{modelTextId->uuid}')&activeZone={zoneId}\n```\n\nThis URL allows you to enter a specific process and load the implementation data based on the provided parameters.\n\nFor more detailed information, you can refer to the documentation on loading implementations: [Load implementations](https://confluence.innoveo.com/dosearchsite.action?queryString=urls).",
      "expectedOutput": "This is possible in Skye by using URLs. There should be an action button with exit process navigation properties. Also a redirect URL control attribute needed in the process step. \nThe redirect URL should contain the new process enter and use the \"data\" or \"action\" parameter. Make sure the data is encrypted by using 'encrypt' function resolver.",
      "context": [
        "# Load implementations\n\nTo start a process and load an existing implementation either the parameter 'data' or 'uuid' have to be used:\n\nProcess layout: internal and public\ndata: /page/{channel}/{language}/{country}/process/enter/{processId}?data=%encrypt('load=source:%{modelTextId->uuid}')&activeZone={zoneId}\nuuid: /page/{channel}/{language}/{country}/process/enter/{processId}?uuid=%encrypt('%{modelTextId->uuid}')&activeZone={zoneId}\n\nProcess layout: standalone\ndata: /page/{channel}/{language}/{country}/component/process?processId={processId}&data=%encrypt('load=source:%{modelTextId->uuid}')\nuuid: /page/{channel}/{language}/{country}/component/process?processId={processId}&uuid=%encrypt('%{modelTextId->uuid}')\n\n##Example\nhttps://training10.innoveo.com/page/callcenter/en/us/process/enter/HomeCreatePolicy?data=%encrypt('load=source:%{Home->uuid}')&activeZone=myproduct\n\n## Explanations\n\n- data: Parameter which has to be used together with the uuid of the implementation to be loaded.\nThe part which is loaded needs to be encrypted, meaning the function resolver %encrypt() has to be used. (Possible to combine this parameter with action parameters like e.g. 'copyAndLoad', 'set', 'setReferences' or 'createBricks'. See chapters below)\n-uuid: Parameter which loads an implementation given its uuid. \nThe part which is loaded needs to be encrypted, meaning the function resolver %encrypt() has to be used. (Not possible to combine this parameter with other action parameters.)"
      ],
      "retrievalContext": [
        "## Enter another process by button  \nBy clicking on a button you normally move from one page to the next within the same process. But it is also possible to directly enter into another process by clicking a button.",
        "## Copy and load implementations  \nIt is possible to create a copy of an existing implementation by clicking on a link with a specific url:  \n| Process layout | Url |\n| --- | --- |\n| internal and public | /page/{channel}/{language}/{country}/**process**/**enter**/{processId}?**data**\\=%encrypt('copyAndLoad=source:%{modelTextId->uuid}')&**activeZone**\\={zoneId} |",
        "## Process step entry event  \nIn bricks of type 'Process step' within 'Process' definitions, it's possible to define a set of parameters to be sent whenever the user enters such process step.",
        "### Copy transition  \nIn the product state machine you can also use a special transition called \"copy\". It is always triggered when the user clicks on a link which includes theparameter \"copyAndLoad\".",
        "## Enter directly to another step than the first  \nIt is possible to configure the process URL to enter directly to another step than the first.",
        "### How to configure  \n1. Add an action attribute to the first process step.\n1. Keep the visibility of this action attribute \"hidden\".\n1. Enter name and action name.\n1. In \"Navigation\" select \"Transition to another process step\".\n1. In \"Transition to step\" enter the textId of the step you want enter directly.\n1. Select \"Validate on action\".  \n![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606421/1/1711441002000/image2023-10-18_14-2-16.png)  \n1. Add the following part to the URL somewhere after the process id: **&initProcessAction={actionName}**  \nLike this you can trigger the action of your hidden action button when entering the process and you will automatically be redirected to the step you have configured in this button.",
        "## Other transition handlers  \nWithin a transition you have the possibility to execute other tasks like:  \n- Create implementation roots\n- Set default values  \nThe goal of this section is to explain the usage of these tasks and how to configure them in a state machine.",
        "## Load implementations  \nTo start a process and load an existing implementation either the parameter 'data' or 'uuid' have to be used:  \n| Process layout | Parameter | Url Pattern |\n| --- | --- | --- |\n| internal and public | data | /page/{channel}/{language}/{country}/**process**/**enter**/{processId}?**data**\\=%encrypt('load=source:%{modelTextId->uuid}')&**activeZone**\\={zoneId} |\n| internal and public | uuid | /page/{channel}/{language}/{country}/**process**/**enter**/{processId}?**uuid**\\=%encrypt('%{modelTextId->uuid}')&**activeZone**\\={zoneId} |\n| standalone | data | /page/{channel}/{language}/{country}/**component**/**process**?**processId**\\={processId}&**data**\\=%encrypt('load=source:%{modelTextId->uuid}') |\n| standalone | uuid | /page/{channel}/{language}/{country}/**component**/**process**?**processId**\\={processId}&**uuid**\\=%encrypt('%{modelTextId->uuid}') |",
        "---\ntitle: \"Import service attribute\"\nweight: 260\n---  \nThe 'Import service attribute' allows the user to configure an online import functionality (not event based). Similar to the \"[Import from root](../../model-types/task/import/import-from-root.md)\", it is possible to trigger an import of implementations based on a csv file within the web application. In contrast to the event based solution, where it is possible to schedule the import for a different date or time, this import is done immediately when the service attribute is triggered. Apart from that, the following functionality is available:  \n- The possibility to **set a reference** in the created roots pointing to the root containing the service attribute.\n- Since this action is triggered by a final user, it's made possible to **give feedback about the operation**, offering the possibility to write in attributes the number of records imported successfully, ignored or failed. Is also possible to create a file with detailed information about the import result and leave this file in a resource attribute.",
        "# Skye solution  \nThe idea behind the solution is the following:  \n* The use of zones and @ProcessStartUrl attribute on zones allows us to redirect the user anywhere after log-in (user logs in, zone is loaded, @ProcessStartUrl is triggered and user is redirected). Generally this is used to load a process when the zone is clicked, but it can be used for this functionality as well.",
        "### Explanations  \n| Parameter | Description | Example |\n| --- | --- | --- |\n| page | fix |    |\n| channel | channel name | callcenter |\n| language | language code | en |\n| country | country code | us |\n| process | fix |   |\n| enter | use \"enter\" for all processes |    |\n| processId | model textId of the process definition | HomeCreatePolicy |\n| modelTextId | model textId of the current process object <br> **Note:** For historical reasons, it is also possible to use 'productId' instead of 'modelTextId'. | Home or SearchModel |\n| zoneId | textId of the brick in the ZoneDefinition that represents the zone you want to be active while going through the process. | activeZone=myproduct |\n| component | indicates that the standalone process component is used. |    |",
        "### Explanations  \n| Parameter | Description | Example |\n| --- | --- | --- |\n| initProcessAction | Parameter which allows to enter directly a process step other than the first. You can find details about this configuration in [Process](./model-types/process.md). | initProcessAction=buyNowOnline |\n| redirectToLoad | Parameter which has as impact that the user is redirected to a \"load\" URL. This should be added if it should not be possible to create another implementation by refreshing the URL in the browser. |   |\n| activeUiGroup | Parameter which loads a page on a specific ui group. As value it is only possible to set a brick text-id of a ui definition which either represents a tab, panel or a fieldset. | activeUiGroup=ContactInformation |",
        "### Configure a process step brick  \n1. Add a brick to the root and enter a text-id.  \nIf you require a UI definition to be created automatically for the process step then select the checkbox 'Create UI definition'. See [here](../model_types/ui_definition/process_layout/_index.md) for more information on UI definition creation.  \n1. Set sort order according to the order of this step in the process.\n1. Set default visibility to read.\n1. Add a text of type \"header\" and enter the label of this process step.\n1. It is also possible to add a text type \"infoText\" to provide an additional explanation about the process step.\nThis text will appear right under the Process header text in the progress bar.  \n**Result:**  \n![Info Text](https://confluence.innoveo.com/is914/files/158606419/158606486/1/1711441006000/image2022-5-17_18-43-29.png)",
        "## Possible values  \nAs values you can either enter a fix string or use variable resolvers or a combination of both. The following variable resolver types can be used:  \n| Type | Examples |\n| --- | --- |\n| Skye context | `%{SkyeContext\\['channel'\\]}, %{SkyeContext\\['localeLanguage'\\]}` |\n| User context | `%{UserContext\\['username'\\]}` |\n| Values from current process object (e.g. product) | `%{ref\\[HomeCreatePolicy.@CurrentProcessObject\\].Analytics.productId->rawValue}` |\n| UUID of current process object | `%{ref\\[HomeCreatePolicy.@CurrentProcessObject\\]->uuid}` |\n| Values from shopping cart of current process object | `%{ref\\[HomeCreatePolicy.@CurrentProcessObject\\].ref\\[HomeTraining.shoppingcartItemRef\\].ref\\[ShoppingcartItem.insuredObject\\].Shoppingcart.paymentMethod->rawValue}` |\n| UUID of shopping cart of current process object | `%{ref\\[HomeCreatePolicy.@CurrentProcessObject\\].ref\\[HomeTraining.shoppingcartItemRef\\].ref\\[ShoppingcartItem.insuredObject\\]->uuid}` |",
        "### Process driven transitions  \nA process driven transition is triggered when the user presses on an action button whose action name equals to the transition event name. The entry point for all transitions originated from a process action is the shoppingcart state machine. To trigger non-automatic transition events in other state machines than the shoppingcart state machine we have to propagate the transitions from the shopping cart state machine to them. How events are propagated from the shoppingcart state machine to the product state machine is described below.  \n![screenshot](https://confluence.innoveo.com/is914/files/158607322/158607323/1/1711441340000/image2016-4-19+11%3A0%3A21.png)",
        "Dynamic search queries on a Process",
        "### Implementation creation and copy service  \nThe configuration of this attribute is fairly straightforward. An example of mapping values to the newly created implementation is shown below.",
        "### Configuring a new process  \n1. Create a new definition of model type \"Process\" and enter a unique model text-id.\n1. Enter the number of process steps required. If you require UI definitions to be created automatically for the process then select the checkbox 'Create UI definitions'. See [here](../model_types/ui_definition/process_layout/_index.md) for more information on UI definition creation.  \n![Create Process Definition](https://confluence.innoveo.com/is914/files/158606419/158606499/1/1711441007000/image2022-5-17_18-11-36.png)  \n1. On the process root, it is possible to configure the followings:  \n![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606550/1/1711441009000/image2022-6-2_17-47-39.png)  \n- If the progress bar will be displayed in the process or not (Property: 'Display progress bar'). In case of a visible progress bar, the following configuration options would be available  \n- 'Progress bar orientation' property: Defines if the progress bar will be displayed vertically or horizontally\n- 'Process step headers to be displayed': Gives the possibility to choose which process steps headers are going to be displayed. The following options are available  \n|||\n| --- | --- |\n| All: all the process step headers are going to be visible | ![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606547/1/1711441009000/image2022-6-2_17-52-22.png) |\n| Current: Only the current process step header is going to be visible | ![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606545/1/1711441008000/image2022-6-2_17-55-59.png) |\n| None: None of the process step headers are going to be visible | ![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606544/1/1711441008000/image2022-6-2_17-57-6.png) |\n| Previous, current and next: Only the previous, the current and the next process step headers are going to be visible |![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606543/1/1711441008000/image2022-6-2_17-58-14.png)  \n- 'Display process step number' property: Select to display the sequence number of the process steps  \n|||\n| --- | --- |\n| Process steps with numbers |![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606547/1/1711441009000/image2022-6-2_17-52-22.png) |\n| Process steps without numbers | ![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606542/1/1711441008000/image2022-6-2_18-0-27.png) |  \n- 'Enable sticky progress bar' property: If the property is selected the progress will be stick with the following criteria\n- If there is a sticky bar element, the progress bar will stick to it.\n- If there isn't a sticky bar element, the progress bar will stick to the header.\n- If there isn't a sticky bar element and there isn't a header, the progress bar will stick to the top of the page.\n**Note:** Sticky progress bar options are only available in the case of horizontal progress bars.\n- 'Progress bar header' text and 'Progress bar footer' text\n- 'Activate progress bar navigation' property: Select this property to enable the navigation to previous process steps. In the case of allowing the navigation, it will be possible to configure\n- The text that will appear as a link                                      ![Link Text](https://confluence.innoveo.com/is914/files/158606419/158606468/1/1711441004000/image2022-5-24_15-43-38.png)\n- The list of process steps where it would not possible to navigate.  \n1. The process is created with suggested action buttons for each step. These can be edited to suit the project needs.  \n![Process Page](https://confluence.innoveo.com/is914/files/158606419/158606491/1/1711441006000/image2022-5-17_18-25-4.png)  \n1. On the root on the control attribute \"@CurrentProcessObject\" on tab 'Reference' set model type of referenced model to \"Product\".  \nRefer to \"[Delete task](https://confluence.innoveo.com/is914/delete-task-158606234.html)\" for Delete behavior.  \nAdd reference to a model (select product definition you want to use this process for). **Note**: It is only possible to reference one process object from a process.  \n![screenshot](https://confluence.innoveo.com/is914/files/158606419/158606490/1/1711441006000/image2022-5-17_18-26-42.png)  \n1. In case a process header should be displayed on top of the process, a text of type 'header' can be defined.",
        "## Import from root with a re trigger in case of failure  \nThis section provides a step-by-step guide on scheduling an import from the root and how to re trigger it if it fails during execution. The only prerequisite is that there exists an initial configuration with two products and processes already in operation, as these products will be utilized both to initiate the import and to serve as the items to be imported.  \n**Create the import from root task**  \n1. Create the CSV file  \nThe import will create or update implementations of type \"ProductImported\" and the CSV file will have three columns KEY, ATTRIBUTE1, ATTRIBUTE2 (The import will update if required 3 attributes)  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606347/1/1711440991000/image2024-3-18_11-5-29.png)  \n1. Add the following configuration in the product that is responsible of triggering the import from root (In this example they will be added to the product \"ProductTriggeringImport\")  \n- Configure the resource attribute where the user will upload the import file\n- Configure the scheduler attribute that will be in charge of scheduling the import task\n- Configure the dependency that will be triggering the scheduler\n- The scheduler used in the scheduler attribute will be explained below  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606351/1/1711440991000/image2024-3-18_10-18-19.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606350/1/1711440991000/image2024-3-18_10-18-45.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606349/1/1711440991000/image2024-3-18_10-24-26.png)  \n1. Create a new \"Import from root\" task and configure it:  \n- General tab: set the language as en_us\n- Import file tab:\n- specify the model text-id that will be in charge of triggering the scheduler\n- define the resource attribute where the file to be imported will be uploaded\n- specify the transformation definition to be used for importing records (See detailed configuration below)  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606353/1/1711440991000/image2024-3-18_10-6-49.png) ![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606352/1/1711440991000/image2024-3-18_10-7-20.png)  \n1. Add a new time based scheduler  \n- Specify the \"Trigger time\" property\n- Add the task where the import from root was configured  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606348/1/1711440991000/image2024-3-18_10-27-30.png)  \n1. Create a new transformation definition and  \n- configure the mandatory control attributes\n- configure the attributes that are going to be updated if required in the import  \n**Mandatory control attributes**  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606346/1/1711440991000/image2024-3-18_11-7-26.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606345/1/1711440991000/image2024-3-18_11-7-50.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606344/1/1711440991000/image2024-3-18_11-8-9.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606343/1/1711440991000/image2024-3-18_11-8-28.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606342/1/1711440991000/image2024-3-18_11-8-48.png)  \n**Attributes updated during the import**  \n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606341/1/1711440991000/image2024-3-18_11-15-25.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606340/1/1711440991000/image2024-3-18_11-15-43.png)\n![screenshot](https://confluence.innoveo.com/is914/files/158606337/158606338/1/1711440991000/image2024-3-18_11-16-6.png)",
        "---\ntitle: \"URLs\"\n---  \nThe urls to start a process depend on the process layout and the actions to be taken. The chapters below are structured by url pattern, examples and explanations."
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Fantastic job! The faithfulness score is 1.00, reflecting flawless alignment between the actual output and the retrieval context. Keep up the stellar work!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.020147500000000002,
          "verboseLogs": "Truths (limit=None):\n[\n    \"A user can move from one page to another within or outside the same process by clicking a button.\",\n    \"It is possible to create a copy of an existing implementation through a specific URL pattern.\",\n    \"The \"copy\" transition is triggered when a user clicks on a link containing the parameter \"copyAndLoad\".\",\n    \"Process step definitions allow for setting parameters that send information when entering a process step.\",\n    \"A process URL can be set up to enter directly into a different step rather than the first.\",\n    \"The 'Import service attribute' provides an online import functionality based on a CSV file.\",\n    \"Imports via the 'Import service attribute' are immediate and not event-scheduled.\",\n    \"The Skye solution uses zones and @ProcessStartUrl to redirect users after login.\",\n    \"Process driven transitions are activated by action buttons matching the transition event name.\",\n    \"A process can be configured with a progress bar that can display vertically or horizontally.\",\n    \"It is possible to configure an import to be triggered from the product context by scheduling tasks.\",\n    \"A dynamic search query can be operated on a process with process-driven transitions.\"\n] \n \nClaims:\n[\n    \"It is possible to navigate from one process to another and load the implementation's data using specific URLs.\",\n    \"The URL pattern \"/page/{channel}/{language}/{country}/process/enter/{processId}?data=%encrypt('load=source:%{modelTextId->uuid}')&activeZone={zoneId}\" can be used to load an existing implementation.\",\n    \"The URL allows entering a specific process and loading implementation data based on the provided parameters.\",\n    \"More detailed information about loading implementations can be found in the documentation linked at: https://confluence.innoveo.com/dosearchsite.action?queryString=urls.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 1.0,
          "reason": "The score is 1.00 because the response excellently answered the input question without including any irrelevant information, maintaining a focus on discussing the possibilities of navigating between processes and loading implementation data.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.004985000000000001,
          "verboseLogs": "Statements:\n[\n    \"It is possible to navigate from one process to another and load the implementation's data.\",\n    \"Achieve this by using specific URLs.\",\n    \"Use the URL pattern to load an existing implementation.\",\n    \"Enter a specific process and load the implementation data based on provided parameters.\",\n    \"Refer to the documentation on loading implementations.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": true,
          "score": 0.853846251780945,
          "reason": "RETRIEVAL_CONTEXT includes relevant information on 'data' and 'uuid' parameters for loading implementations, similar to CONTEXT. However, the example link provided in CONTEXT is not replicated, and there's more emphasis on 'copyAndLoad' in RETRIEVAL_CONTEXT, which adds complexity without altering relevance.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.015102499999999998,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Check if RETRIEVAL_CONTEXT includes all relevant information found in CONTEXT.\",\n    \"Verify that RETRIEVAL_CONTEXT has a link as expected.\",\n    \"Ensure that additional information in RETRIEVAL_CONTEXT does not impede the relevance or accuracy of the original CONTEXT.\",\n    \"Assess if the overall intent and main points of CONTEXT are preserved in RETRIEVAL_CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": false,
          "score": 0.5,
          "reason": "The Actual Output provides a URL pattern for loading implementation with an encryption detail, matching the Expected Output's need for encrypted 'data', but lacks mention of an action button and redirect URL control attribute.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0030625,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Check if the Actual Output contains a link to documentation as expected.\",\n    \"Evaluate how closely the Actual Output matches the Expected Output in terms of key information and details.\",\n    \"Ensure that any additional information provided in the Actual Output does not contradict the Expected Output.\",\n    \"Confirm that any additional details in the Actual Output are relevant and do not detract from the primary information expected.\"\n]"
        }
      ],
      "runDuration": 27.55947816600019,
      "evaluationCost": 0.0432975,
      "order": 15
    },
    {
      "name": "test_customer_chatbot[test_case16]",
      "input": "I am generating documents using a PrintService attribute on a generic definition. How can I access the datas that are on the product definition and print them onto the document?",
      "actualOutput": "To access data from a product definition and print it onto a document using the PrintService attribute on a generic definition, you can utilize variable resolvers to navigate through references. Here\u2019s a general approach:\n\n1. **Set Up the PrintService Attribute**: Ensure that your PrintService attribute is correctly configured with the necessary properties, including the template, context channel, context role, context page, locale, document name, and resource attribute.\n\n2. **Use Variable Resolvers**: You can use variable resolvers to access attributes from the product definition. The syntax for accessing attributes through references typically looks like this:\n   ```\n   %{ref[Root1.ReferenceAttribute1].Root2.Attribute->formattedValue}\n   ```\n   Here, `Root1` would be your generic definition, `ReferenceAttribute1` would be the attribute that references the product definition, and `Root2.Attribute` would be the specific attribute you want to access from the product definition.\n\n3. **Example**: If you have a reference attribute in your generic definition that points to a product definition, you can access its attributes like this:\n   ```xml\n   <productName>%{ref[GenericDefinition.ProductRef].Product.Name->formattedValue}</productName>\n   <productPrice>%{ref[GenericDefinition.ProductRef].Product.Price->formattedValue}</productPrice>\n   ```\n\n4. **Configure the Template**: Ensure that your XSL template used for generating the PDF document is set up to include these variable resolvers. The template should be able to interpret and format the data correctly.\n\n5. **Trigger the PrintService**: Once everything is set up, you can trigger the PrintService by setting its value to true, which will generate the PDF document with the data pulled from the product definition.\n\nFor more detailed information on configuring the PrintService attribute and using variable resolvers, you can refer to the following documentation links:\n- [Print Service Configuration](https://confluence.innoveo.com/dosearchsite.action?queryString=print)\n- [Variable Resolvers](https://confluence.innoveo.com/dosearchsite.action?queryString=variable-resolver)\n\nMake sure to adapt the variable resolver paths according to your specific definitions and attributes.",
      "expectedOutput": "You can access the datas on the product definition by using a reference attribute. Reference attributes pick up UUIDs as values, so you can map the generic's UUID to the created reference attribute on the product definition. Depending on your solution, you can do it in the opposite way as well.",
      "context": [
        "Generating Documents\n# Overview\n\nInnoveo Skye offers XSLT-FOP based document generation and document archive functionalities out of the box. It also offers the possibility to extract template definitions, images, styles and font definition in to a common definition for reuse across products.  \n\nApache\u2122 FOP (Formatting Objects Processor) is a print formatter driven by XSL formatting objects (XSL-FO) and an output independent formatter. It is a Java application that reads a formatting object (FO) tree and renders the resulting pages to a specified output. Innoveo Skye leverages the power of FOP to generate document that can output target as PDF.\n\nThe documents are generated on demand, meaning that it is generated when the user click on a document link. There are distinct URL\u2019s for document generation with or without persisting or with attachment to an email.\n\n# Adding content from attributes navigating through references and back references \n\nIn the following example,  two attributes are included coming from a navigation through a back reference (firstName, lastName), and an attribute is included from a navigation through a reference. \n\nTo include external attributes, all of them (references, back references and attributes) need to have visibility read in the printing context.\n```\n        <fo:block>\n               First name from back ref:\n              <xsl:for-each select=\"//attribute-lines[*/id = 'Travel-myBackRef-Home-Customer-firstName']/right-column-attribute\">      \n              - <xsl:value-of select=\"value-text\"/> \n              </xsl:for-each>\n           </fo:block>\n            <fo:block>\n           Last name from back ref:  \n               <xsl:for-each select=\"//attribute-lines[*/id = 'Travel-myBackRef-Home-Customer-lastName']/right-column-attribute\">      \n              - <xsl:value-of select=\"value-text\"/>\n              </xsl:for-each>\n        </fo:block>\n\n          <fo:block>\n          Email from a reference: <xsl:value-of select=\"//attribute-lines[*/id = 'Travel-MotorRef-Motor-Customer-Email']/*/value-text\"/>\n        </fo:block>\n```\n\nReference attribute\n# Overview\n\nReference attributes are used to link implementations. Some of them are set automatically at creation time of an implementation structure, others are set by configuration. References between implementations are needed in order to use values of attributes of one implementation in the other one. Therefore it is possible to navigate through implementation references via dependencies, excels and variable resolver expressions. \n\n# The value of a reference attribute\n\nThe value of a reference attribute is the concatenation of the root uuid and the brick uuid (or again the root uuid if the reference points to the root) separated by \";\". This is also true if the reference is set via @CustomId! \n\n    {rootUUID};{brickUUID} \n    {rootUUID};{rootUUID}\n "
      ],
      "retrievalContext": [
        "---\ntitle: \"Print service\"\nweight: 350\n---  \nThe print service attribute generates a PDF document using a configured template and saves the document in a resource attribute.",
        "## Configure print service attribute  \n![screenshot](https://confluence.innoveo.com/is914/files/158604870/158604871/1/1711440492000/image2018-12-21_10-32-45.png)  \n| Property | <div style=\"width:500px\">Description</div> | Mandatory | Default value | Example |\n| --- | --- | --- | --- | --- |\n| Template | Template file used to generate the PDF document. | Y | - | someName.xsl |\n| Context channel | Channel used to calculate the context in which the attributes in the template are configured (visibility and sort order). <br> It accepts text and variable resolver. | Y | - | `%{SkyeContext['channel']}` |\n| Context role | Role used to calculate the context in which the attributes in the template are configured (visibility and sort order). <br> It accept text and variable resolver. | Y | - | `%{SkyeContext['skyeRole']}` |\n| Context page | Page used to calculate the context in which the attributes in the template are configured (visibility and sort order). <br> It accepts text and variable resolver.  | Y | - | `%{SkyeContext['page']}` |\n| Locale | Defines the locale/language in which the document has to be generated. <br> The picker has two options, variable resolver or a drop down with the languages available in the project.  | Y | - | en_US |\n| Document name | Defines the PDF filename (extension will be added if not provided). <br> It accepts text and variable resolver. | Y | - | DocumentName |\n| Resource attribute | Defines the resource attribute in which the PDF is going to be stored. | Y | - | Travel.ResourceAttribute |",
        "# Export with APIs  \n## Expose APIs  \nInformation can be retrieved by exposing a REST endpoint from Skye. The response body can contain any attribute of the definition or connected definitions (Reachable on the logical definition model).  \nThere are three different methods to achieve this",
        "## Display of other model types  \nInstead of displaying product definitions in the product selector it is also possible to display definitions of the following model types:  \n- User\n- User group\n- Generic\n- Campaign  \nThe respective model type has to be set on the definition reference attribute. Texts and images have to be configured exactly the same way as on product definitions.",
        "---\ntitle: \"Generic\"\n---  \nGeneric definitions are used when no special model type is needed. As for product definitions, most of the tools described in this user guide are applicable for generic definitions (depending on the usage stream) so there is no additional documentation added here.",
        "## Triggering printing service  \nAs most of our service attributes,the printing service will be triggered every time that its value is set to true. Once the PDF is generated, the value is reset to empty.",
        "## Selector component configuration for a current process object  \n1. Create the selector component definition\n1. Ensure the contexts where the items (definition reference attribute/s e.g. to products) are visible in the [product categorization definition](./product-categorization.md) are configured identically to the product categorization definition\n1. On the current process object, where the selector component definition should be displayed, create a[component attribute](../attributes/specialized/component.md)\n1. On the component attribute property 'Component model text id' select the selector component definition\n1. On the property 'Context page' select the context where the relevant definition reference attribute/s are visible in the [product categorization definition](./product-categorization.md)\n1. Set the[component attribute](../attributes/specialized/component.md)to be visible in the contexts which the elector component definition should appear",
        "## List of non-functional variable resolvers  \n{{< callout type=\"warning\" >}}\nIn the formulas below we use \"Root\" instead of \"ModelTextId / RootTextId\", \"root\" to refer to the current definition root without having to specify its text-id, \"Brick\" instead of \"BrickTextId\", \"Attribute\" instead of \"AttributeTextId\" and \"ReferenceAttribute\" instead of \"ReferenceAttributetextId\".\n{{< /callout >}}  \n| Resolver type | Formula | Retrieves |\n| --- | --- | --- |\n| **Value resolver** | `%{Brick.Attribute->shortOrFormattedValue}` | Label text of the value if existing, otherwise the formatted value of referenced attribute (same as `%{Brick.Attribute->formattedValue})` |\n| | `%{Brick.Attribute->formattedValue}` | Formatted value of the referenced attribute |\n| | `%{Brick.Attribute->rawValue}` | Unformatted value of the referenced attribute which is stored in the database. |\n| | `%{Brick.Attribute->uuid}` | UUID of referenced attribute (implementation) |\n| | `%{Brick->uuid}` | UUID of referenced brick (implementation) |\n| | `%{Root->uuid}` | UUID of referenced root (implementation) |\n| **Resource specific resolver** | `%{Brick.ResourceAttribute->resourceContent}` | Returns the base64 of the resource in the resource attribute or empty if there is no resource associated to the attribute. |\n| | `%{Brick.ResourceAttribute->resourceName}` | Returns the file name of the resource associated to the single resource attribute or empty if there is none. |\n| **Multibrick resolverMultibrick resolver** | `%{Brick#.Attribute->formattedValue}` | Formatted value of the referenced attribute in the current multibrick |\n| | `%{Brick#1.Attribute->rawValue}` | Unformatted value of the referenced attribute in the first multibrick |\n| | `%{Brick#2.Attribute->rawValue}` | Unformatted value of the referenced attribute in the second multibrick |\n| **Property resolver** | `%{SkyeConfigurationProperty['property_name']}` | Value of a specific Skye configuration property |\n| **Text resolver** | `%{Brick.Attribute->text['text_type']}` | Text stored in referenced text type of referenced attribute |\n| | `%{Brick.Attribute->valueText['text_type']}` | Text stored in referenced text type of the value of the referencedattribute |\n| | `%{Brick->text['text_type']}` | Text stored in referenced text type of referenced brick |\n| | `%{Root->text['text_type']}` | Text stored in referenced text type of referenced root |\n| **Context resolver** | `%{SkyeContext['skyeRole']}` | Role of the user that is logged in (or \u201canonymous\u201d) <br> <br> Example: callcenter |\n| | `%{SkyeContext['channel']}` | Current channel (e.g. callcenter) |\n| | `%{SkyeContext['skyeApplicationChannel']}` | The channel the user tries to log into (e.g. callcenter). This variable resolver is used in the User management only. <br> See details [below](#brickattribute-formattedvalue-brickattribute-rawvalue-brickattribute-shortorformattedvalue). |\n| | `%{SkyeContext['localeLanguage']}` | Current language (e.g. en) |\n| | `%{SkyeContext['localeCountry']}` | Current country (e.g. US) |\n| | `%{SkyeContext['locale']}` | Current locale (e.g. en\\_US) |\n| **User context resolver** | `%{UserContext['username']}` | User name of the current user |\n| | `%{UserContext['uuid']}` | Returns the UUID of the last forgotten password user implementation |\n| | `%{UserContext['givenname']}` | First name of the current user |\n| | `%{UserContext['surname']}` | Last name of the current user |\n| | `%{UserContext['organizationId']}` | Organization ID of the current user |\n| | `%{UserContext['authorizationLevel']}` | Authorization level of the current user |\n| | `%{UserContext['skyeRole']}` | SkyeRole of the logged in user, retrieved from user management <br> <br> Example: SKYE_CALLCENTER |\n| **Date and time resolver** | `%{TODAY}` | Current system date |\n| | `%{TODAY+1DAY}` | Current system date + 1 day <br> <br> It is possible to add 1 \u201399 days |\n| | `%{TODAY +1MONTH}` | Current date + 1 month <br> <br> It is possible to add 1-99 months |\n| | `%{TODAY+1YEAR}` | Current date + 1 year <br> <br> It is possible to add 1-9999 years |\n| | `%{TODAY+10DAY + 3MONTH +4YEAR}` | Combination of the three above |\n| | `%{TODAY+3MONTH + 5YEAR+4YEAR+ 6DAY+3MONTH}` | Current system date + 6 days + 6 months + 9 years |\n| | `%{TODAY+3MONTH + 5YEAR+4YEAR+ 6DAY+3MONTH + TIME(NOW) + 2HOUR + 3MINUTE}` | Current system date + 6 days + 6 months + 9 years at current system time + 2 hours + 3 minutes |\n| | `%{FIRST_DAY_OF_MONTH}` | First day of the current month |\n| | `%{Brick.Attribute ->rawValue +5DAY}` | Date from another attribute and add days, months or years |\n| | `%{TIME(NOW)}` | Current system time |\n| | `%{TIME(13:30:59)}` | Returns a specific time in 24 hour clock |\n| | `%{TODAY + TIME(NOW)}` | Current system date and time |\n| | `%{TODAY + 1DAY +TIME(NOW)}` | Tomorrow at the same time |\n| | `%{FIRST_DAY_OF_MONTH + 1DAY + TIME(01:00:00)}` | Second day of the month |\n| **Root field resolver** | `%{root->creationDate}` | Creation date of the implementation root. It returns a value with data type Date. |\n| | `%{root->lastModifiedDate}` | Last modified date of the implementation root. It returns a value with data type Date. |\n| | `%{root->userCreated}` | User name of the user who has created the implementation root |\n| | `%{root->userModified}` | User name of the user who has modified the implementation root latest. |\n| | `%{Root->creationDate}` | Creation date of the implementation root. It returns a value with data type Date. |\n| | `%{Root->lastModifiedDate}` | Last modified date of the implementation root. It returns a value with data type Date. |\n| | `%{Root->userCreated}` | User name of the user who has created the implementation root |\n| | `%{Root->userModified}` | User name of the user who has modified the implementation root latest. |\n| **Reference resolver** | `%{ref[Root1.ReferenceAttribute1].Root2.Attribute->formattedValue}` | Get a formatted value of an attribute navigating through a reference attribute pointing only to one root (Root2) |\n| | `%{ref[Root1.ReferenceAttribute1].root.Attribute->formattedValue}` | Get the formatted value(s) of the attribute(s) navigating through a reference pointing to one or several roots. In case an additional reference to a new root is added it will also be considered. |\n| | `%{ref[Root1.ReferenceAttribute1 to Root2, Root3].ref[Brick.ReferenceAttribute2 to Root4].` <br> <br> `Root4.Attribute->formattedValue}` | Get a formatted value of an attribute navigating through two reference attributes, the first one is pointing to several roots, but the expression only applied to two (Root2 and Root3). The second reference attribute is also pointing to several roots, but the expression is only applied to one root (Root4). |\n| | `%{ref[Root1.ReferenceAttribute1 to Root2].ref[Root2.ReferenceAttribute2 to Root3].` <br> <br> `ref[Root3.ReferenceAttribute3 to Root4]. Root4.Attribute->formattedValue}` | Get a formatted value of an attribute navigating through three reference attributes |\n| | `%{ref[Root1.ReferenceAttribute to Root2].Root2.Attribute->text['text_type']}` | Get a specific text of an attribute navigating through a reference attribute |\n| | `%{ref[Root1.ReferenceAttribute1 to Root2].root.Attribute->formattedValue}` | Get a formatted value of an attribute navigating through a reference attribute (using root notation) |\n| | `%{ref[Root1.ReferenceAttribute to Root2].root.Attribute->text['text_type']}` | Get a specific text of an attribute navigating through a reference attribute (using root notation) |\n| **Link attribute specific resolver** | `%{Brick.LinkAttribute->link}` | This resolver can be used to embed a Link attribute in a text (e.g. Message attribute, HTML/JS attribute or the infoText of an attribute). |\n| | `%{Brick.LinkAttribute->text['linkUrl']}` | Get the value of the 'Link URL' property of the Link attribute. |\n| | `%{Brick.LinkAttribute->text['linkText']}` | Get the value of the 'Link text' property of the Link attribute. |",
        "## Definition  \nA definition is something that you configure in Business Canvas.  \nA definition or set of definitions is a frame-work describing how your functionality will look like.  \nIn object oriented programming terms, it could be called a class.  \nLet\u2019s take a customer as an example.  \nA customer definition will have:  \n* All applicable data for a customer (first name, last name)\n* All applicable logic (could be dependencies or Excels or other components, e.g. if date of birth is x, then I calculate the age with an Excel, or if a field is filled out, I make another field visible)\n* All applicable references:  \n+ Customer definition will not achieve the functionality on its own. it needs helper definitions.\n+ It will have a related process definition (e.g. CreateCustomerProcess), or an event definition (DeleteCustomerEvent), or a related product or generic definition (CreateCustomerAPI), or a transformation definition (ImportCustomer).\n+ There will usually be 5-6 separate definitions working together to achieve a given functionality. These definitions will be connected to each other through references (either somewhere in the background, or very visibly to the person doing the configuration, e.g. through reference or back-reference attributes).\n+ By default, separate definitions are not able to communicate with each other, they can only send/receive data if they are connected through reference attributes, or if they communicate with an API (in this case, they may not be connected to each other at all).",
        "### Texts on the root  \nThe following text types can be added to the root of a product definition:  \n| **Text type** | **Description** |\n| --- | --- |\n| backgroundPicture | Defines the image that is displayed in the header of all processes that use the product. |\n| infoPicture | Defines the image that is displayed for the product in the Product selector components. Please refer to [Product categorization](./product-categorization.md) for the configuration. |\n| pageFavicon | Defines the icon that is displayed in the browser's header for all processes that use the product. |\n| pageTitle | Defines the title that is displayed in the browser's header for all processes that use the product. |\n| productInfoText | Defines the info text of the product Product selector components. The info text is displayed as a pop-up message when the user clicks on the info icon. Please refer to [Product categorization](./product-categorization.md) for the configuration. |\n| productMarketing | Defines the text that is displayed for the product in Product selector components. Please refer to [Product categorization](./product-categorization.md) for the configuration. |",
        "# XSL and XML files  \n## XSL file  \nThe XSL file is written in the xsl-fo markup language for formatting the XML document with the purpose of generating the PDF file.  \n**NB**: This is the file that will be added as a resource file to the product definition in Skye. Name the file the**same as the new context**in the Business Canvas. For more information, see  \nTo learn more about how to create the XSL document in XSL-FO, visit",
        "### How to navigate through references  \n**Dependencies**  \nDependencies with supplier attributes from other definitions are also called \"cross-model\" dependencies. To create such a dependency, please proceed with the following steps.  \n1. To use an attribute from a referenced implementation as supplier attribute in a condition of a dependency, you can click on the reference attribute link in the attribute searcher.  \n![screenshot](https://confluence.innoveo.com/is914/files/158604886/158604896/1/1711440494000/image2018-2-23_14-36-43.png)  \n1. After having selected the reference attribute, attributes from the referenced definition are listed and the path how to get to this attribute is displayed on top of the dialog.  \n![screenshot](https://confluence.innoveo.com/is914/files/158604886/158604897/1/1711440494000/image2018-2-23_14-38-23.png)  \n**Variable resolvers**  \nHow to navigate through references via variable resolvers is described [here...](../../variable-resolver.md) . Using the same mechanism it is of course also possible to set a value in a referenced implementation via default value dependency.  \n**Excel**  \nVia excel it is possible to retrieve and set values from referenced implementations. The following format has to be used:  \n`{BrickTextId1}.{referenceTextId}.{BrickTextId2}.{attributeTextId}`  \nwhere  \n- {BrickTextId1}: is the brick text-id of the brick where the reference attribute is located.\n- {referenceTextId}: is the attribute text-id of the reference attribute (the excel attribute needs to be on the same definition than this reference)  \n- {BrickTextId2}: is the brick text-id of the brick where the attribute to be used in input or output is located.\n- {attributeTextId}: is the attribute text-id of the attribute to be set / to be retrieved.  \nIt is of course also possible to navigate through multiple references.  \nExample:  \n`Home.shoppingcartItemRef.ShoppingcartItem.insuredObject.Shoppingcart.setPaymentMethodVR`",
        "## Setup  \n* Create a new export event\n* Select the definitions to be exported and add filters if needed\n* Setup the Headers and map attributes to the headers",
        "## Create implementation service  \nThe createImplementation request is defined in a generic way. Attributes are identified by their parent (container brick) full text-id path and the attribute text-id and values are specified in its string representation.  \nFurther request data is (besides the common data):  \n- text-id of the root implementation to be created\n- whether or not the created object shall be persisted in the database  \nCreating a product implementation without persisting to the database may be used by an external system for quote calculation.  \nBelow is a request template for creating an implementation object:  \n```\n<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:imp=\"http://skye.innoveo.com/implementation-xml\" xmlns:imp1=\"http://skye.innoveo.com/ws/implementation-type\">\n<soapenv:Header/>\n<soapenv:Body>\n<imp:createImplementationRequest>\n<imp:definitionTextId>?</imp:definitionTextId>\n<imp:shouldPersist>?</imp:shouldPersist>\n<imp:contextInfo>\n<imp1:locale>?</imp1:locale>\n<imp1:channel>?</imp1:channel>\n<imp1:role>?</imp1:role>\n</imp:contextInfo>\n<imp:changeList>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>?</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>?</imp1:attributeTextId>\n<imp1:value>?</imp1:value>\n</imp1:setAttributeValue>\n<imp1:addBrick>\n<imp1:parentFullTextIdPath>?</imp1:parentFullTextIdPath>\n<imp1:brickTextId>?</imp1:brickTextId>\n</imp1:addBrick>\n<imp1:deleteBrick>\n<imp1:brickFullTextIdPath>?</imp1:brickFullTextIdPath>\n</imp1:deleteBrick>\n</imp:changeList>\n<imp:validationStrategy>?</imp:validationStrategy>\n</imp:createImplementationRequest>\n</soapenv:Body>\n</soapenv:Envelope>\n```  \nThe change list section contains a list of attribute set-value and/or add- or remove-brick settings. The following characteristics apply:  \n- The blocks are executed in the order specified in the request.\n- Attributes that are not listed in the create request will get their defined default value (eventually including dependency evaluation).\n- Adding or deleting bricks requires that the defined min-/max-settings of the corresponding bricks are respected. Otherwise, an error will be thrown  \nFollowing is an example request to create a persisted Home product. It creates a root implementation, sets some attribute values, adds 2 multi-bricks, sets values on the multi-bricks, and deletes a before added multibrick.  \n```\n<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:imp=\"http://skye.innoveo.com/implementation-xml\" xmlns:imp1=\"http://skye.innoveo.com/ws/implementation-type\">\n<soapenv:Header/>\n<soapenv:Body>\n<imp:createImplementationRequest>\n<imp:definitionTextId>Home</imp:definitionTextId>\n<imp:shouldPersist>true</imp:shouldPersist>\n<imp:contextInfo>\n<imp1:locale>en_US</imp1:locale>\n<imp1:channel>public</imp1:channel>\n<imp1:role>anonymous</imp1:role>\n</imp:contextInfo>\n<imp:changeList>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>Home.Customer</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>lastName</imp1:attributeTextId>\n<imp1:value>Miller</imp1:value>\n</imp1:setAttributeValue>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>Home.Customer</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>dateOfBirth</imp1:attributeTextId>\n<imp1:value>1967.07.30</imp1:value>\n</imp1:setAttributeValue>\n<imp1:addBrick>\n<imp1:parentFullTextIdPath>Home.Product</imp1:parentFullTextIdPath>\n<imp1:brickTextId>Valuable</imp1:brickTextId>\n</imp1:addBrick>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>Home.Product.Valuable[1]</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>Category</imp1:attributeTextId>\n<imp1:value>Paintings</imp1:value>\n</imp1:setAttributeValue>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>Home.Product.Valuable[1]</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>SumInsured</imp1:attributeTextId>\n<imp1:value>1200.50</imp1:value>\n</imp1:setAttributeValue>\n<imp1:addBrick>\n<imp1:parentFullTextIdPath>Home.Product</imp1:parentFullTextIdPath>\n<imp1:brickTextId>Valuable</imp1:brickTextId>\n</imp1:addBrick>\n<imp1:setAttributeValue>\n<imp1:parentFullTextIdPath>Home.Product.Valuable[2]</imp1:parentFullTextIdPath>\n<imp1:attributeTextId>Category</imp1:attributeTextId>\n<imp1:value>MusicalInstruments</imp1:value>\n</imp1:setAttributeValue>\n<imp1:deleteBrick>\n<imp1:brickFullTextIdPath>Home.Product.Valuable[2]</imp1:brickFullTextIdPath>\n</imp1:deleteBrick>\n</imp:changeList>\n</imp:createImplementationRequest>\n</soapenv:Body>\n</soapenv:Envelope>\n```",
        "# Logs  \nYou can see the XML you\u2019re working with in the server logs, by setting the following log4j to TRACE:  \n<logger name=\"skye.integration.printing.pdf\" level=\"TRACE\"/>  \nWhen the document generation happens, this will give you the entire XML structure being used that you can then copy from the logs and analyze as desired, or put into [Oxygen](https://innoveo.atlassian.net/wiki/spaces/PBKS/pages/4722866/Oxygen+XML+Editor)",
        "# Export to CSV  \nProvides the ability to create csv files with custom headers and information as an on-demand or recurring service.  \nThe data is not restricted to only one definition in the application however it is recommended to:  \n* (1) Have a \u201croot definition\u201d where from the export is initiated from, and the data exported follows the logical definition structure.\n* (2) When choosing multiple definitions to be exported, it is recommended that they have a similar structure \u2192 The same attributes are available on all of them\n* Example Requirement: Export all coverages with Policy and customer information  \n+ Different coverages are normally easy to export at once, as they tend to have similar setup (2)\n+ Coverages normally do have a reference to their Policy and to their Customer \u2192 They are accessible trough the logical definition structure (1)",
        "# Configure \"Definition(s) to export\" properties  \n![screenshot](https://confluence.innoveo.com/is915/files/158612224/158612235/1/1718367918000/exporttoroot2.png)  \n| Configuration | Description |\n| --- | --- |\n| Definition(s) to export | The field \"Definition(s) to export\" defines which definition(s) that should be exported. At least one definition has to be selected. Multiple definitions from different model types are supported. |",
        "## Create XML in an attribute  \nFor storing the Data-Set in an XML format the label / long Texts of an attribute can be used.  \nResolvers can be used to populate the XML with actual Skye attributes values.  \nExample of XML data format with resolvers<product>\n<plan\\_start\\_date>%{Brick.StartDate->rawValue}</plan\\_start\\_date>\n<plan\\_number>%{Brick.PlanNumber->rawValue}</plan\\_number>\n<product>%{Brick.ProductName->rawValue}</product>\n<currency>%{Brick.ProcutCurrency->rawValue}</currency>\n<payment\\_frequency>%{Brick.PaymnetFrequency->rawValue}</payment\\_frequency>\n<total\\_premium>%{Brick.AnnualPremium->rawValue}</total\\_premium>\n</product>  \n| Useful links | |\n| --- | --- |\n| Official site | [SmartCOMM | Next-Generation CCM (smartcommunications.com)](https://www.smartcommunications.com/products/smartcomm/) |\n| Now Health project Confluence | SmartComm |",
        "### Example for the XML file  \n| <?xml version=\"1.0\" encoding=\"UTF-8\"?><print-template-view-model> </print-template-view-model> |\n| --- |",
        "# Configure \"Definition(s) to export\" properties  \n![screenshot](https://confluence.innoveo.com/is915/files/158612146/158612156/1/1718367886000/exporttoSFTP2.png)  \n| Configuration | Description |\n| --- | --- |\n| Definition(s) to export | The field \"Definition(s) to export\" defines which definition(s) that should be exported. At least one definition has to be selected. Multiple definitions from different model types are supported. |"
      ],
      "success": false,
      "metricsData": [
        {
          "name": "Faithfulness",
          "threshold": 0.7,
          "success": true,
          "score": 1.0,
          "reason": "Fantastic job! The faithfulness score is 1.00 because there are no contradictions detected between the actual output and the retrieval context. Keep up the great work!",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.029969999999999997,
          "verboseLogs": "Truths (limit=None):\n[\n    \"The print service attribute can generate a PDF document using a configured template.\",\n    \"PDF documents are generated and saved in a resource attribute through the print service attribute.\",\n    \"Templates are mandatory when configuring the print service attribute to generate a PDF.\",\n    \"All configured attributes like context channel, context role, context page, and locale are mandatory for the print service attribute.\",\n    \"REST endpoint exposure allows retrieval of information in Skye through a logical definition model.\",\n    \"Different model types like User, User Group, Generic, and Campaign can be displayed in the product selector.\",\n    \"A `definition` in Business Canvas describes how functionality looks like, similar to a class in object-oriented programming.\",\n    \"Generic definitions can use most of the tools applicable to product definitions.\",\n    \"Once the PDF is generated by the printing service, the value is reset to empty.\",\n    \"The createImplementation request can create a product implementation without persisting it to the database for external systems.\",\n    \"Setting the log level to TRACE for skye.integration.printing.pdf shows the complete XML structure used during document generation.\",\n    \"Export to CSV features enable the user to create files with customizable headers and information as a one-time or recurring service.\",\n    \"Long texts or labels of an attribute can store data sets in XML format utilizing resolvers.\",\n    \"The XSL file is crucial for formatting the XML document to generate the PDF file with the xsl-fo markup language.\",\n    \"The context role defines visibility and sort order configurations for attributes in a template.\",\n    \"A product definition will have attributes for data, logic, and references needed for functionality.\",\n    \"Multiple definitions can work together in an application through references or APIs.\",\n    \"Non-functional variable resolvers provide access to different attributes or contexts within the defined parameters.\",\n    \"The date and time resolver can modify the current system date/time by days, months, or years.\",\n    \"The SkyeContext captures current user roles, channels, and locale settings.\",\n    \"Resource attributes store generated PDF documents from the print service.\",\n    \"A customer definition may involve multiple definitions like CreateCustomerProcess or DeleteCustomerEvent for functionality.\",\n    \"Definition or text types like background picture, and page title can be attributed to the root of a product definition.\",\n    \"SOAP requests can create or update implementations in Skye encompassing model and context information.\"\n] \n \nClaims:\n[\n    \"To access data from a product definition and print it onto a document, you can use the PrintService attribute on a generic definition.\",\n    \"You need to set up the PrintService attribute with necessary properties like template, context channel, context role, context page, locale, document name, and resource attribute.\",\n    \"Variable resolvers are used to navigate references to access attributes from the product definition.\",\n    \"The syntax for accessing attributes through references looks like 'ref[Root1.ReferenceAttribute1].Root2.Attribute->formattedValue'.\",\n    \"In the syntax, 'Root1' represents the generic definition, 'ReferenceAttribute1' is the attribute referencing the product definition, and 'Root2.Attribute' is the specific attribute from the product definition.\",\n    \"An example of using variable resolvers is '<productName>%{ref[GenericDefinition.ProductRef].Product.Name->formattedValue}</productName>'.\",\n    \"The XSL template should include variable resolvers to format data correctly in a PDF document.\",\n    \"Setting the PrintService value to true triggers the generation of a PDF document with data from the product definition.\",\n    \"Links for detailed documentation include 'Print Service Configuration' and 'Variable Resolvers'.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Answer Relevancy",
          "threshold": 0.5,
          "success": true,
          "score": 0.6363636363636364,
          "reason": "The score is 0.64 because while the output generally attempts to address accessing data on the product definition, several pieces of advice, such as setting up the PrintService and XSL templates, diverge from the core focus on accessing data. The presence of ancillary information gives some insight but also somewhat detracts from addressing the core query directly.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.0089125,
          "verboseLogs": "Statements:\n[\n    \"To access data from a product definition, use the PrintService attribute on a generic definition.\",\n    \"You can utilize variable resolvers to navigate through references.\",\n    \"Set up the PrintService attribute with the necessary properties.\",\n    \"Properties include template, context channel, context role, context page, locale, document name, and resource attribute.\",\n    \"Variable resolvers are used to access attributes from the product definition.\",\n    \"The syntax for accessing attributes through references is provided in the document.\",\n    \"\nExample syntax is available for accessing product attributes.\",\n    \"Ensure that your XSL template is set up correctly for PDF document generation.\",\n    \"Trigger the PrintService by setting its value to true to generate the PDF document.\",\n    \"Documentation links are provided for more detailed information on configuring the PrintService and using variable resolvers.\",\n    \"Adapt variable resolver paths according to your specific definitions and attributes.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Setting up the PrintService attribute is procedural advice, not directly related to accessing data on the product definition.\"\n    },\n    {\n        \"verdict\": \"idk\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Setting up an XSL template for PDF generation is a broader task that doesn't specifically address accessing data from the product definition.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Triggering the PrintService is operational advice, not about accessing data.\"\n    },\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"Providing documentation links is a resource guide, not directly helping in accessing data on the product definition.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"
        },
        {
          "name": "Context Relevancy (GEval)",
          "threshold": 0.6,
          "success": false,
          "score": 0.25733521072114873,
          "reason": "The retrieval context partially includes key information like PDF generation using templates and reference attributes but misses specific details such as XSLT-FOP use and reference navigation examples from the context. It enhances understanding by providing configuration examples, but lacks a contextually appropriate link related to the context. The additional details do not overshadow the core context information but are not fully aligned with all core context elements.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.02096,
          "verboseLogs": "Criteria:\nYou are testing the retriever part of the application. CONTEXT contains the reference context for the application, RETRIEVAL_CONTEXT contains the actual context. RETRIEVAL_CONTEXT will contain significantly more information which is not a problem.RETRIEVAL_CONTEXT is expected to contain a link \n \nEvaluation Steps:\n[\n    \"Verify that the RETRIEVAL_CONTEXT contains all key pieces of information from the CONTEXT.\",\n    \"Ensure that the RETRIEVAL_CONTEXT includes additional relevant details that enhance or provide a comprehensive understanding, without contradicting the CONTEXT.\",\n    \"Check that the RETRIEVAL_CONTEXT includes a link that is contextually appropriate and related to the information in the CONTEXT.\",\n    \"Confirm that the extra information in the RETRIEVAL_CONTEXT does not overshadow or misrepresent the core information present in the CONTEXT.\"\n]"
        },
        {
          "name": "Actual output/expected output quality (GEval)",
          "threshold": 0.7,
          "success": true,
          "score": 0.7,
          "reason": "The actual output provides detailed instructions on using PrintService and variable resolvers, which aligns with accessing product definitions. Documentation links are present. However, it includes more detail than the expected output and doesn't directly address mapping UUIDs, which is a key component in the expected output.",
          "strictMode": false,
          "evaluationModel": "gpt-4o",
          "evaluationCost": 0.00406,
          "verboseLogs": "Criteria:\nDetermine how close the ACTUAL OUTPUT is to the EXPECTED OUTPUTACTUAL OUTPUT is expected to share a link to documentationHaving more information is acceptable. Having contradicting information is NOT acceptable \n \nEvaluation Steps:\n[\n    \"Compare the actual output with the expected output to ensure they are similar in content and intent.\",\n    \"Check the actual output for the presence of a link to documentation, as this is an expected requirement.\",\n    \"Verify that the actual output contains only additional supportive information and no contradictory statements compared to the expected output.\",\n    \"Evaluate the completeness of the actual output in relation to the expected output to ensure all required components are present.\"\n]"
        }
      ],
      "runDuration": 43.24752762500066,
      "evaluationCost": 0.0639025,
      "order": 16
    }
  ],
  "conversationalTestCases": [],
  "metricsScores": [],
  "runDuration": 0.0,
  "evaluationCost": 0.7008375
}